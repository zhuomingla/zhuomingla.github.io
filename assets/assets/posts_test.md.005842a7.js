import{_ as s,c as o,o as n,d as e,a}from"./app.eaabe06d.js";const y=JSON.parse('{"title":"\u53EF\u7B11","description":"","frontmatter":{"title":"\u53EF\u7B11","date":"2023-03-06T00:00:00.000Z","tags":["\u65E0\u804A\u65E5\u5E38"],"cover":"../img/fcf6ae3c13fc0da1d4f215c969a0ffd22a5bb5f1.jpg%40942w_668h_progressive.webp"},"headers":[{"level":3,"title":"MLP \u7C7B","slug":"mlp-\u7C7B"},{"level":3,"title":"Block \u7C7B","slug":"block-\u7C7B"},{"level":3,"title":"GPT \u7C7B","slug":"gpt-\u7C7B"},{"level":3,"title":"\u5BFC\u5165\u5FC5\u8981\u7684\u5E93","slug":"\u5BFC\u5165\u5FC5\u8981\u7684\u5E93"},{"level":3,"title":"\u8BBE\u7F6E\u6A21\u578B\u548C\u8BAD\u7EC3\u53C2\u6570","slug":"\u8BBE\u7F6E\u6A21\u578B\u548C\u8BAD\u7EC3\u53C2\u6570"},{"level":3,"title":"\u8BBE\u5907\u548C\u6DF7\u5408\u7CBE\u5EA6\u914D\u7F6E","slug":"\u8BBE\u5907\u548C\u6DF7\u5408\u7CBE\u5EA6\u914D\u7F6E"},{"level":3,"title":"\u6570\u636E\u52A0\u8F7D\u51FD\u6570","slug":"\u6570\u636E\u52A0\u8F7D\u51FD\u6570"},{"level":3,"title":"\u6A21\u578B\u521D\u59CB\u5316","slug":"\u6A21\u578B\u521D\u59CB\u5316"},{"level":3,"title":"\u4F18\u5316\u5668\u548C GradScaler \u521D\u59CB\u5316","slug":"\u4F18\u5316\u5668\u548C-gradscaler-\u521D\u59CB\u5316"},{"level":3,"title":"\u8BC4\u4F30\u51FD\u6570","slug":"\u8BC4\u4F30\u51FD\u6570"},{"level":3,"title":"\u5B66\u4E60\u7387\u8C03\u5EA6\u51FD\u6570","slug":"\u5B66\u4E60\u7387\u8C03\u5EA6\u51FD\u6570"},{"level":3,"title":"\u8BAD\u7EC3\u5FAA\u73AF","slug":"\u8BAD\u7EC3\u5FAA\u73AF"},{"level":3,"title":"\u6027\u80FD\u76D1\u63A7","slug":"\u6027\u80FD\u76D1\u63A7"},{"level":3,"title":"\u9000\u51FA\u6761\u4EF6","slug":"\u9000\u51FA\u6761\u4EF6"},{"level":3,"title":"\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3","slug":"\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3"},{"level":3,"title":"\u68C0\u67E5\u70B9\u4FDD\u5B58","slug":"\u68C0\u67E5\u70B9\u4FDD\u5B58"},{"level":3,"title":"\u65E5\u5FD7\u8BB0\u5F55","slug":"\u65E5\u5FD7\u8BB0\u5F55"}],"relativePath":"posts/test.md"}'),l={name:"posts/test.md"},t=e(`<h1 id="\u6D4B\u8BD5\u4E86\u4E00\u4E0B-kimi" tabindex="-1">\u6D4B\u8BD5\u4E86\u4E00\u4E0B kimi <a class="header-anchor" href="#\u6D4B\u8BD5\u4E86\u4E00\u4E0B-kimi" aria-hidden="true">#</a></h1><p>User: NameError: name &#39;<strong>file</strong>&#39; is not defined</p><p>Kimi: <code>NameError: name &#39;__file__&#39; is not defined</code> \u8FD9\u4E2A\u9519\u8BEF\u901A\u5E38\u53D1\u751F\u5728 Python \u811A\u672C\u4E2D\uFF0C\u5F53\u5C1D\u8BD5\u8BBF\u95EE\u4E00\u4E2A\u4E0D\u5B58\u5728\u7684\u53D8\u91CF\u6216\u5C5E\u6027\u65F6\u3002\u5728 Python \u4E2D\uFF0C<code>__file__</code> \u662F\u4E00\u4E2A\u7279\u6B8A\u53D8\u91CF\uFF0C\u5B83\u5305\u542B\u4E86\u5F53\u524D\u811A\u672C\u7684\u8DEF\u5F84\u3002\u5982\u679C\u8FD9\u4E2A\u53D8\u91CF\u6CA1\u6709\u5B9A\u4E49\uFF0C\u53EF\u80FD\u662F\u56E0\u4E3A\u4EE5\u4E0B\u539F\u56E0\uFF1A</p><ol><li>\u4F60\u6B63\u5728\u8FD0\u884C\u7684\u662F\u4E00\u4E2A\u4EA4\u4E92\u5F0F Python \u4F1A\u8BDD\uFF0C\u800C\u4E0D\u662F\u4E00\u4E2A\u811A\u672C\u6587\u4EF6\u3002\u5728\u4EA4\u4E92\u5F0F\u4F1A\u8BDD\u4E2D\uFF0C<code>__file__</code> \u53D8\u91CF\u5E76\u4E0D\u5B58\u5728\u3002</li><li>\u4F60\u53EF\u80FD\u5728\u4E00\u4E2A\u6CA1\u6709\u6587\u4EF6\u540D\u7684\u811A\u672C\u4E2D\u8FD0\u884C\u4EE3\u7801\uFF0C\u6BD4\u5982\u4F7F\u7528 <code>python -c</code> \u547D\u4EE4\u76F4\u63A5\u6267\u884C\u4EE3\u7801\u3002</li></ol><p>\u5982\u679C\u4F60\u9700\u8981\u5728\u4EA4\u4E92\u5F0F\u4F1A\u8BDD\u4E2D\u4F7F\u7528 <code>__file__</code> \u53D8\u91CF\uFF0C\u4F60\u53EF\u4EE5\u624B\u52A8\u8BBE\u7F6E\u5B83\uFF0C\u4F8B\u5982\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#79B8FF;">__file__</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#FFAB70;">&#39;your_script_name.py&#39;</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>\u4F46\u8BF7\u6CE8\u610F\uFF0C\u8FD9\u53EA\u662F\u4E00\u4E2A\u6A21\u62DF\uFF0C\u5E76\u4E0D\u4F1A\u6539\u53D8\u5B9E\u9645\u7684\u811A\u672C\u8DEF\u5F84\u3002</p><p>\u5982\u679C\u4F60\u5728\u7F16\u5199\u811A\u672C\uFF0C\u786E\u4FDD\u4F60\u6B63\u5728\u8FD0\u884C\u7684\u662F\u811A\u672C\u6587\u4EF6\uFF0C\u800C\u4E0D\u662F\u5728\u4EA4\u4E92\u5F0F\u4F1A\u8BDD\u4E2D\u6267\u884C\u4EE3\u7801\u3002\u5982\u679C\u4F60\u786E\u5B9E\u9700\u8981\u5728\u4EA4\u4E92\u5F0F\u4F1A\u8BDD\u4E2D\u4F7F\u7528 <code>__file__</code>\uFF0C\u8003\u8651\u5C06\u4EE3\u7801\u79FB\u52A8\u5230\u4E00\u4E2A\u811A\u672C\u6587\u4EF6\u4E2D\uFF0C\u7136\u540E\u8FD0\u884C\u8BE5\u811A\u672C\u3002</p><p>User: len\uFF08\uFF09</p><p>Kimi: \u5728 Python \u4E2D\uFF0C<code>len()</code> \u51FD\u6570\u7528\u6765\u83B7\u53D6\u4E00\u4E2A\u5BF9\u8C61\u7684\u957F\u5EA6\u3002\u6700\u5E38\u89C1\u7684\u7528\u6CD5\u662F\u83B7\u53D6\u5B57\u7B26\u4E32\u3001\u5217\u8868\u3001\u5143\u7EC4\u3001\u5B57\u5178\u7B49\u6570\u636E\u7ED3\u6784\u4E2D\u5143\u7D20\u7684\u6570\u91CF\u3002\u4EE5\u4E0B\u662F\u4E00\u4E9B\u793A\u4F8B\uFF1A</p><ul><li><p>\u83B7\u53D6\u5B57\u7B26\u4E32\u7684\u957F\u5EA6\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#B392F0;">my_string </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#FFAB70;">&quot;Hello, World!&quot;</span></span>
<span class="line"><span style="color:#B392F0;">length </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> len</span><span style="color:#BBBBBB;">(my_string)</span><span style="color:#B392F0;">  </span><span style="color:#6B737C;"># \u8FD4\u56DE 13</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li><li><p>\u83B7\u53D6\u5217\u8868\u7684\u957F\u5EA6\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#B392F0;">my_list </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> [</span><span style="color:#F8F8F8;">1</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">2</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">3</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">4</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">5</span><span style="color:#B392F0;">]</span></span>
<span class="line"><span style="color:#B392F0;">length </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> len</span><span style="color:#BBBBBB;">(my_list)</span><span style="color:#B392F0;">  </span><span style="color:#6B737C;"># \u8FD4\u56DE 5</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li><li><p>\u83B7\u53D6\u5143\u7EC4\u7684\u957F\u5EA6\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#B392F0;">my_tuple </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> (</span><span style="color:#F8F8F8;">1</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">2</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">3</span><span style="color:#B392F0;">)</span></span>
<span class="line"><span style="color:#B392F0;">length </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> len</span><span style="color:#BBBBBB;">(my_tuple)</span><span style="color:#B392F0;">  </span><span style="color:#6B737C;"># \u8FD4\u56DE 3</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li><li><p>\u83B7\u53D6\u5B57\u5178\u7684\u957F\u5EA6\uFF08\u5373\u952E\u503C\u5BF9\u7684\u6570\u91CF\uFF09\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#B392F0;">my_dict </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#BBBBBB;">{</span><span style="color:#FFAB70;">&#39;a&#39;</span><span style="color:#BBBBBB;">:</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">1</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#FFAB70;">&#39;b&#39;</span><span style="color:#BBBBBB;">:</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">2</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#FFAB70;">&#39;c&#39;</span><span style="color:#BBBBBB;">:</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">3</span><span style="color:#BBBBBB;">}</span></span>
<span class="line"><span style="color:#B392F0;">length </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> len</span><span style="color:#BBBBBB;">(my_dict)</span><span style="color:#B392F0;">  </span><span style="color:#6B737C;"># \u8FD4\u56DE 3</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li><li><p>\u83B7\u53D6\u96C6\u5408\u7684\u957F\u5EA6\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#B392F0;">my_set </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#BBBBBB;">{</span><span style="color:#F8F8F8;">1</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">2</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">3</span><span style="color:#BBBBBB;">}</span></span>
<span class="line"><span style="color:#B392F0;">length </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> len</span><span style="color:#BBBBBB;">(my_set)</span><span style="color:#B392F0;">  </span><span style="color:#6B737C;"># \u8FD4\u56DE 3</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li></ul><p><code>len()</code> \u51FD\u6570\u662F Python \u5185\u7F6E\u7684\uFF0C\u56E0\u6B64\u65E0\u9700\u5BFC\u5165\u4EFB\u4F55\u6A21\u5757\u5373\u53EF\u4F7F\u7528\u3002\u5B83\u662F\u4E00\u4E2A\u975E\u5E38\u5FEB\u901F\u4E14\u5E38\u7528\u7684\u51FD\u6570\uFF0C\u7528\u4E8E\u83B7\u53D6\u6570\u636E\u7ED3\u6784\u7684\u5927\u5C0F\u3002</p><p>User: train_data = data[:int(n*0.9)]</p><p>Kimi: \u5728 Python \u4E2D\uFF0C\u8FD9\u6BB5\u4EE3\u7801\u8868\u793A\u4ECE\u540D\u4E3A <code>data</code> \u7684\u5217\u8868\u6216\u6570\u7EC4\u4E2D\u9009\u62E9\u524D <code>n * 0.9</code> \u4E2A\u5143\u7D20\uFF0C\u5E76\u5C06\u8FD9\u4E9B\u5143\u7D20\u5B58\u50A8\u5728\u540D\u4E3A <code>train_data</code> \u7684\u65B0\u53D8\u91CF\u4E2D\u3002\u8FD9\u91CC <code>n</code> \u662F <code>data</code> \u7684\u957F\u5EA6\uFF0C<code>int()</code> \u51FD\u6570\u7528\u4E8E\u5C06\u6D6E\u70B9\u6570\u7ED3\u679C\u8F6C\u6362\u4E3A\u6574\u6570\uFF0C\u56E0\u4E3A\u5217\u8868\u5207\u7247\u9700\u8981\u6574\u6570\u7D22\u5F15\u3002</p><p>\u4F8B\u5982\uFF0C\u5982\u679C <code>data</code> \u662F\u4E00\u4E2A\u5305\u542B 100 \u4E2A\u5143\u7D20\u7684\u5217\u8868\uFF0C\u5E76\u4E14 <code>n</code> \u662F 100\uFF0C\u90A3\u4E48 <code>train_data</code> \u5C06\u5305\u542B\u524D 90 \u4E2A\u5143\u7D20\uFF0C\u56E0\u4E3A <code>int(100 * 0.9)</code> \u7B49\u4E8E 90\u3002</p><p>\u8FD9\u91CC\u662F\u4E00\u4E2A\u5177\u4F53\u7684\u793A\u4F8B\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#B392F0;">data </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> [i </span><span style="color:#F97583;">for</span><span style="color:#B392F0;"> i </span><span style="color:#F97583;">in</span><span style="color:#B392F0;"> range</span><span style="color:#BBBBBB;">(</span><span style="color:#F8F8F8;">100</span><span style="color:#BBBBBB;">)</span><span style="color:#B392F0;">]  </span><span style="color:#6B737C;"># \u521B\u5EFA\u4E00\u4E2A\u5305\u542B0\u523099\u7684\u5217\u8868</span></span>
<span class="line"><span style="color:#B392F0;">n </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> len</span><span style="color:#BBBBBB;">(data)</span><span style="color:#B392F0;">  </span><span style="color:#6B737C;"># \u83B7\u53D6\u5217\u8868\u957F\u5EA6</span></span>
<span class="line"><span style="color:#B392F0;">train_data </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> data</span><span style="color:#BBBBBB;">[:</span><span style="color:#79B8FF;">int</span><span style="color:#BBBBBB;">(n </span><span style="color:#F97583;">*</span><span style="color:#BBBBBB;"> </span><span style="color:#F8F8F8;">0.9</span><span style="color:#BBBBBB;">)]</span><span style="color:#B392F0;">  </span><span style="color:#6B737C;"># \u9009\u62E9\u524D90\u4E2A\u5143\u7D20</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>\u5728\u8FD9\u4E2A\u793A\u4F8B\u4E2D\uFF0C<code>train_data</code> \u5C06\u5305\u542B\u5217\u8868 <code>data</code> \u7684\u524D 90 \u4E2A\u5143\u7D20\u3002</p><p>\u8BF7\u6CE8\u610F\uFF0C\u5982\u679C <code>n * 0.9</code> \u7684\u7ED3\u679C\u4E0D\u662F\u6574\u6570\uFF0C<code>int()</code> \u51FD\u6570\u5C06\u5411\u4E0B\u53D6\u6574\uFF0C\u8FD9\u610F\u5473\u7740\u53EF\u80FD\u4E0D\u4F1A\u7CBE\u786E\u5730\u9009\u62E9 <code>n * 0.9</code> \u4E2A\u5143\u7D20\uFF0C\u800C\u662F\u9009\u62E9\u5C11\u4E8E\u8FD9\u4E2A\u6570\u91CF\u7684\u6574\u6570\u4E2A\u5143\u7D20\u3002\u5982\u679C\u9700\u8981\u56DB\u820D\u4E94\u5165\u5230\u6700\u63A5\u8FD1\u7684\u6574\u6570\uFF0C\u53EF\u4EE5\u4F7F\u7528 <code>round()</code> \u51FD\u6570\u4EE3\u66FF <code>int()</code>\u3002</p><p>User: enc = tiktoken.get_encoding(&quot;gpt2&quot;)</p><p>Kimi: <code>enc = tiktoken.get_encoding(&quot;gpt2&quot;)</code> \u8FD9\u884C\u4EE3\u7801\u662F\u5728\u4F7F\u7528 <code>tiktoken</code> \u5E93\u6765\u83B7\u53D6\u4E0E &quot;gpt2&quot; \u6A21\u578B\u76F8\u5173\u7684\u7F16\u7801\u5668\u3002<code>tiktoken</code> \u662F\u4E00\u4E2A\u7528\u4E8E\u5904\u7406\u81EA\u7136\u8BED\u8A00\u7684\u5E93\uFF0C\u5B83\u63D0\u4F9B\u4E86\u591A\u79CD\u6A21\u578B\u7684\u7F16\u7801\u5668\uFF0C\u8FD9\u4E9B\u7F16\u7801\u5668\u53EF\u4EE5\u5C06\u6587\u672C\u8F6C\u6362\u4E3A\u6A21\u578B\u53EF\u4EE5\u7406\u89E3\u7684\u683C\u5F0F\uFF0C\u901A\u5E38\u662F\u4E00\u7CFB\u5217\u7684\u6570\u5B57\uFF08token IDs\uFF09\u3002</p><p>&quot;gpt2&quot; \u6307\u7684\u662F GPT-2 \u6A21\u578B\uFF0C\u8FD9\u662F\u7531 OpenAI \u5F00\u53D1\u7684\u4E00\u4E2A\u9884\u8BAD\u7EC3\u8BED\u8A00\u6A21\u578B\u3002\u5F53\u4F60\u8C03\u7528 <code>get_encoding</code> \u51FD\u6570\u5E76\u4F20\u5165 &quot;gpt2&quot; \u4F5C\u4E3A\u53C2\u6570\u65F6\uFF0C\u4F60\u5C06\u5F97\u5230\u4E00\u4E2A\u4E0E GPT-2 \u6A21\u578B\u517C\u5BB9\u7684\u7F16\u7801\u5668\u5BF9\u8C61\u3002</p><p>\u4EE5\u4E0B\u662F\u4F7F\u7528 <code>tiktoken</code> \u5E93\u8FDB\u884C\u7F16\u7801\u7684\u4E00\u4E2A\u7B80\u5355\u793A\u4F8B\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> tiktoken</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6B737C;"># \u83B7\u53D6 GPT-2 \u6A21\u578B\u7684\u7F16\u7801\u5668</span></span>
<span class="line"><span style="color:#B392F0;">enc </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> tiktoken</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">get_encoding</span><span style="color:#BBBBBB;">(</span><span style="color:#FFAB70;">&quot;gpt2&quot;</span><span style="color:#BBBBBB;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6B737C;"># \u8981\u7F16\u7801\u7684\u6587\u672C</span></span>
<span class="line"><span style="color:#B392F0;">text </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#FFAB70;">&quot;Hello, how are you?&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6B737C;"># \u4F7F\u7528\u7F16\u7801\u5668\u5C06\u6587\u672C\u8F6C\u6362\u4E3A token IDs</span></span>
<span class="line"><span style="color:#B392F0;">token_ids </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> enc</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">encode</span><span style="color:#BBBBBB;">(text)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#B392F0;">print</span><span style="color:#BBBBBB;">(token_ids)</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>\u5728\u8FD9\u4E2A\u793A\u4F8B\u4E2D\uFF0C<code>enc.encode(text)</code> \u5C06\u6587\u672C &quot;Hello, how are you?&quot; \u8F6C\u6362\u4E3A\u4E00\u4E2A\u6574\u6570\u5217\u8868\uFF0C\u8FD9\u4E2A\u5217\u8868\u4EE3\u8868\u4E86\u6587\u672C\u5728 GPT-2 \u6A21\u578B\u4E2D\u7684 token \u8868\u793A\u3002</p><p>\u8BF7\u6CE8\u610F\uFF0C\u8981\u8FD0\u884C\u4E0A\u8FF0\u4EE3\u7801\uFF0C\u4F60\u9700\u8981\u5148\u5B89\u88C5 <code>tiktoken</code> \u5E93\u3002\u53EF\u4EE5\u4F7F\u7528 pip \u6765\u5B89\u88C5\uFF1A</p><div class="language-sh line-numbers-mode"><button class="copy"></button><span class="lang">sh</span><pre><code><span class="line"><span style="color:#B392F0;">pip install tiktoken</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>\u5982\u679C\u4F60\u6CA1\u6709\u5B89\u88C5 <code>tiktoken</code> \u6216\u8005\u4F60\u7684\u4EE3\u7801\u73AF\u5883\u4E2D\u6CA1\u6709\u8FD9\u4E2A\u5E93\uFF0C\u5C1D\u8BD5\u8FD0\u884C <code>enc = tiktoken.get_encoding(&quot;gpt2&quot;)</code> \u5C06\u4F1A\u5BFC\u81F4 <code>ImportError</code> \u6216 <code>AttributeError</code>\u3002</p><p>User: train_ids = enc.encode_ordinary(train_data) val_ids = enc.encode_ordinary(val_data) print(f&quot;train has {len(train_ids):,} tokens&quot;) print(f&quot;val has {len(val_ids):,} tokens&quot;)</p><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u662F\u5728\u4F7F\u7528 <code>tiktoken</code> \u5E93\u7684\u7F16\u7801\u5668\u6765\u5C06\u6587\u672C\u6570\u636E\u8F6C\u6362\u4E3A\u6A21\u578B\u53EF\u4EE5\u7406\u89E3\u7684 token IDs\u3002\u8FD9\u91CC <code>train_data</code> \u548C <code>val_data</code> \u5E94\u8BE5\u662F\u6587\u672C\u6570\u636E\u7684\u5217\u8868\uFF0C<code>enc</code> \u662F\u4E4B\u524D\u901A\u8FC7 <code>tiktoken.get_encoding(&quot;gpt2&quot;)</code> \u83B7\u53D6\u7684\u7F16\u7801\u5668\u5BF9\u8C61\u3002</p><p><code>enc.encode_ordinary</code> \u51FD\u6570\u5C06\u6587\u672C\u6570\u636E\u8F6C\u6362\u4E3A token IDs\uFF0C\u7136\u540E <code>train_ids</code> \u548C <code>val_ids</code> \u5206\u522B\u5B58\u50A8\u4E86\u8BAD\u7EC3\u96C6\u548C\u9A8C\u8BC1\u96C6\u7684 token IDs\u3002</p><p>\u4EE5\u4E0B\u662F\u8FD9\u6BB5\u4EE3\u7801\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ol><li><p><code>train_ids = enc.encode_ordinary(train_data)</code>\uFF1A\u8FD9\u884C\u4EE3\u7801\u5C06\u8BAD\u7EC3\u6570\u636E <code>train_data</code> \u8F6C\u6362\u4E3A token IDs\uFF0C\u5E76\u5C06\u7ED3\u679C\u5B58\u50A8\u5728 <code>train_ids</code> \u4E2D\u3002<code>encode_ordinary</code> \u65B9\u6CD5\u901A\u5E38\u8FD4\u56DE\u4E00\u4E2A\u5217\u8868\uFF0C\u5176\u4E2D\u6BCF\u4E2A\u5143\u7D20\u90FD\u662F\u4E00\u4E2A\u6574\u6570\u5217\u8868\uFF0C\u4EE3\u8868\u4E00\u4E2A\u6587\u672C\u5E8F\u5217\u7684 token IDs\u3002</p></li><li><p><code>val_ids = enc.encode_ordinary(val_data)</code>\uFF1A\u8FD9\u884C\u4EE3\u7801\u5C06\u9A8C\u8BC1\u6570\u636E <code>val_data</code> \u8F6C\u6362\u4E3A token IDs\uFF0C\u5E76\u5C06\u7ED3\u679C\u5B58\u50A8\u5728 <code>val_ids</code> \u4E2D\u3002</p></li><li><p><code>print(f&quot;train has {len(train_ids):,} tokens&quot;)</code>\uFF1A\u8FD9\u884C\u4EE3\u7801\u8BA1\u7B97\u8BAD\u7EC3\u6570\u636E\u7684\u603B token \u6570\u91CF\uFF0C\u5E76\u6253\u5370\u51FA\u6765\u3002<code>len(train_ids)</code> \u8BA1\u7B97\u7684\u662F\u5217\u8868\u7684\u957F\u5EA6\uFF0C\u5373\u8BAD\u7EC3\u96C6\u4E2D\u6240\u6709\u6587\u672C\u5E8F\u5217\u7684 token IDs \u6570\u91CF\u4E4B\u548C\u3002\u683C\u5F0F\u5316\u5B57\u7B26\u4E32 <code>{len(train_ids):,}</code> \u7528\u4E8E\u6DFB\u52A0\u5343\u4F4D\u5206\u9694\u7B26\uFF0C\u4F7F\u6570\u5B57\u66F4\u6613\u4E8E\u9605\u8BFB\u3002</p></li><li><p><code>print(f&quot;val has {len(val_ids):,} tokens&quot;)</code>\uFF1A\u8FD9\u884C\u4EE3\u7801\u8BA1\u7B97\u9A8C\u8BC1\u6570\u636E\u7684\u603B token \u6570\u91CF\uFF0C\u5E76\u6253\u5370\u51FA\u6765\u3002\u540C\u6837\uFF0C<code>len(val_ids)</code> \u8BA1\u7B97\u7684\u662F\u9A8C\u8BC1\u96C6\u4E2D\u6240\u6709\u6587\u672C\u5E8F\u5217\u7684 token IDs \u6570\u91CF\u4E4B\u548C\uFF0C\u683C\u5F0F\u5316\u5B57\u7B26\u4E32\u7528\u4E8E\u6DFB\u52A0\u5343\u4F4D\u5206\u9694\u7B26\u3002</p></li></ol><p>\u8BF7\u6CE8\u610F\uFF0C<code>encode_ordinary</code> \u65B9\u6CD5\u7684\u5177\u4F53\u884C\u4E3A\u53EF\u80FD\u53D6\u51B3\u4E8E <code>tiktoken</code> \u5E93\u7684\u7248\u672C\u548C\u4F7F\u7528\u7684\u6A21\u578B\u3002\u5728\u67D0\u4E9B\u60C5\u51B5\u4E0B\uFF0C\u5B83\u53EF\u80FD\u8FD4\u56DE\u4E00\u4E2A\u4E8C\u7EF4\u5217\u8868\uFF0C\u5176\u4E2D\u6BCF\u4E2A\u5185\u90E8\u5217\u8868\u4EE3\u8868\u4E00\u4E2A\u6587\u672C\u5E8F\u5217\u7684 token IDs\u3002</p><p>\u5982\u679C\u4F60\u7684\u73AF\u5883\u4E2D\u6CA1\u6709\u5B89\u88C5 <code>tiktoken</code> \u5E93\uFF0C\u4F60\u9700\u8981\u5148\u5B89\u88C5\u5B83\uFF0C\u7136\u540E\u624D\u80FD\u8FD0\u884C\u8FD9\u6BB5\u4EE3\u7801\u3002\u5982\u679C\u4F60\u5DF2\u7ECF\u5B89\u88C5\u4E86 <code>tiktoken</code> \u5E93\uFF0C\u4F46\u9047\u5230\u4EFB\u4F55\u95EE\u9898\uFF0C\u8BF7\u786E\u4FDD\u4F60\u7684 <code>train_data</code> \u548C <code>val_data</code> \u662F\u6B63\u786E\u7684\u6587\u672C\u6570\u636E\u5217\u8868\uFF0C\u5E76\u4E14 <code>enc</code> \u662F\u6709\u6548\u7684\u7F16\u7801\u5668\u5BF9\u8C61\u3002</p><p>User: train_ids = np.array(train_ids, dtype=np.uint16) val_ids = np.array(val_ids, dtype=np.uint16) train_ids.tofile(os.path.join(os.path.dirname(<strong>file</strong>), &#39;train.bin&#39;)) val_ids.tofile(os.path.join(os.path.dirname(<strong>file</strong>), &#39;val.bin&#39;))</p><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u662F\u5C06\u7F16\u7801\u540E\u7684\u8BAD\u7EC3\u96C6\u548C\u9A8C\u8BC1\u96C6\u7684 token IDs \u8F6C\u6362\u4E3A NumPy \u6570\u7EC4\uFF0C\u5E76\u4FDD\u5B58\u5230\u4E8C\u8FDB\u5236\u6587\u4EF6\u4E2D\u3002\u4E0B\u9762\u662F\u4EE3\u7801\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ol><li><p><code>train_ids = np.array(train_ids, dtype=np.uint16)</code> \u548C <code>val_ids = np.array(val_ids, dtype=np.uint16)</code>\uFF1A\u8FD9\u4E24\u884C\u4EE3\u7801\u5C06 <code>train_ids</code> \u548C <code>val_ids</code> \uFF08\u5B83\u4EEC\u662F\u7F16\u7801\u540E\u7684 token IDs \u5217\u8868\uFF09\u8F6C\u6362\u4E3A NumPy \u6570\u7EC4\u3002<code>dtype=np.uint16</code> \u6307\u5B9A\u4E86\u6570\u7EC4\u7684\u6570\u636E\u7C7B\u578B\u4E3A\u65E0\u7B26\u53F7 16 \u4F4D\u6574\u6570\uFF0C\u8FD9\u901A\u5E38\u7528\u4E8E\u5B58\u50A8 token IDs\uFF0C\u56E0\u4E3A\u5B83\u4EEC\u901A\u5E38\u662F\u975E\u8D1F\u6574\u6570\u3002</p></li><li><p><code>train_ids.tofile(os.path.join(os.path.dirname(__file__), &#39;train.bin&#39;))</code> \u548C <code>val_ids.tofile(os.path.join(os.path.dirname(__file__), &#39;val.bin&#39;))</code>\uFF1A\u8FD9\u4E24\u884C\u4EE3\u7801\u5C06\u8F6C\u6362\u540E\u7684 NumPy \u6570\u7EC4\u4FDD\u5B58\u4E3A\u4E8C\u8FDB\u5236\u6587\u4EF6\u3002<code>os.path.join</code> \u7528\u4E8E\u8FDE\u63A5\u8DEF\u5F84\uFF0C<code>os.path.dirname(__file__)</code> \u83B7\u53D6\u5F53\u524D\u811A\u672C\u6587\u4EF6\u7684\u76EE\u5F55\u8DEF\u5F84\u3002\u7136\u540E\uFF0C\u5B83\u5C06\u6587\u4EF6\u540D &#39;train.bin&#39; \u548C &#39;val.bin&#39; \u5206\u522B\u9644\u52A0\u5230\u8FD9\u4E2A\u8DEF\u5F84\u4E0A\uFF0C\u4F5C\u4E3A\u8F93\u51FA\u6587\u4EF6\u7684\u5B8C\u6574\u8DEF\u5F84\u3002</p><ul><li><code>&#39;train.bin&#39;</code> \u662F\u8BAD\u7EC3\u96C6 token IDs \u7684\u4E8C\u8FDB\u5236\u6587\u4EF6\u540D\u3002</li><li><code>&#39;val.bin&#39;</code> \u662F\u9A8C\u8BC1\u96C6 token IDs \u7684\u4E8C\u8FDB\u5236\u6587\u4EF6\u540D\u3002</li></ul></li></ol><p><code>tofile</code> \u65B9\u6CD5\u7528\u4E8E\u5C06 NumPy \u6570\u7EC4\u76F4\u63A5\u5199\u5165\u5230\u4E00\u4E2A\u4E8C\u8FDB\u5236\u6587\u4EF6\u4E2D\u3002\u5982\u679C\u6587\u4EF6\u5DF2\u5B58\u5728\uFF0C\u5B83\u4F1A\u88AB\u8986\u76D6\uFF1B\u5982\u679C\u6587\u4EF6\u4E0D\u5B58\u5728\uFF0C\u5B83\u4F1A\u88AB\u521B\u5EFA\u3002</p><p>\u8BF7\u6CE8\u610F\uFF0C\u8FD9\u6BB5\u4EE3\u7801\u5047\u8BBE\uFF1A</p><ul><li>\u4F60\u5DF2\u7ECF\u6709\u4E00\u4E2A\u540D\u4E3A <code>__file__</code> \u7684\u53D8\u91CF\uFF0C\u5B83\u901A\u5E38\u5728 Python \u811A\u672C\u4E2D\u81EA\u52A8\u5B9A\u4E49\uFF0C\u8868\u793A\u5F53\u524D\u811A\u672C\u7684\u6587\u4EF6\u8DEF\u5F84\u3002\u5982\u679C\u4F60\u5728\u4EA4\u4E92\u5F0F\u73AF\u5883\uFF08\u5982 Jupyter Notebook \u6216 Python shell\uFF09\u4E2D\u8FD0\u884C\u8FD9\u6BB5\u4EE3\u7801\uFF0C<code>__file__</code> \u53EF\u80FD\u672A\u5B9A\u4E49\uFF0C\u4F60\u9700\u8981\u76F8\u5E94\u5730\u8C03\u6574\u4EE3\u7801\u3002</li><li><code>train_ids</code> \u548C <code>val_ids</code> \u662F\u4E4B\u524D\u901A\u8FC7 <code>enc.encode_ordinary</code> \u5F97\u5230\u7684 token IDs \u5217\u8868\u3002</li></ul><p>\u6B64\u5916\uFF0C\u8FD9\u6BB5\u4EE3\u7801\u4F7F\u7528\u4E86 NumPy \u5E93\uFF0C\u5982\u679C\u4F60\u7684\u73AF\u5883\u4E2D\u6CA1\u6709\u5B89\u88C5 NumPy\uFF0C\u4F60\u9700\u8981\u5148\u5B89\u88C5\u5B83\uFF0C\u53EF\u4EE5\u4F7F\u7528\u4EE5\u4E0B\u547D\u4EE4\uFF1A</p><div class="language-sh line-numbers-mode"><button class="copy"></button><span class="lang">sh</span><pre><code><span class="line"><span style="color:#B392F0;">pip install numpy</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>\u5982\u679C\u4F60\u5DF2\u7ECF\u5B89\u88C5\u4E86 NumPy \u5E76\u4E14 <code>__file__</code> \u53D8\u91CF\u5728\u4F60\u7684\u4EE3\u7801\u73AF\u5883\u4E2D\u662F\u53EF\u7528\u7684\uFF0C\u8FD9\u6BB5\u4EE3\u7801\u5E94\u8BE5\u80FD\u591F\u6B63\u5E38\u5DE5\u4F5C\u3002\u5982\u679C\u4F60\u5728\u4EA4\u4E92\u5F0F\u73AF\u5883\u4E2D\u5DE5\u4F5C\uFF0C\u4F60\u53EF\u80FD\u9700\u8981\u6307\u5B9A\u4E00\u4E2A\u5177\u4F53\u7684\u6587\u4EF6\u8DEF\u5F84\u800C\u4E0D\u662F\u4F7F\u7528 <code>__file__</code>\u3002</p><p>User: import os import requests import tiktoken import numpy as np</p><p>Kimi: \u5F88\u597D\uFF0C\u4F60\u5DF2\u7ECF\u5217\u51FA\u4E86\u4E00\u4E9B Python \u4E2D\u5E38\u7528\u7684\u5E93\uFF0C\u8FD9\u4E9B\u5E93\u5728\u6570\u636E\u79D1\u5B66\u3001\u673A\u5668\u5B66\u4E60\u548C\u7F51\u7EDC\u8BF7\u6C42\u7B49\u9886\u57DF\u975E\u5E38\u6709\u7528\u3002\u4E0B\u9762\u662F\u6BCF\u4E2A\u5E93\u7684\u7B80\u8981\u8BF4\u660E\uFF1A</p><ol><li><p><strong>os</strong>: \u8FD9\u4E2A\u5E93\u63D0\u4F9B\u4E86\u4E00\u79CD\u65B9\u4FBF\u7684\u65B9\u5F0F\u6765\u4F7F\u7528\u64CD\u4F5C\u7CFB\u7EDF\u4F9D\u8D56\u7684\u529F\u80FD\u3002\u5B83\u53EF\u4EE5\u7528\u6765\u6267\u884C\u5982\u6587\u4EF6\u8DEF\u5F84\u64CD\u4F5C\u3001\u73AF\u5883\u53D8\u91CF\u8BBF\u95EE\u7B49\u4EFB\u52A1\u3002</p></li><li><p><strong>requests</strong>: \u8FD9\u662F\u4E00\u4E2A\u7528\u4E8E\u53D1\u9001 HTTP \u8BF7\u6C42\u7684\u5E93\uFF0C\u5B83\u975E\u5E38\u5F3A\u5927\u4E14\u6613\u4E8E\u4F7F\u7528\uFF0C\u53EF\u4EE5\u7528\u6765\u4ECE\u7F51\u9875\u83B7\u53D6\u6570\u636E\u3002</p></li><li><p><strong>tiktoken</strong>: \u8FD9\u662F\u4E00\u4E2A\u7528\u4E8E\u81EA\u7136\u8BED\u8A00\u5904\u7406\u7684\u5E93\uFF0C\u5B83\u63D0\u4F9B\u4E86\u591A\u79CD\u6A21\u578B\u7684\u7F16\u7801\u5668\u548C\u89E3\u7801\u5668\uFF0C\u7528\u4E8E\u5C06\u6587\u672C\u8F6C\u6362\u4E3A\u6A21\u578B\u53EF\u4EE5\u7406\u89E3\u7684\u683C\u5F0F\u3002</p></li><li><p><strong>numpy</strong>: \u8FD9\u662F\u4E00\u4E2A\u7528\u4E8E\u79D1\u5B66\u8BA1\u7B97\u7684\u5E93\uFF0C\u5B83\u63D0\u4F9B\u4E86\u591A\u7EF4\u6570\u7EC4\u5BF9\u8C61\u3001\u6D3E\u751F\u5BF9\u8C61\uFF08\u5982\u63A9\u7801\u6570\u7EC4\u548C\u77E9\u9635\uFF09\u4EE5\u53CA\u7528\u4E8E\u5FEB\u901F\u64CD\u4F5C\u6570\u7EC4\u7684\u5404\u79CD\u4F8B\u7A0B\uFF0C\u5305\u62EC\u6570\u5B66\u3001\u903B\u8F91\u3001\u5F62\u72B6\u64CD\u4F5C\u3001\u6392\u5E8F\u3001\u9009\u62E9\u3001I/O\u3001\u79BB\u6563\u5085\u7ACB\u53F6\u53D8\u6362\u3001\u57FA\u672C\u7EBF\u6027\u4EE3\u6570\u3001\u57FA\u672C\u7EDF\u8BA1\u8FD0\u7B97\u3001\u968F\u673A\u6A21\u62DF\u7B49\u7B49\u3002</p></li></ol><p>\u8FD9\u4E9B\u5E93\u5728 Python \u4E2D\u975E\u5E38\u6D41\u884C\uFF0C\u5E76\u4E14\u5B83\u4EEC\u4E4B\u95F4\u53EF\u4EE5\u534F\u540C\u5DE5\u4F5C\uFF0C\u4EE5\u5B8C\u6210\u590D\u6742\u7684\u4EFB\u52A1\u3002\u4F8B\u5982\uFF0C\u4F60\u53EF\u4EE5\u4F7F\u7528 <code>requests</code> \u83B7\u53D6\u7F51\u7EDC\u6570\u636E\uFF0C\u7136\u540E\u4F7F\u7528 <code>numpy</code> \u8FDB\u884C\u6570\u636E\u5904\u7406\uFF0C\u63A5\u7740\u4F7F\u7528 <code>tiktoken</code> \u5BF9\u6570\u636E\u8FDB\u884C\u7F16\u7801\uFF0C\u6700\u540E\u4F7F\u7528 <code>os</code> \u6765\u5904\u7406\u6587\u4EF6\u8DEF\u5F84\u548C\u4FDD\u5B58\u6570\u636E\u3002</p><p>\u5982\u679C\u4F60\u9700\u8981\u8FDB\u4E00\u6B65\u7684\u5E2E\u52A9\uFF0C\u4F8B\u5982\u5982\u4F55\u4F7F\u7528\u8FD9\u4E9B\u5E93\u4E2D\u7684\u7279\u5B9A\u529F\u80FD\uFF0C\u6216\u8005\u5982\u4F55\u5C06\u5B83\u4EEC\u7ED3\u5408\u4F7F\u7528\u6765\u89E3\u51B3\u7279\u5B9A\u7684\u95EE\u9898\uFF0C\u8BF7\u968F\u65F6\u63D0\u95EE\u3002</p><p>User: import torch import torch.nn as nn import math from torch.nn import functional as F import inspect</p><p>Kimi: \u4F60\u5217\u51FA\u7684\u8FD9\u4E9B Python \u5E93\u548C\u6A21\u5757\u4E3B\u8981\u7528\u4E8E\u6DF1\u5EA6\u5B66\u4E60\u9886\u57DF\uFF0C\u7279\u522B\u662F\u4F7F\u7528 PyTorch \u6846\u67B6\u3002\u4E0B\u9762\u662F\u6BCF\u4E2A\u7EC4\u4EF6\u7684\u7B80\u8981\u8BF4\u660E\uFF1A</p><ol><li><p><strong>torch</strong>: \u8FD9\u662F PyTorch \u7684\u6838\u5FC3\u5E93\uFF0C\u63D0\u4F9B\u4E86\u5F20\u91CF\uFF08Tensor\uFF09\u5BF9\u8C61\u3001\u81EA\u52A8\u5FAE\u5206\u7CFB\u7EDF autograd\u3001\u4EE5\u53CA\u7528\u4E8E\u6784\u5EFA\u548C\u8BAD\u7EC3\u795E\u7ECF\u7F51\u7EDC\u7684\u5DE5\u5177\u3002</p></li><li><p><strong>torch.nn</strong>: \u8FD9\u4E2A\u6A21\u5757\u5305\u542B\u4E86\u6784\u5EFA\u795E\u7ECF\u7F51\u7EDC\u6240\u9700\u7684\u6240\u6709\u57FA\u7840\u6784\u4EF6\uFF0C\u4F8B\u5982\u5C42\uFF08Layer\uFF09\u3001\u635F\u5931\u51FD\u6570\u3001\u4F18\u5316\u5668\u7B49\u3002</p></li><li><p><strong>math</strong>: \u8FD9\u662F\u4E00\u4E2A Python \u6807\u51C6\u5E93\uFF0C\u63D0\u4F9B\u4E86\u8BB8\u591A\u6570\u5B66\u8FD0\u7B97\u51FD\u6570\uFF0C\u5982\u4E09\u89D2\u51FD\u6570\u3001\u6307\u6570\u3001\u5BF9\u6570\u7B49\u3002</p></li><li><p><strong>torch.nn.functional</strong>: \u8FD9\u4E2A\u6A21\u5757\u63D0\u4F9B\u4E86\u4E00\u4E9B\u51FD\u6570\u5F0F\u7684\u63A5\u53E3\uFF0C\u7528\u4E8E\u5728\u795E\u7ECF\u7F51\u7EDC\u6784\u5EFA\u4E2D\u8FDB\u884C\u64CD\u4F5C\uFF0C\u4F8B\u5982\u6FC0\u6D3B\u51FD\u6570\uFF08ReLU\uFF09\u3001\u635F\u5931\u51FD\u6570\uFF08cross_entropy\uFF09\u3001\u5377\u79EF\u51FD\u6570\uFF08conv2d\uFF09\u7B49\u3002</p></li><li><p><strong>inspect</strong>: \u8FD9\u662F Python \u7684\u4E00\u4E2A\u6807\u51C6\u5E93\uFF0C\u7528\u4E8E\u83B7\u53D6\u5B9E\u65F6\u7684\u5BF9\u8C61\u4FE1\u606F\uFF0C\u5305\u62EC\u6A21\u5757\u3001\u7C7B\u3001\u65B9\u6CD5\u3001\u51FD\u6570\u3001\u8FFD\u8E2A\u6808\u7B49\u3002\u5728\u6DF1\u5EA6\u5B66\u4E60\u4E2D\uFF0C<code>inspect</code> \u53EF\u4EE5\u7528\u6765\u68C0\u67E5\u51FD\u6570\u7684\u53C2\u6570\u7B49\u3002</p></li></ol><p>\u8FD9\u4E9B\u7EC4\u4EF6\u5171\u540C\u6784\u6210\u4E86\u4F7F\u7528 PyTorch \u8FDB\u884C\u6DF1\u5EA6\u5B66\u4E60\u7684\u57FA\u7840\u3002\u4F8B\u5982\uFF0C\u4F60\u53EF\u4EE5\u4F7F\u7528 <code>torch</code> \u6765\u521B\u5EFA\u548C\u64CD\u4F5C\u5F20\u91CF\uFF0C\u4F7F\u7528 <code>torch.nn</code> \u6765\u5B9A\u4E49\u6A21\u578B\u7684\u5C42\u548C\u7F51\u7EDC\u7ED3\u6784\uFF0C\u4F7F\u7528 <code>torch.nn.functional</code> \u6765\u8FDB\u884C\u524D\u5411\u4F20\u64AD\u548C\u8BA1\u7B97\u635F\u5931\uFF0C\u4F7F\u7528 <code>math</code> \u6765\u8FDB\u884C\u4E00\u4E9B\u6570\u5B66\u8FD0\u7B97\uFF0C\u4EE5\u53CA\u4F7F\u7528 <code>inspect</code> \u6765\u68C0\u67E5\u4EE3\u7801\u6216\u8C03\u8BD5\u3002</p><p>\u5982\u679C\u4F60\u9700\u8981\u5177\u4F53\u7684\u5E2E\u52A9\uFF0C\u6BD4\u5982\u5982\u4F55\u5728 PyTorch \u4E2D\u5B9A\u4E49\u4E00\u4E2A\u6A21\u578B\uFF0C\u6216\u8005\u5982\u4F55\u4F7F\u7528\u8FD9\u4E9B\u6A21\u5757\u6765\u6267\u884C\u7279\u5B9A\u7684\u64CD\u4F5C\uFF0C\u8BF7\u968F\u65F6\u63D0\u95EE\u3002\u5982\u679C\u4F60\u8FD8\u6CA1\u6709\u5B89\u88C5 PyTorch\uFF0C\u53EF\u4EE5\u4F7F\u7528 pip \u6765\u5B89\u88C5\uFF1A</p><div class="language-sh line-numbers-mode"><button class="copy"></button><span class="lang">sh</span><pre><code><span class="line"><span style="color:#B392F0;">pip install torch</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>\u8BF7\u6CE8\u610F\uFF0CPyTorch \u7684\u5B89\u88C5\u53EF\u80FD\u4F9D\u8D56\u4E8E\u4F60\u7684\u7CFB\u7EDF\u914D\u7F6E\u548C CUDA \u7248\u672C\uFF0C\u6240\u4EE5\u5B89\u88C5\u547D\u4EE4\u53EF\u80FD\u4F1A\u6709\u6240\u4E0D\u540C\u3002\u4F60\u53EF\u4EE5\u8BBF\u95EE PyTorch \u7684\u5B98\u65B9\u7F51\u7AD9\u6765\u83B7\u53D6\u9002\u5408\u4F60\u7CFB\u7EDF\u7684\u5B89\u88C5\u6307\u4EE4\u3002</p><p>User: # \u6A21\u578B\u53C2\u6570 from dataclasses import dataclass @dataclass class Model_args: block_size: int = 1024 # \u4F20\u5165\u7684\u6700\u5927\u5927\u5C0F vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency n_layer: int = 12 n_head: int = 12 n_embed: int = 768 dropout: float = 0.0 # \u9ED8\u8BA4\u4E0D dropout bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster</p><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u5B9A\u4E49\u4E86\u4E00\u4E2A\u540D\u4E3A <code>Model_args</code> \u7684\u6570\u636E\u7C7B\uFF0C\u7528\u4E8E\u5B58\u50A8\u795E\u7ECF\u7F51\u7EDC\u6A21\u578B\u7684\u53C2\u6570\u3002\u6570\u636E\u7C7B\u662F Python 3.7 \u53CA\u4EE5\u540E\u7248\u672C\u4E2D\u5F15\u5165\u7684\u4E00\u79CD\u65B0\u7684\u9762\u5411\u5BF9\u8C61\u7F16\u7A0B\u7279\u6027\uFF0C\u5B83\u63D0\u4F9B\u4E86\u4E00\u79CD\u65B9\u4FBF\u7684\u65B9\u5F0F\u6765\u5B9A\u4E49\u53EA\u5305\u542B\u6570\u636E\u7684\u7C7B\u3002</p><p>\u4E0B\u9762\u662F <code>Model_args</code> \u6570\u636E\u7C7B\u4E2D\u5404\u4E2A\u5B57\u6BB5\u7684\u89E3\u91CA\uFF1A</p><ul><li><p><code>block_size: int = 1024</code>: \u8FD9\u4E2A\u53C2\u6570\u6307\u5B9A\u4E86\u6A21\u578B\u4E00\u6B21\u5904\u7406\u7684\u6700\u5927\u8F93\u5165\u5927\u5C0F\u3002\u5728\u67D0\u4E9B\u6A21\u578B\u4E2D\uFF0C\u5982 Transformer \u6A21\u578B\uFF0C\u8FD9\u4E2A\u503C\u901A\u5E38\u5BF9\u5E94\u4E8E\u5E8F\u5217\u7684\u6700\u5927\u957F\u5EA6\u3002</p></li><li><p><code>vocab_size: int = 50304</code>: \u8BCD\u6C47\u8868\u7684\u5927\u5C0F\uFF0C\u5373\u6A21\u578B\u80FD\u591F\u7406\u89E3\u7684\u4E0D\u540C\u8BCD\u6C47\u7684\u603B\u6570\u3002\u8FD9\u91CC\u63D0\u5230\u7684 &quot;GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency&quot; \u610F\u5473\u7740\u539F\u59CB\u7684 GPT-2 \u6A21\u578B\u6709 50257 \u4E2A\u8BCD\u6C47\uFF0C\u4F46\u4E3A\u4E86\u8BA1\u7B97\u6548\u7387\uFF0C\u8FD9\u91CC\u5C06\u5176\u6269\u5C55\u5230\u6700\u63A5\u8FD1\u7684 64 \u7684\u500D\u6570\uFF0C\u5373 50304\u3002</p></li><li><p><code>n_layer: int = 12</code>: \u6A21\u578B\u4E2D\u7684\u5C42\u6570\u3002\u5728 Transformer \u67B6\u6784\u4E2D\uFF0C\u8FD9\u901A\u5E38\u6307\u7684\u662F\u6CE8\u610F\u529B\u5C42\u7684\u6570\u91CF\u3002</p></li><li><p><code>n_head: int = 12</code>: \u6BCF\u4E2A\u6CE8\u610F\u529B\u5C42\u4E2D\u7684\u5934\u6570\u3002\u591A\u5934\u6CE8\u610F\u529B\u5141\u8BB8\u6A21\u578B\u540C\u65F6\u4ECE\u4E0D\u540C\u7684\u8868\u793A\u5B50\u7A7A\u95F4\u4E2D\u5B66\u4E60\u3002</p></li><li><p><code>n_embed: int = 768</code>: \u5D4C\u5165\u5C42\u7684\u7EF4\u5EA6\u5927\u5C0F\u3002\u5728 Transformer \u6A21\u578B\u4E2D\uFF0C\u8FD9\u901A\u5E38\u662F\u6A21\u578B\u9690\u85CF\u5C42\u7684\u7EF4\u5EA6\u3002</p></li><li><p><code>dropout: float = 0.0</code>: dropout \u7387\uFF0C\u7528\u4E8E\u6B63\u5219\u5316\u4EE5\u9632\u6B62\u8FC7\u62DF\u5408\u3002\u8FD9\u91CC\u7684\u9ED8\u8BA4\u503C\u662F 0.0\uFF0C\u610F\u5473\u7740\u4E0D\u4F7F\u7528 dropout\u3002</p></li><li><p><code>bias: bool = True</code>: \u662F\u5426\u5728\u6A21\u578B\u7684\u7EBF\u6027\u5C42\u548C\u5C42\u5F52\u4E00\u5316\uFF08LayerNorm\uFF09\u4E2D\u4F7F\u7528\u504F\u7F6E\u3002GPT-2 \u6A21\u578B\u4E2D\u4F7F\u7528\u4E86\u504F\u7F6E\uFF0C\u4F46\u6709\u65F6\u5019\u53BB\u6389\u504F\u7F6E\u53EF\u4EE5\u63D0\u9AD8\u6027\u80FD\u5E76\u52A0\u5FEB\u8BA1\u7B97\u901F\u5EA6\u3002</p></li></ul><p>\u4F7F\u7528 <code>@dataclass</code> \u88C5\u9970\u5668\u53EF\u4EE5\u81EA\u52A8\u4E3A\u7C7B\u751F\u6210\u7279\u6B8A\u7684\u65B9\u6CD5\uFF0C\u5982 <code>__init__()</code> \u548C <code>__repr__()</code>\uFF0C\u8FD9\u6837\u4F60\u5C31\u4E0D\u9700\u8981\u624B\u52A8\u7F16\u5199\u8FD9\u4E9B\u65B9\u6CD5\u3002\u8FD9\u4F7F\u5F97\u5B9A\u4E49\u53EA\u5305\u542B\u6570\u636E\u7684\u7C7B\u53D8\u5F97\u66F4\u52A0\u7B80\u6D01\u548C\u65B9\u4FBF\u3002</p><p>\u5982\u679C\u4F60\u60F3\u4F7F\u7528\u8FD9\u4E2A <code>Model_args</code> \u7C7B\uFF0C\u53EF\u4EE5\u8FD9\u6837\u521B\u5EFA\u4E00\u4E2A\u5B9E\u4F8B\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#B392F0;">model_args </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> Model_args</span><span style="color:#BBBBBB;">(block_size</span><span style="color:#F97583;">=</span><span style="color:#F8F8F8;">512</span><span style="color:#BBBBBB;">, vocab_size</span><span style="color:#F97583;">=</span><span style="color:#F8F8F8;">10000</span><span style="color:#BBBBBB;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>\u5728\u8FD9\u4E2A\u4F8B\u5B50\u4E2D\uFF0C\u6211\u4EEC\u521B\u5EFA\u4E86\u4E00\u4E2A <code>Model_args</code> \u7684\u5B9E\u4F8B\uFF0C\u5176\u4E2D <code>block_size</code> \u548C <code>vocab_size</code> \u88AB\u8D4B\u4E88\u4E86\u65B0\u7684\u503C\uFF0C\u800C\u5176\u4ED6\u53C2\u6570\u5219\u4FDD\u6301\u4E86\u9ED8\u8BA4\u503C\u3002</p><p>User: \u6CE8\u610F\u529B\u5C42</p><p>Kimi: \u6CE8\u610F\u529B\u5C42\u662F\u6DF1\u5EA6\u5B66\u4E60\u4E2D\u7684\u4E00\u79CD\u673A\u5236\uFF0C\u7279\u522B\u662F\u5728\u5E8F\u5217\u5904\u7406\u6A21\u578B\u5982 Transformer \u4E2D\u53D1\u6325\u7740\u6838\u5FC3\u4F5C\u7528\u3002\u6CE8\u610F\u529B\u5C42\u5141\u8BB8\u6A21\u578B\u5728\u5904\u7406\u5E8F\u5217\u65F6\uFF0C\u80FD\u591F\u805A\u7126\u4E8E\u5E8F\u5217\u4E2D\u4E0E\u5F53\u524D\u5904\u7406\u4F4D\u7F6E\u6700\u76F8\u5173\u7684\u90E8\u5206\u3002\u8FD9\u79CD\u673A\u5236\u4F7F\u5F97\u6A21\u578B\u80FD\u591F\u6355\u6349\u5230\u957F\u8DDD\u79BB\u7684\u4F9D\u8D56\u5173\u7CFB\uFF0C\u5E76\u4E14\u63D0\u9AD8\u4E86\u6A21\u578B\u5BF9\u5E8F\u5217\u6570\u636E\u7684\u7406\u89E3\u80FD\u529B\u3002</p><p>\u6CE8\u610F\u529B\u5C42\u901A\u5E38\u5305\u542B\u4EE5\u4E0B\u51E0\u4E2A\u5173\u952E\u6982\u5FF5\uFF1A</p><ol><li><p><strong>Query\uFF08Q\uFF09</strong>\uFF1A\u5F53\u524D\u5904\u7406\u7684\u5143\u7D20\u6216\u4F4D\u7F6E\u7684\u8868\u793A\uFF0C\u7528\u4E8E\u4E0E\u5176\u5B83\u5143\u7D20\u8FDB\u884C\u6BD4\u8F83\u3002</p></li><li><p><strong>Key\uFF08K\uFF09</strong>\uFF1A\u5E8F\u5217\u4E2D\u6240\u6709\u5143\u7D20\u7684\u8868\u793A\uFF0C\u7528\u4E8E\u4E0E Query \u8FDB\u884C\u5339\u914D\u3002</p></li><li><p><strong>Value\uFF08V\uFF09</strong>\uFF1A\u5E8F\u5217\u4E2D\u6240\u6709\u5143\u7D20\u7684\u8868\u793A\uFF0C\u7528\u4E8E\u5728\u5339\u914D\u6210\u529F\u540E\uFF0C\u6839\u636E\u5339\u914D\u7A0B\u5EA6\u5BF9\u5143\u7D20\u8FDB\u884C\u52A0\u6743\u3002</p></li><li><p><strong>\u6CE8\u610F\u529B\u5206\u6570\uFF08Attention Score\uFF09</strong>\uFF1A\u901A\u8FC7\u8BA1\u7B97 Query \u4E0E Key \u4E4B\u95F4\u7684\u76F8\u4F3C\u5EA6\u5F97\u5230\uFF0C\u901A\u5E38\u4F7F\u7528\u70B9\u79EF\uFF08dot product\uFF09\u6216\u7F29\u653E\u70B9\u79EF\uFF08scaled dot product\uFF09\u6765\u8BA1\u7B97\u3002</p></li><li><p><strong>\u6CE8\u610F\u529B\u6743\u91CD\uFF08Attention Weights\uFF09</strong>\uFF1A\u901A\u8FC7 softmax \u51FD\u6570\u5BF9\u6CE8\u610F\u529B\u5206\u6570\u8FDB\u884C\u5F52\u4E00\u5316\u5904\u7406\uFF0C\u786E\u4FDD\u6240\u6709\u6743\u91CD\u7684\u548C\u4E3A 1\u3002</p></li><li><p><strong>\u52A0\u6743\u548C\uFF08Weighted Sum\uFF09</strong>\uFF1A\u5C06\u6CE8\u610F\u529B\u6743\u91CD\u4E0E\u5BF9\u5E94\u7684 Value \u76F8\u4E58\uFF0C\u5E76\u6C42\u548C\uFF0C\u5F97\u5230\u6700\u7EC8\u7684\u8F93\u51FA\u3002</p></li><li><p><strong>\u591A\u5934\u6CE8\u610F\u529B\uFF08Multi-Head Attention\uFF09</strong>\uFF1A\u5C06\u4E0A\u8FF0\u8FC7\u7A0B\u590D\u5236\u591A\u6B21\uFF0C\u6BCF\u4E2A\u201C\u5934\u201D\u5B66\u4E60\u5230\u4E0D\u540C\u7684\u8868\u793A\u5B50\u7A7A\u95F4\uFF0C\u7136\u540E\u5C06\u8FD9\u4E9B\u8868\u793A\u5408\u5E76\uFF0C\u4EE5\u6355\u83B7\u4E0D\u540C\u65B9\u9762\u7684\u4FE1\u606F\u3002</p></li></ol><p>\u5728 Transformer \u6A21\u578B\u4E2D\uFF0C\u6CE8\u610F\u529B\u5C42\u901A\u5E38\u5206\u4E3A\u4E24\u79CD\u7C7B\u578B\uFF1A</p><ul><li><p><strong>\u81EA\u6CE8\u610F\u529B\uFF08Self-Attention\uFF09</strong>\uFF1AQuery\u3001Key \u548C Value \u90FD\u6765\u81EA\u540C\u4E00\u5E8F\u5217\uFF0C\u8FD9\u79CD\u6CE8\u610F\u529B\u673A\u5236\u5141\u8BB8\u6A21\u578B\u5728\u5E8F\u5217\u5185\u90E8\u8FDB\u884C\u4FE1\u606F\u7684\u4EA4\u4E92\u3002</p></li><li><p><strong>\u7F16\u7801\u5668-\u89E3\u7801\u5668\u6CE8\u610F\u529B\uFF08Encoder-Decoder Attention\uFF09</strong>\uFF1AQuery \u6765\u81EA\u89E3\u7801\u5668\u7684\u4E0A\u4E00\u5C42\uFF0C\u800C Key \u548C Value \u6765\u81EA\u7F16\u7801\u5668\u7684\u8F93\u51FA\u3002\u8FD9\u79CD\u6CE8\u610F\u529B\u673A\u5236\u5141\u8BB8\u6A21\u578B\u5728\u7F16\u7801\u5668\u7684\u8F93\u51FA\u4E0A\u8FDB\u884C\u805A\u7126\uFF0C\u4EE5\u751F\u6210\u5E8F\u5217\u7684\u4E0B\u4E00\u4E2A\u5143\u7D20\u3002</p></li></ul><p>\u6CE8\u610F\u529B\u5C42\u7684\u5F15\u5165\u6781\u5927\u5730\u63A8\u52A8\u4E86\u81EA\u7136\u8BED\u8A00\u5904\u7406\u9886\u57DF\u7684\u53D1\u5C55\uFF0C\u7279\u522B\u662F\u5728\u673A\u5668\u7FFB\u8BD1\u3001\u6587\u672C\u6458\u8981\u3001\u95EE\u7B54\u7CFB\u7EDF\u7B49\u4EFB\u52A1\u4E2D\u8868\u73B0\u51FA\u8272\u3002</p><p>User: \u504F\u7F6E</p><p>Kimi: \u5728\u795E\u7ECF\u7F51\u7EDC\u4E2D\uFF0C&quot;\u504F\u7F6E&quot;\uFF08Bias\uFF09\u662F\u4E00\u4E2A\u91CD\u8981\u7684\u6982\u5FF5\uFF0C\u5B83\u7528\u4E8E\u63D0\u4F9B\u989D\u5916\u7684\u81EA\u7531\u5EA6\uFF0C\u5E2E\u52A9\u6A21\u578B\u66F4\u597D\u5730\u62DF\u5408\u6570\u636E\u3002\u4EE5\u4E0B\u662F\u5173\u4E8E\u504F\u7F6E\u7684\u4E00\u4E9B\u5173\u952E\u70B9\uFF1A</p><ol><li><p><strong>\u5B9A\u4E49</strong>\uFF1A\u504F\u7F6E\u662F\u4E00\u4E2A\u6807\u91CF\u503C\uFF0C\u6DFB\u52A0\u5230\u795E\u7ECF\u7F51\u7EDC\u7684\u6BCF\u4E2A\u8F93\u51FA\u4E0A\uFF0C\u53EF\u4EE5\u770B\u4F5C\u662F\u8BE5\u5C42\u8F93\u51FA\u7684&quot;\u5E73\u79FB&quot;\u3002</p></li><li><p><strong>\u4F5C\u7528</strong>\uFF1A</p><ul><li><strong>\u589E\u52A0\u7075\u6D3B\u6027</strong>\uFF1A\u504F\u7F6E\u5141\u8BB8\u6BCF\u4E00\u5C42\u7684\u8F93\u51FA\u5728\u4E0D\u540C\u7684\u8F93\u5165\u4E0B\u6709\u4E0D\u540C\u7684\u57FA\u7EBF\uFF0C\u589E\u52A0\u4E86\u6A21\u578B\u7684\u7075\u6D3B\u6027\u3002</li><li><strong>\u6539\u5584\u5B66\u4E60</strong>\uFF1A\u5728\u67D0\u4E9B\u60C5\u51B5\u4E0B\uFF0C\u504F\u7F6E\u6709\u52A9\u4E8E\u6A21\u578B\u66F4\u5FEB\u5730\u6536\u655B\u5230\u6700\u4F18\u89E3\u3002</li><li><strong>\u907F\u514D\u5BF9\u79F0\u6027\u95EE\u9898</strong>\uFF1A\u5728\u67D0\u4E9B\u7F51\u7EDC\u7ED3\u6784\u4E2D\uFF0C\u504F\u7F6E\u53EF\u4EE5\u9632\u6B62\u5BF9\u79F0\u6027\u95EE\u9898\uFF0C\u786E\u4FDD\u4E0D\u540C\u7684\u795E\u7ECF\u5143\u53EF\u4EE5\u5B66\u4E60\u5230\u4E0D\u540C\u7684\u7279\u5F81\u3002</li></ul></li><li><p><strong>\u5B9E\u73B0</strong>\uFF1A\u5728\u6BCF\u4E00\u5C42\u7684\u8F93\u51FA\u8BA1\u7B97\u4E2D\uFF0C\u504F\u7F6E\u901A\u5E38\u4E0E\u6743\u91CD\u77E9\u9635\u7684\u8F93\u51FA\u76F8\u52A0\u3002\u4F8B\u5982\uFF0C\u5728\u5168\u8FDE\u63A5\u5C42\u4E2D\uFF0C\u8F93\u51FA\u8BA1\u7B97\u516C\u5F0F\u4E3A\uFF1A [ \\text{output} = \\mathbf{W} \\times \\mathbf{x} + b ] \u5176\u4E2D\uFF0C( \\mathbf{W} ) \u662F\u6743\u91CD\u77E9\u9635\uFF0C( \\mathbf{x} ) \u662F\u8F93\u5165\uFF0C( b ) \u662F\u504F\u7F6E\u5411\u91CF\u3002</p></li><li><p><strong>\u6743\u91CD\u4E0E\u504F\u7F6E\u7684\u5173\u7CFB</strong>\uFF1A\u6743\u91CD\u51B3\u5B9A\u4E86\u8F93\u5165\u7279\u5F81\u4E0E\u8F93\u51FA\u4E4B\u95F4\u7684\u5173\u7CFB\uFF0C\u800C\u504F\u7F6E\u5219\u63D0\u4F9B\u4E86\u4E00\u4E2A\u989D\u5916\u7684\u8C03\u6574\u56E0\u5B50\u3002</p></li><li><p><strong>\u8BAD\u7EC3</strong>\uFF1A\u5728\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\uFF0C\u504F\u7F6E\u548C\u6743\u91CD\u4E00\u6837\uFF0C\u4F1A\u901A\u8FC7\u53CD\u5411\u4F20\u64AD\u7B97\u6CD5\u8FDB\u884C\u66F4\u65B0\uFF0C\u4EE5\u6700\u5C0F\u5316\u635F\u5931\u51FD\u6570\u3002</p></li><li><p><strong>\u9009\u62E9\u4F7F\u7528</strong>\uFF1A\u5728\u67D0\u4E9B\u60C5\u51B5\u4E0B\uFF0C\u4E3A\u4E86\u7B80\u5316\u6A21\u578B\u6216\u63D0\u9AD8\u6027\u80FD\uFF0C\u53EF\u4EE5\u9009\u62E9\u4E0D\u4F7F\u7528\u504F\u7F6E\u3002\u4F8B\u5982\uFF0C\u5728\u67D0\u4E9B\u53D8\u4F53\u7684 Transformer \u6A21\u578B\u4E2D\uFF0C\u5C42\u5F52\u4E00\u5316\uFF08Layer Normalization\uFF09\u53EF\u4EE5\u66FF\u4EE3\u504F\u7F6E\u7684\u4F5C\u7528\u3002</p></li><li><p><strong>\u5728\u4E0D\u540C\u5C42\u4E2D\u7684\u5E94\u7528</strong>\uFF1A</p><ul><li><strong>\u5168\u8FDE\u63A5\u5C42</strong>\uFF1A\u5728\u5168\u8FDE\u63A5\u5C42\u4E2D\uFF0C\u504F\u7F6E\u901A\u5E38\u662F\u5FC5\u987B\u7684\uFF0C\u4EE5\u63D0\u4F9B\u989D\u5916\u7684\u81EA\u7531\u5EA6\u3002</li><li><strong>\u5377\u79EF\u5C42</strong>\uFF1A\u5728\u5377\u79EF\u5C42\u4E2D\uFF0C\u504F\u7F6E\u4E5F\u53EF\u4EE5\u63D0\u4F9B\u989D\u5916\u7684\u7075\u6D3B\u6027\uFF0C\u4F46\u5728\u67D0\u4E9B\u60C5\u51B5\u4E0B\uFF0C\u53EF\u4EE5\u901A\u8FC7\u8C03\u6574\u6FC0\u6D3B\u51FD\u6570\u6765\u66FF\u4EE3\u504F\u7F6E\u3002</li><li><strong>\u6CE8\u610F\u529B\u5C42</strong>\uFF1A\u5728\u6CE8\u610F\u529B\u5C42\u4E2D\uFF0C\u504F\u7F6E\u901A\u5E38\u7528\u4E8E\u8C03\u6574\u6CE8\u610F\u529B\u5206\u6570\uFF0C\u4EE5\u5F71\u54CD\u6CE8\u610F\u529B\u6743\u91CD\u7684\u5206\u5E03\u3002</li></ul></li><li><p><strong>\u5F71\u54CD</strong>\uFF1A\u504F\u7F6E\u7684\u5927\u5C0F\u548C\u66F4\u65B0\u65B9\u5F0F\u53EF\u4EE5\u5F71\u54CD\u6A21\u578B\u7684\u6027\u80FD\u548C\u6536\u655B\u901F\u5EA6\u3002\u5408\u7406\u7684\u521D\u59CB\u5316\u548C\u8C03\u6574\u504F\u7F6E\u662F\u6A21\u578B\u8C03\u4F18\u7684\u4E00\u90E8\u5206\u3002</p></li></ol><p>\u603B\u7684\u6765\u8BF4\uFF0C\u504F\u7F6E\u662F\u795E\u7ECF\u7F51\u7EDC\u4E2D\u4E00\u4E2A\u91CD\u8981\u7684\u7EC4\u6210\u90E8\u5206\uFF0C\u5B83\u63D0\u4F9B\u4E86\u989D\u5916\u7684\u81EA\u7531\u5EA6\uFF0C\u5E2E\u52A9\u6A21\u578B\u66F4\u597D\u5730\u62DF\u5408\u6570\u636E\u548C\u5B66\u4E60\u7279\u5F81\u3002\u7136\u800C\uFF0C\u662F\u5426\u4F7F\u7528\u504F\u7F6E\u4EE5\u53CA\u5982\u4F55\u8C03\u6574\u504F\u7F6E\uFF0C\u9700\u8981\u6839\u636E\u5177\u4F53\u7684\u6A21\u578B\u7ED3\u6784\u548C\u4EFB\u52A1\u9700\u6C42\u6765\u51B3\u5B9A\u3002</p><p>User: class RMS_Norm(nn.Module): # \u53C2\u8003 llama \u4F7F\u7528 RMS Norm def <strong>init</strong>(self,hidden_size,eps=1e-6): super().<strong>init</strong>() self.weight = nn.Parameter(torch.ones(hidden_size)) self.eps = eps # \u5F15\u5165 eps \u907F\u514D\u5206\u6BCD\u4E3A 0</p><pre><code>def forward(self,hidden_states):
    input_dtype = hidden_states.dtype
    hidden_states = hidden_states.to(torch.float32)
    sqrt_pow_mean = torch.sqrt(hidden_states.pow(2).mean(-1, keepdim = True))
    # \u8FD9\u91CC\u8BA1\u7B97L2\u8303\u5F0F/n\u540E\u5F00\u6839\uFF0C\u8BE6\u89C1RMS Norm\u7684\u5B9A\u4E49
    return self.weight * hidden_states/(sqrt_pow_mean+self.eps)
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u5B9A\u4E49\u4E86\u4E00\u4E2A\u540D\u4E3A <code>RMS_Norm</code> \u7684\u7C7B\uFF0C\u5B83\u662F\u4E00\u4E2A PyTorch \u7684 <code>nn.Module</code> \u7684\u5B50\u7C7B\uFF0C\u5B9E\u73B0\u4E86\u4E00\u79CD\u79F0\u4E3A RMS\uFF08Root Mean Square\uFF09Norm \u7684\u5F52\u4E00\u5316\u65B9\u6CD5\u3002RMS Norm \u662F\u4E00\u79CD\u81EA\u5F52\u4E00\u5316\u673A\u5236\uFF0C\u901A\u5E38\u7528\u4E8E\u6539\u5584\u6DF1\u5EA6\u5B66\u4E60\u6A21\u578B\u7684\u8BAD\u7EC3\u8FC7\u7A0B\u3002</p><p>\u4EE5\u4E0B\u662F\u4EE3\u7801\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ol><li><p><code>__init__(self, hidden_size, eps=1e-6)</code>: \u8FD9\u662F <code>RMS_Norm</code> \u7C7B\u7684\u6784\u9020\u51FD\u6570\u3002</p><ul><li><code>hidden_size</code>: \u8868\u793A\u8F93\u5165\u7279\u5F81\u7684\u7EF4\u5EA6\u3002</li><li><code>eps</code>: \u662F\u4E00\u4E2A\u5C0F\u7684\u5E38\u6570\uFF0C\u7528\u4E8E\u6570\u503C\u7A33\u5B9A\u6027\uFF0C\u9632\u6B62\u9664\u4EE5\u96F6\u3002</li></ul></li><li><p><code>self.weight = nn.Parameter(torch.ones(hidden_size))</code>: \u5B9A\u4E49\u4E86\u4E00\u4E2A\u53EF\u5B66\u4E60\u7684\u53C2\u6570 <code>weight</code>\uFF0C\u5B83\u662F\u4E00\u4E2A\u957F\u5EA6\u4E3A <code>hidden_size</code> \u7684\u5411\u91CF\uFF0C\u521D\u59CB\u503C\u4E3A 1\u3002\u8FD9\u4E2A\u53C2\u6570\u5C06\u5728\u6A21\u578B\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\u66F4\u65B0\u3002</p></li><li><p><code>self.eps</code>: \u5B58\u50A8\u4E86\u4F20\u5165\u7684 <code>eps</code> \u503C\uFF0C\u7528\u4E8E\u63D0\u4F9B\u6570\u503C\u7A33\u5B9A\u6027\u3002</p></li><li><p><code>forward(self, hidden_states)</code>: \u5B9A\u4E49\u4E86 <code>RMS_Norm</code> \u7684\u524D\u5411\u4F20\u64AD\u903B\u8F91\u3002</p><ul><li><code>input_dtype</code>: \u5B58\u50A8\u4E86\u8F93\u5165 <code>hidden_states</code> \u7684\u6570\u636E\u7C7B\u578B\uFF0C\u4EE5\u4FBF\u5728\u5F52\u4E00\u5316\u540E\u53EF\u4EE5\u5C06\u5176\u8F6C\u6362\u56DE\u539F\u59CB\u6570\u636E\u7C7B\u578B\u3002</li><li><code>hidden_states.to(torch.float32)</code>: \u5C06 <code>hidden_states</code> \u8F6C\u6362\u4E3A <code>float32</code> \u7C7B\u578B\uFF0C\u4EE5\u4FBF\u8FDB\u884C\u540E\u7EED\u7684\u6570\u5B66\u8FD0\u7B97\u3002</li><li><code>sqrt_pow_mean = torch.sqrt(hidden_states.pow(2).mean(-1, keepdim=True))</code>: \u8BA1\u7B97 <code>hidden_states</code> \u7684\u6BCF\u4E2A\u5143\u7D20\u7684\u5E73\u65B9\u7684\u5E73\u5747\u503C\u7684\u5E73\u65B9\u6839\u3002\u8FD9\u91CC <code>pow(2)</code> \u8BA1\u7B97\u5E73\u65B9\uFF0C<code>mean(-1, keepdim=True)</code> \u8BA1\u7B97\u6700\u540E\u4E00\u4E2A\u7EF4\u5EA6\u7684\u5E73\u5747\u503C\uFF0C\u5E76\u4F7F\u7528 <code>keepdim</code> \u4FDD\u6301\u7EF4\u5EA6\uFF0C\u4EE5\u4FBF\u53EF\u4EE5\u8FDB\u884C\u5E7F\u64AD\u64CD\u4F5C\u3002</li><li><code>return self.weight * hidden_states / (sqrt_pow_mean + self.eps)</code>: \u6267\u884C\u5F52\u4E00\u5316\u64CD\u4F5C\uFF0C\u5C06 <code>hidden_states</code> \u4E2D\u7684\u6BCF\u4E2A\u5143\u7D20\u9664\u4EE5\u5176\u5E73\u65B9\u7684\u5E73\u5747\u503C\u7684\u5E73\u65B9\u6839\u52A0\u4E0A <code>eps</code>\uFF0C\u7136\u540E\u4E58\u4EE5 <code>weight</code> \u53C2\u6570\u3002</li></ul></li></ol><p>RMS Norm \u7684\u6838\u5FC3\u601D\u60F3\u662F\u52A8\u6001\u5730\u5BF9\u6BCF\u4E2A\u7279\u5F81\u7684\u5C3A\u5EA6\u8FDB\u884C\u8C03\u6574\uFF0C\u4F7F\u5F97\u6BCF\u4E2A\u7279\u5F81\u7684\u5747\u65B9\u6839\u503C\u63A5\u8FD1 1\u3002\u8FD9\u6709\u52A9\u4E8E\u7A33\u5B9A\u8BAD\u7EC3\u8FC7\u7A0B\uFF0C\u7279\u522B\u662F\u5728\u6DF1\u5EA6\u7F51\u7EDC\u4E2D\u3002</p><p>\u8BF7\u6CE8\u610F\uFF0C\u8FD9\u4E2A\u5B9E\u73B0\u4E2D\uFF0C<code>hidden_states</code> \u88AB\u8F6C\u6362\u4E3A <code>float32</code> \u7C7B\u578B\u8FDB\u884C\u8BA1\u7B97\uFF0C\u4F46\u5728\u5B9E\u9645\u4F7F\u7528\u65F6\uFF0C\u4F60\u53EF\u80FD\u9700\u8981\u6839\u636E\u4F60\u7684\u6A21\u578B\u548C\u786C\u4EF6\u8003\u8651\u662F\u5426\u9700\u8981\u8F6C\u6362\u56DE\u539F\u59CB\u7684\u6570\u636E\u7C7B\u578B\u3002\u6B64\u5916\uFF0C\u8FD9\u4E2A\u7C7B\u6CA1\u6709\u5B9E\u73B0\u53CD\u5411\u4F20\u64AD\u903B\u8F91\uFF0C\u56E0\u4E3A\u4F5C\u4E3A <code>nn.Module</code> \u7684\u5B50\u7C7B\uFF0CPyTorch \u4F1A\u81EA\u52A8\u4F7F\u7528 <code>autograd</code> \u6765\u8BA1\u7B97\u68AF\u5EA6\u3002</p><p>User: \u81EA\u5F52\u4E00\u5316</p><p>Kimi: \u81EA\u5F52\u4E00\u5316\uFF08Self-Normalization\uFF09\u662F\u6DF1\u5EA6\u5B66\u4E60\u4E2D\u4E00\u79CD\u7528\u4E8E\u6539\u5584\u795E\u7ECF\u7F51\u7EDC\u8BAD\u7EC3\u548C\u6CDB\u5316\u6027\u80FD\u7684\u6280\u672F\u3002\u8FD9\u79CD\u6280\u672F\u7684\u6838\u5FC3\u601D\u60F3\u662F\u901A\u8FC7\u5F52\u4E00\u5316\u5C42\u7684\u8F93\u51FA\uFF0C\u4F7F\u5F97\u7F51\u7EDC\u7684\u6BCF\u4E00\u5C42\u8F93\u51FA\u7684\u5206\u5E03\u4FDD\u6301\u76F8\u5BF9\u7A33\u5B9A\uFF0C\u4ECE\u800C\u51CF\u5C11\u5185\u90E8\u534F\u53D8\u91CF\u504F\u79FB\uFF08Internal Covariate Shift\uFF09\u73B0\u8C61\uFF0C\u5373\u524D\u5C42\u7684\u8F93\u51FA\u5206\u5E03\u968F\u7740\u8BAD\u7EC3\u7684\u8FDB\u884C\u800C\u53D1\u751F\u663E\u8457\u53D8\u5316\uFF0C\u8FD9\u53EF\u80FD\u4F1A\u5F71\u54CD\u540E\u5C42\u7684\u5B66\u4E60\u3002</p><p>\u81EA\u5F52\u4E00\u5316\u6280\u672F\u901A\u5E38\u5305\u62EC\u4EE5\u4E0B\u51E0\u79CD\u65B9\u6CD5\uFF1A</p><ol><li><p><strong>\u6279\u91CF\u5F52\u4E00\u5316\uFF08Batch Normalization\uFF09</strong>:</p><ul><li>\u8FD9\u662F\u6700\u5E38\u7528\u7684\u81EA\u5F52\u4E00\u5316\u6280\u672F\u4E4B\u4E00\uFF0C\u901A\u8FC7\u5BF9\u6BCF\u4E2A\u5C0F\u6279\u91CF\u6570\u636E\u7684\u8F93\u51FA\u8FDB\u884C\u5F52\u4E00\u5316\u6765\u5DE5\u4F5C\u3002</li><li>\u5B83\u901A\u8FC7\u8BA1\u7B97\u5747\u503C\u548C\u65B9\u5DEE\uFF0C\u7136\u540E\u4F7F\u7528\u8FD9\u4E9B\u7EDF\u8BA1\u91CF\u6765\u5F52\u4E00\u5316\u8F93\u51FA\u3002</li></ul></li><li><p><strong>\u5C42\u5F52\u4E00\u5316\uFF08Layer Normalization\uFF09</strong>:</p><ul><li>\u8FD9\u79CD\u6280\u672F\u5BF9\u6BCF\u4E2A\u6837\u672C\u7684\u6240\u6709\u6FC0\u6D3B\u8FDB\u884C\u5F52\u4E00\u5316\uFF0C\u800C\u4E0D\u662F\u5BF9\u5C0F\u6279\u91CF\u6570\u636E\u8FDB\u884C\u5F52\u4E00\u5316\u3002</li><li>\u5B83\u4FDD\u6301\u4E86\u4E0D\u540C\u6837\u672C\u95F4\u7684\u72EC\u7ACB\u6027\uFF0C\u9002\u7528\u4E8E\u5904\u7406\u5E8F\u5217\u6570\u636E\u3002</li></ul></li><li><p><strong>\u5B9E\u4F8B\u5F52\u4E00\u5316\uFF08Instance Normalization\uFF09</strong>:</p><ul><li>\u4E3B\u8981\u7528\u4E8E\u98CE\u683C\u8FC1\u79FB\u4EFB\u52A1\uFF0C\u901A\u8FC7\u5BF9\u5355\u4E2A\u56FE\u50CF\u7684\u6BCF\u4E2A\u901A\u9053\u8FDB\u884C\u5F52\u4E00\u5316\u6765\u5DE5\u4F5C\u3002</li></ul></li><li><p><strong>\u7EC4\u5F52\u4E00\u5316\uFF08Group Normalization\uFF09</strong>:</p><ul><li>\u8FD9\u79CD\u5F52\u4E00\u5316\u65B9\u5F0F\u5C06\u901A\u9053\u5206\u6210\u591A\u4E2A\u7EC4\uFF0C\u7136\u540E\u5728\u6BCF\u4E2A\u7EC4\u5185\u8FDB\u884C\u5F52\u4E00\u5316\u3002</li><li>\u5B83\u5728\u5904\u7406\u4E0D\u540C\u6279\u91CF\u5927\u5C0F\u7684\u6570\u636E\u65F6\u5177\u6709\u66F4\u597D\u7684\u7075\u6D3B\u6027\u3002</li></ul></li><li><p><strong>\u6743\u91CD\u5F52\u4E00\u5316\uFF08Weight Normalization\uFF09</strong>:</p><ul><li>\u8FD9\u79CD\u6280\u672F\u901A\u8FC7\u5F52\u4E00\u5316\u6743\u91CD\u5411\u91CF\u6765\u5DE5\u4F5C\uFF0C\u800C\u4E0D\u662F\u6FC0\u6D3B\u503C\u3002</li></ul></li><li><p><strong>RMSNorm</strong>:</p><ul><li>\u8FD9\u662F\u4E00\u79CD\u7C7B\u4F3C\u4E8E\u6279\u91CF\u5F52\u4E00\u5316\u7684\u6280\u672F\uFF0C\u4F46\u5B83\u4F7F\u7528\u5747\u65B9\u6839\uFF08Root Mean Square\uFF09\u503C\u6765\u8FDB\u884C\u5F52\u4E00\u5316\u3002</li><li>\u5B83\u901A\u8FC7\u8BA1\u7B97\u8F93\u5165\u7684\u5E73\u65B9\u7684\u5E73\u5747\u503C\u7684\u5E73\u65B9\u6839\uFF0C\u7136\u540E\u9664\u4EE5\u8FD9\u4E2A\u503C\u6765\u8FDB\u884C\u5F52\u4E00\u5316\u3002</li></ul></li></ol><p>\u81EA\u5F52\u4E00\u5316\u6280\u672F\u7684\u4F18\u70B9\u5305\u62EC\uFF1A</p><ul><li><strong>\u52A0\u901F\u6536\u655B</strong>\uFF1A\u901A\u8FC7\u51CF\u5C11\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\u7684\u68AF\u5EA6\u95EE\u9898\uFF0C\u53EF\u4EE5\u52A0\u5FEB\u6536\u655B\u901F\u5EA6\u3002</li><li><strong>\u63D0\u9AD8\u6027\u80FD</strong>\uFF1A\u901A\u8FC7\u7A33\u5B9A\u7F51\u7EDC\u7684\u4E2D\u95F4\u5C42\u8868\u793A\uFF0C\u53EF\u4EE5\u63D0\u9AD8\u6A21\u578B\u7684\u6CDB\u5316\u80FD\u529B\u3002</li><li><strong>\u51CF\u5C11\u8D85\u53C2\u6570\u8C03\u6574</strong>\uFF1A\u81EA\u5F52\u4E00\u5316\u51CF\u5C11\u4E86\u5BF9\u521D\u59CB\u5316\u548C\u5B66\u4E60\u7387\u7B49\u8D85\u53C2\u6570\u7684\u654F\u611F\u6027\u3002</li></ul><p>\u7136\u800C\uFF0C\u81EA\u5F52\u4E00\u5316\u6280\u672F\u4E5F\u6709\u4E00\u4E9B\u5C40\u9650\u6027\uFF0C\u6BD4\u5982\u6279\u91CF\u5F52\u4E00\u5316\u5728\u5C0F\u6279\u91CF\u5927\u5C0F\u4E0B\u53EF\u80FD\u6548\u679C\u4E0D\u4F73\uFF0C\u6216\u8005\u5728\u67D0\u4E9B\u7279\u5B9A\u4EFB\u52A1\u4E2D\u53EF\u80FD\u4E0D\u9002\u5408\u4F7F\u7528\u3002</p><p>\u5728\u4F60\u4E4B\u524D\u63D0\u4F9B\u7684 <code>RMS_Norm</code> \u7C7B\u4E2D\uFF0C\u5B9E\u73B0\u7684\u5C31\u662F RMSNorm\uFF0C\u5B83\u901A\u8FC7\u9664\u4EE5\u8F93\u5165\u7684\u5747\u65B9\u6839\u503C\u6765\u8FDB\u884C\u5F52\u4E00\u5316\uFF0C\u8FD9\u79CD\u65B9\u6CD5\u6709\u52A9\u4E8E\u7A33\u5B9A\u7F51\u7EDC\u7684\u8F93\u51FA\u5206\u5E03\uFF0C\u4ECE\u800C\u63D0\u9AD8\u8BAD\u7EC3\u7684\u7A33\u5B9A\u6027\u548C\u6A21\u578B\u7684\u6027\u80FD\u3002</p><p>User: class flash_att(nn.Module): # \u53C2\u8003 NanoGPT def <strong>init</strong>(self,args): super().<strong>init</strong>() # qkv \u5408\u5230\u4E00\u4E2A Linear \u91CC\u9762\u53BB self.qkv_atten = nn.Linear(args.n_embed,3*args.n_embed,bias = args.bias) # \u8BB0\u5F97\u6709\u4E00\u7BC7\u8BBA\u6587\u8BF4 head_size \u8981\u7B49\u4E8E seq_length \u624D\u5408\u7406 self.n_head = args.n_head self.n_embed = args.n_embed # \u8BA1\u7B97\u4E00\u4E0B head_size assert args.n_embed % args.n_head == 0 self.head_size = args.n_embed//args.n_head # dropout self.dropout = args.dropout # \u8FD9\u91CC\u662F\u5B58\u5E03\u5C14\u503C\uFF0C\u53C2\u6570 dropout \u6982\u7387\uFF0Cgenerate \u65F6\u8BBE\u7F6E\u4E3A 0 \u5373\u53EF self.att_dropout = nn.Dropout(self.dropout) # \u7B49\u4EF7\u4E8E nn.Dropout(p=self.dropout) # projection layer self.c_proj = nn.Linear(self.n_embed,self.n_embed, bias = args.bias)</p><pre><code>def forward(self, x):
    B,T,C = x.shape
    # x\u7684\u5C3A\u5BF8\uFF1A(B,T,C)
    q, k, v = self.qkv_atten(x).split(self.n_embed,dim = 2) # B,T,C

    q = q.view(B,T,self.n_head,self.head_size).transpose(1,2)
    # (B,T,C) -&gt; (B,T,n_head,head_size) -&gt; (B,n_head,T,head_size)
    k = k.view(B,T,self.n_head,self.head_size).transpose(1,2)
    v = v.view(B,T,self.n_head,self.head_size).transpose(1,2)

    # \u4F7F\u7528torch\u5C01\u88C5\u597D\u7684flash attention
    y = nn.functional.scaled_dot_product_attention(q,k,v,attn_mask=None,
                                                   dropout_p = self.dropout if self.training else 0,
                                                   is_causal=True)
    # \u8BAD\u7EC3\u65F6dropout
    # (B, nh, T, T) x (B, nh, T, hs) -&gt; (B, nh, T, hs)
    # \u4E4B\u540E\u8981transpose\u4E00\u4E0B\u8BA9\u5B83\u53D8\u6210(B,T,nh,hs)
    y = y.transpose(1,2)# (B,T,nh,hs)
    # .contiguous()\u65B9\u6CD5\u4F1A\u8FD4\u56DE\u4E00\u4E2A\u5F20\u91CF\uFF0C\u4FDD\u8BC1\u4E86\u5176\u5728\u5185\u5B58\u4E2D\u7684\u8FDE\u7EED\u6027
    y = y.contiguous().view(B,T,C) # (B,T,C)

    # \u8F93\u51FA\u65F6\u7ECF\u8FC7\u6295\u5F71\u5C42\u540Edropout
    return self.att_dropout(self.c_proj(y))
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u5B9A\u4E49\u4E86\u4E00\u4E2A\u540D\u4E3A <code>flash_att</code> \u7684\u7C7B\uFF0C\u5B83\u662F\u4E00\u4E2A PyTorch \u7684 <code>nn.Module</code> \u7684\u5B50\u7C7B\uFF0C\u5B9E\u73B0\u4E86\u4E00\u79CD\u6CE8\u610F\u529B\u673A\u5236\uFF0C\u79F0\u4E3A Flash Attention\uFF0C\u7075\u611F\u53EF\u80FD\u6765\u6E90\u4E8E NanoGPT\u3002\u8FD9\u4E2A\u7C7B\u7528\u4E8E\u6784\u5EFA Transformer \u6A21\u578B\u4E2D\u7684\u6CE8\u610F\u529B\u5C42\u3002\u4E0B\u9762\u662F\u4EE3\u7801\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ol><li><p><code>__init__(self, args)</code>: \u7C7B\u7684\u6784\u9020\u51FD\u6570\uFF0C\u63A5\u53D7\u4E00\u4E2A <code>args</code> \u53C2\u6570\uFF0C\u5B83\u662F\u4E00\u4E2A\u5305\u542B\u6A21\u578B\u53C2\u6570\u7684\u6570\u636E\u7C7B\u5B9E\u4F8B\u3002</p></li><li><p><code>self.qkv_atten = nn.Linear(args.n_embed, 3 * args.n_embed, bias=args.bias)</code>: \u521B\u5EFA\u4E00\u4E2A\u7EBF\u6027\u5C42\uFF0C\u7528\u4E8E\u540C\u65F6\u751F\u6210 Query\uFF08Q\uFF09\u3001Key\uFF08K\uFF09\u548C Value\uFF08V\uFF09\u3002\u8FD9\u4E2A\u7EBF\u6027\u5C42\u5C06\u8F93\u5165\u7684\u7279\u5F81\u7EF4\u5EA6\u6269\u5C55\u4E3A\u4E09\u500D\uFF0C\u56E0\u4E3A Q\u3001K \u548C V \u90FD\u662F\u76F8\u540C\u7EF4\u5EA6\u7684\u3002</p></li><li><p><code>self.n_head = args.n_head</code> \u548C <code>self.n_embed = args.n_embed</code>: \u5B58\u50A8\u5934\u7684\u6570\u91CF\u548C\u5D4C\u5165\u7EF4\u5EA6\u3002</p></li><li><p><code>assert args.n_embed % args.n_head == 0</code>: \u786E\u4FDD\u5D4C\u5165\u7EF4\u5EA6\u53EF\u4EE5\u88AB\u5934\u7684\u6570\u91CF\u6574\u9664\uFF0C\u8FD9\u662F\u591A\u5934\u6CE8\u610F\u529B\u673A\u5236\u7684\u8981\u6C42\u3002</p></li><li><p><code>self.head_size = args.n_embed // args.n_head</code>: \u8BA1\u7B97\u6BCF\u4E2A\u5934\u7684\u7EF4\u5EA6\u5927\u5C0F\u3002</p></li><li><p><code>self.dropout = args.dropout</code> \u548C <code>self.att_dropout = nn.Dropout(self.dropout)</code>: \u5B58\u50A8 dropout \u6982\u7387\uFF0C\u5E76\u521B\u5EFA\u4E00\u4E2A dropout \u5C42\u3002</p></li><li><p><code>self.c_proj = nn.Linear(self.n_embed, self.n_embed, bias=args.bias)</code>: \u521B\u5EFA\u4E00\u4E2A\u7EBF\u6027\u5C42\uFF0C\u7528\u4E8E\u6CE8\u610F\u529B\u8F93\u51FA\u7684\u6295\u5F71\u3002</p></li><li><p><code>forward(self, x)</code>: \u7C7B\u7684\u524D\u5411\u4F20\u64AD\u51FD\u6570\u3002</p><ul><li><code>B, T, C = x.shape</code>: \u83B7\u53D6\u8F93\u5165\u5F20\u91CF <code>x</code> \u7684\u5F62\u72B6\uFF0C\u5176\u4E2D <code>B</code> \u662F\u6279\u6B21\u5927\u5C0F\uFF0C<code>T</code> \u662F\u5E8F\u5217\u957F\u5EA6\uFF0C<code>C</code> \u662F\u7279\u5F81\u7EF4\u5EA6\u3002</li><li><code>q, k, v = self.qkv_atten(x).split(self.n_embed, dim=2)</code>: \u4F7F\u7528 <code>qkv_atten</code> \u7EBF\u6027\u5C42\u751F\u6210 Q\u3001K\u3001V\uFF0C\u5E76\u5C06\u7ED3\u679C\u6CBF\u6700\u540E\u4E00\u4E2A\u7EF4\u5EA6\u5206\u5272\u4E3A\u4E09\u90E8\u5206\u3002</li><li><code>q.view(...)</code>, <code>k.view(...)</code>, <code>v.view(...)</code>: \u5C06 Q\u3001K\u3001V \u91CD\u5851\u5E76\u8F6C\u7F6E\uFF0C\u4EE5\u9002\u5E94\u591A\u5934\u6CE8\u610F\u529B\u673A\u5236\u7684\u683C\u5F0F\u3002</li><li><code>y = nn.functional.scaled_dot_product_attention(...)</code>: \u4F7F\u7528 PyTorch \u7684 <code>scaled_dot_product_attention</code> \u51FD\u6570\u5B9E\u73B0 Flash Attention\u3002\u6CE8\u610F\uFF0C\u8FD9\u91CC\u7684\u5B9E\u73B0\u4F7F\u7528\u4E86 <code>is_causal=True</code> \u53C2\u6570\uFF0C\u8FD9\u53EF\u80FD\u610F\u5473\u7740\u5B83\u5B9E\u73B0\u4E86\u4E00\u79CD\u56E0\u679C\u8BED\u8A00\u6A21\u578B\u7684\u6CE8\u610F\u529B\u673A\u5236\uFF0C\u5176\u4E2D\u6BCF\u4E2A\u4F4D\u7F6E\u53EA\u80FD\u5173\u6CE8\u5230\u5B83\u4E4B\u524D\u7684\u5E8F\u5217\u3002</li><li><code>y = y.transpose(1,2)</code>: \u8F6C\u7F6E\u6CE8\u610F\u529B\u8F93\u51FA\uFF0C\u4EE5\u9002\u5E94\u540E\u7EED\u7684\u6295\u5F71\u5C42\u3002</li><li><code>y = y.contiguous().view(B, T, C)</code>: \u786E\u4FDD\u5F20\u91CF\u5728\u5185\u5B58\u4E2D\u8FDE\u7EED\uFF0C\u5E76\u5C06\u5176\u89C6\u56FE\u8F6C\u6362\u56DE\u539F\u59CB\u7684\u6279\u6B21\u548C\u5E8F\u5217\u5F62\u72B6\u3002</li><li><code>return self.att_dropout(self.c_proj(y))</code>: \u5E94\u7528\u6295\u5F71\u5C42\u548C dropout\uFF0C\u7136\u540E\u8FD4\u56DE\u6700\u7EC8\u7684\u8F93\u51FA\u3002</li></ul></li></ol><p>\u8FD9\u4E2A <code>flash_att</code> \u7C7B\u5B9E\u73B0\u4E86\u4E00\u4E2A\u81EA\u5B9A\u4E49\u7684\u6CE8\u610F\u529B\u673A\u5236\uFF0C\u5B83\u7ED3\u5408\u4E86\u591A\u5934\u6CE8\u610F\u529B\u3001\u7EBF\u6027\u6295\u5F71\u548C dropout\u3002\u8FD9\u79CD\u6CE8\u610F\u529B\u673A\u5236\u53EF\u4EE5\u4F5C\u4E3A Transformer \u6A21\u578B\u7684\u4E00\u4E2A\u7EC4\u4EF6\uFF0C\u7528\u4E8E\u5904\u7406\u5E8F\u5217\u6570\u636E\u3002\u4EE3\u7801\u4E2D\u7684 <code>scaled_dot_product_attention</code> \u51FD\u6570\u662F PyTorch \u63D0\u4F9B\u7684\u4E00\u4E2A\u51FD\u6570\uFF0C\u7528\u4E8E\u8BA1\u7B97\u6CE8\u610F\u529B\u5206\u6570\u548C\u52A0\u6743\u8F93\u51FA\u3002\u6CE8\u610F\uFF0C\u8FD9\u91CC\u7684\u5B9E\u73B0\u53EF\u80FD\u9700\u8981\u6839\u636E\u5B9E\u9645\u7684\u6A21\u578B\u67B6\u6784\u548C\u4EFB\u52A1\u9700\u6C42\u8FDB\u884C\u8C03\u6574\u3002</p><p>User: dropout</p><p>Kimi: Dropout \u662F\u4E00\u79CD\u5728\u8BAD\u7EC3\u6DF1\u5EA6\u795E\u7ECF\u7F51\u7EDC\u65F6\u5E38\u7528\u7684\u6B63\u5219\u5316\u6280\u672F\uFF0C\u7531 Geoffrey Hinton \u548C\u4ED6\u7684\u540C\u4E8B\u5728 2012 \u5E74\u63D0\u51FA\u3002Dropout \u7684\u4E3B\u8981\u76EE\u7684\u662F\u9632\u6B62\u6A21\u578B\u8FC7\u62DF\u5408\uFF0C\u63D0\u9AD8\u6A21\u578B\u7684\u6CDB\u5316\u80FD\u529B\u3002</p><p>\u4EE5\u4E0B\u662F Dropout \u7684\u5173\u952E\u6982\u5FF5\u548C\u5DE5\u4F5C\u539F\u7406\uFF1A</p><ol><li><p><strong>\u968F\u673A\u4E22\u5F03</strong>\uFF1A\u5728\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\uFF0CDropout \u968F\u673A\u5C06\u4E00\u90E8\u5206\u795E\u7ECF\u5143\u7684\u6FC0\u6D3B\u8F93\u51FA\u8BBE\u7F6E\u4E3A\u96F6\u3002\u5177\u4F53\u6765\u8BF4\uFF0C\u6BCF\u4E2A\u795E\u7ECF\u5143\u8F93\u51FA\u88AB\u4E22\u5F03\u7684\u6982\u7387\u662F\u76F8\u540C\u7684\uFF0C\u901A\u5E38\u7531\u8D85\u53C2\u6570 <code>p</code> \u51B3\u5B9A\u3002</p></li><li><p><strong>\u4FDD\u7559\u7A00\u758F\u6027</strong>\uFF1A\u7531\u4E8E\u795E\u7ECF\u5143\u7684\u968F\u673A\u4E22\u5F03\uFF0C\u7F51\u7EDC\u5728\u6BCF\u6B21\u8BAD\u7EC3\u8FED\u4EE3\u4E2D\u90FD\u4F1A\u6709\u4E0D\u540C\u7684\u67B6\u6784\uFF0C\u8FD9\u8FEB\u4F7F\u7F51\u7EDC\u5B66\u4E60\u66F4\u52A0\u9C81\u68D2\u7684\u7279\u5F81\u8868\u793A\u3002</p></li><li><p><strong>\u8BAD\u7EC3\u4E0E\u63A8\u7406\u65F6\u7684\u533A\u522B</strong>\uFF1A\u5728\u8BAD\u7EC3\u65F6\u5E94\u7528 Dropout\uFF0C\u800C\u5728\u6A21\u578B\u63A8\u7406\uFF08\u6216\u6D4B\u8BD5\uFF09\u9636\u6BB5\u4E0D\u5E94\u7528\u3002\u5728\u63A8\u7406\u65F6\uFF0C\u4E3A\u4E86\u4FDD\u6301\u795E\u7ECF\u5143\u7684\u671F\u671B\u503C\u4E0D\u53D8\uFF0C\u901A\u5E38\u4F1A\u5C06\u795E\u7ECF\u5143\u7684\u8F93\u51FA\u4E58\u4EE5 <code>(1-p)</code>\u3002</p></li><li><p><strong>\u8D85\u53C2\u6570 <code>p</code></strong>\uFF1ADropout \u7684\u4E22\u5F03\u6982\u7387\uFF0C\u662F\u4E00\u4E2A\u91CD\u8981\u7684\u8D85\u53C2\u6570\u3002\u5E38\u89C1\u7684\u503C\u6709 0.2\u30010.5 \u7B49\uFF0C\u5177\u4F53\u503C\u9700\u8981\u6839\u636E\u6A21\u578B\u548C\u4EFB\u52A1\u8FDB\u884C\u8C03\u6574\u3002</p></li><li><p><strong>\u5B9E\u73B0\u65B9\u5F0F</strong>\uFF1A\u5728 PyTorch \u4E2D\uFF0CDropout \u53EF\u4EE5\u901A\u8FC7 <code>nn.Dropout</code> \u6A21\u5757\u5B9E\u73B0\u3002\u4F8B\u5982\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#B392F0;">dropout_layer </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> nn</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">Dropout</span><span style="color:#BBBBBB;">(p</span><span style="color:#F97583;">=</span><span style="color:#F8F8F8;">0.5</span><span style="color:#BBBBBB;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li><li><p><strong>\u5E94\u7528\u573A\u666F</strong>\uFF1ADropout \u901A\u5E38\u5E94\u7528\u4E8E\u5168\u8FDE\u63A5\u5C42\uFF08\u4E5F\u79F0\u4E3A\u5BC6\u96C6\u5C42\u6216\u7EBF\u6027\u5C42\uFF09\u7684\u8F93\u51FA\u4E0A\u3002\u5728\u5377\u79EF\u795E\u7ECF\u7F51\u7EDC\uFF08CNN\uFF09\u4E2D\uFF0C\u6709\u65F6\u4E5F\u4F1A\u5E94\u7528\u4E8E\u5377\u79EF\u5C42\u7684\u8F93\u51FA\u4E0A\u3002</p></li><li><p><strong>\u4E0E\u5176\u4ED6\u6B63\u5219\u5316\u6280\u672F\u7684\u6BD4\u8F83</strong>\uFF1ADropout \u4E0E L1\u3001L2 \u6B63\u5219\u5316\u7B49\u5176\u4ED6\u6B63\u5219\u5316\u6280\u672F\u76F8\u6BD4\uFF0C\u63D0\u4F9B\u4E86\u4E00\u79CD\u4E0D\u540C\u7684\u6B63\u5219\u5316\u65B9\u5F0F\uFF0C\u5B83\u53EF\u4EE5\u51CF\u5C11\u6A21\u578B\u5BF9\u8BAD\u7EC3\u6570\u636E\u4E2D\u7279\u5B9A\u6837\u672C\u7684\u4F9D\u8D56\u3002</p></li><li><p><strong>\u7F3A\u70B9</strong>\uFF1A\u867D\u7136 Dropout \u6709\u52A9\u4E8E\u51CF\u5C11\u8FC7\u62DF\u5408\uFF0C\u4F46\u6709\u65F6\u53EF\u80FD\u4F1A\u5BFC\u81F4\u8BAD\u7EC3\u65F6\u95F4\u53D8\u957F\uFF0C\u56E0\u4E3A\u9700\u8981\u66F4\u591A\u7684\u8FED\u4EE3\u6765\u8FBE\u5230\u76F8\u540C\u7684\u6027\u80FD\u6C34\u5E73\u3002</p></li><li><p><strong>\u53D8\u4F53</strong>\uFF1A\u5B58\u5728\u4E00\u4E9B Dropout \u7684\u53D8\u4F53\uFF0C\u4F8B\u5982 Spatial Dropout\uFF08\u7528\u4E8E\u5377\u79EF\u795E\u7ECF\u7F51\u7EDC\uFF09\uFF0C\u5B83\u968F\u673A\u4E22\u5F03\u6574\u4E2A\u7279\u5F81\u56FE\uFF1B\u6216\u8005 Inverted Dropout\uFF08\u6216\u79F0 DropConnect\uFF09\uFF0C\u5B83\u968F\u673A\u4E22\u5F03\u6743\u91CD\u800C\u4E0D\u662F\u6FC0\u6D3B\u3002</p></li></ol><p>\u5728\u4F60\u7684 <code>flash_att</code> \u7C7B\u4E2D\uFF0C<code>self.dropout</code> \u5B58\u50A8\u4E86 Dropout \u7684\u6982\u7387\u503C\uFF0C<code>self.att_dropout</code> \u662F <code>nn.Dropout</code> \u7684\u4E00\u4E2A\u5B9E\u4F8B\uFF0C\u7528\u4E8E\u5728\u6CE8\u610F\u529B\u673A\u5236\u7684\u8F93\u51FA\u4E0A\u5E94\u7528 Dropout\u3002\u5728\u6A21\u578B\u8BAD\u7EC3\u65F6\uFF0CDropout \u6709\u52A9\u4E8E\u6A21\u578B\u5B66\u4E60\u66F4\u52A0\u6CDB\u5316\u7684\u7279\u5F81\uFF0C\u800C\u5728\u6A21\u578B\u63A8\u7406\u65F6\uFF0C\u901A\u8FC7\u4E58\u4EE5 <code>(1-self.dropout)</code> \u6765\u8865\u507F\u8BAD\u7EC3\u65F6\u7684\u4E22\u5F03\u64CD\u4F5C\u3002</p><p>User: args</p><p>Kimi: \u5728 Python \u4E2D\uFF0C<code>args</code> \u901A\u5E38\u662F\u5728\u5B9A\u4E49\u51FD\u6570\u6216\u65B9\u6CD5\u65F6\uFF0C\u7528\u4E8E\u6307\u4EE3\u4F20\u5165\u8BE5\u51FD\u6570\u6216\u65B9\u6CD5\u7684\u6240\u6709\u53C2\u6570\u3002\u7136\u800C\uFF0C\u5728\u4F60\u4E4B\u524D\u63D0\u5230\u7684\u4E0A\u4E0B\u6587\u4E2D\uFF0C<code>args</code> \u662F\u4E00\u4E2A\u5B9E\u4F8B\u5316\u7684\u7C7B\uFF0C\u5B83\u4F7F\u7528 <code>dataclasses</code> \u6A21\u5757\u7684 <code>@dataclass</code> \u88C5\u9970\u5668\u6765\u5B9A\u4E49\u3002\u8FD9\u4E2A <code>args</code> \u5B9E\u4F8B\u5305\u542B\u4E86\u6A21\u578B\u7684\u53C2\u6570\u914D\u7F6E\uFF0C\u7528\u4E8E\u521D\u59CB\u5316\u548C\u914D\u7F6E\u795E\u7ECF\u7F51\u7EDC\u6A21\u578B\u3002</p><p>\u4F8B\u5982\uFF0C\u4F60\u4E4B\u524D\u5B9A\u4E49\u7684 <code>Model_args</code> \u6570\u636E\u7C7B\u53EF\u80FD\u770B\u8D77\u6765\u50CF\u8FD9\u6837\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#F97583;">from</span><span style="color:#B392F0;"> dataclasses </span><span style="color:#F97583;">import</span><span style="color:#B392F0;"> dataclass</span></span>
<span class="line"></span>
<span class="line"><span style="color:#B392F0;">@dataclass</span></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#B392F0;"> Model_args:</span></span>
<span class="line"><span style="color:#B392F0;">    block_size</span><span style="color:#BBBBBB;">:</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">int</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">1024</span></span>
<span class="line"><span style="color:#B392F0;">    vocab_size</span><span style="color:#BBBBBB;">:</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">int</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">50257</span></span>
<span class="line"><span style="color:#B392F0;">    n_layer</span><span style="color:#BBBBBB;">:</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">int</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">12</span></span>
<span class="line"><span style="color:#B392F0;">    n_head</span><span style="color:#BBBBBB;">:</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">int</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">12</span></span>
<span class="line"><span style="color:#B392F0;">    n_embed</span><span style="color:#BBBBBB;">:</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">int</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">768</span></span>
<span class="line"><span style="color:#B392F0;">    dropout</span><span style="color:#BBBBBB;">:</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">float</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">0.1</span></span>
<span class="line"><span style="color:#B392F0;">    bias</span><span style="color:#BBBBBB;">:</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">bool</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">True</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>\u5728\u8FD9\u4E2A <code>Model_args</code> \u7C7B\u4E2D\uFF0C\u6BCF\u4E2A\u5C5E\u6027\u90FD\u6709\u4E00\u4E2A\u9ED8\u8BA4\u503C\u3002\u4F60\u53EF\u4EE5\u901A\u8FC7\u521B\u5EFA\u8FD9\u4E2A\u7C7B\u7684\u5B9E\u4F8B\u5E76\u4F20\u9012\u7279\u5B9A\u7684\u503C\u6765\u8986\u76D6\u8FD9\u4E9B\u9ED8\u8BA4\u503C\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#B392F0;">args </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> Model_args</span><span style="color:#BBBBBB;">(block_size</span><span style="color:#F97583;">=</span><span style="color:#F8F8F8;">512</span><span style="color:#BBBBBB;">, vocab_size</span><span style="color:#F97583;">=</span><span style="color:#F8F8F8;">10000</span><span style="color:#BBBBBB;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>\u5728\u8FD9\u4E2A\u4F8B\u5B50\u4E2D\uFF0C<code>args</code> \u662F <code>Model_args</code> \u7C7B\u7684\u4E00\u4E2A\u5B9E\u4F8B\uFF0C\u5176 <code>block_size</code> \u548C <code>vocab_size</code> \u5C5E\u6027\u88AB\u8BBE\u7F6E\u4E3A\u7279\u5B9A\u503C\uFF0C\u800C\u5176\u4ED6\u5C5E\u6027\u5219\u4FDD\u6301\u9ED8\u8BA4\u503C\u3002</p><p>\u5728\u4F60\u7684 <code>flash_att</code> \u7C7B\u7684\u6784\u9020\u51FD\u6570\u4E2D\uFF0C<code>args</code> \u4F5C\u4E3A\u53C2\u6570\u4F20\u5165\uFF0C\u7136\u540E\u7528\u4E8E\u8BBE\u7F6E\u7C7B\u7684\u5C5E\u6027\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#F97583;">class</span><span style="color:#B392F0;"> flash_att(nn</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">Module):</span></span>
<span class="line"><span style="color:#B392F0;">    </span><span style="color:#F97583;">def</span><span style="color:#B392F0;"> __init__(</span><span style="color:#FF9800;">self</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> </span><span style="color:#FF9800;">args</span><span style="color:#B392F0;">):</span></span>
<span class="line"><span style="color:#B392F0;">        </span><span style="color:#79B8FF;">super</span><span style="color:#BBBBBB;">().</span><span style="color:#B392F0;">__init__</span><span style="color:#BBBBBB;">()</span></span>
<span class="line"><span style="color:#B392F0;">        </span><span style="color:#6B737C;"># \u4F7F\u7528 args \u4E2D\u7684\u5C5E\u6027\u6765\u914D\u7F6E\u6A21\u578B</span></span>
<span class="line"><span style="color:#B392F0;">        self</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">qkv_atten </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> nn</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">Linear</span><span style="color:#BBBBBB;">(args.n_embed, </span><span style="color:#F8F8F8;">3</span><span style="color:#BBBBBB;"> </span><span style="color:#F97583;">*</span><span style="color:#BBBBBB;"> args.n_embed, bias</span><span style="color:#F97583;">=</span><span style="color:#BBBBBB;">args.bias)</span></span>
<span class="line"><span style="color:#B392F0;">        </span><span style="color:#6B737C;"># ... \u5176\u4ED6\u5C5E\u6027\u548C\u521D\u59CB\u5316\u4EE3\u7801 ...</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>\u5728\u8FD9\u4E2A <code>flash_att</code> \u7C7B\u4E2D\uFF0C<code>args</code> \u5B9E\u4F8B\u88AB\u7528\u6765\u8BBF\u95EE\u6A21\u578B\u53C2\u6570\uFF0C\u5982 <code>args.n_embed</code> \u7528\u4E8E\u8BBE\u7F6E\u5D4C\u5165\u7EF4\u5EA6\uFF0C<code>args.bias</code> \u7528\u4E8E\u51B3\u5B9A\u662F\u5426\u5728\u7F51\u7EDC\u5C42\u4E2D\u4F7F\u7528\u504F\u7F6E\u3002</p><p>\u7B80\u800C\u8A00\u4E4B\uFF0C\u5728\u6DF1\u5EA6\u5B66\u4E60\u6A21\u578B\u4E2D\uFF0C<code>args</code> \u901A\u5E38\u662F\u4E00\u4E2A\u914D\u7F6E\u5BF9\u8C61\uFF0C\u5B83\u5305\u542B\u4E86\u6A21\u578B\u7684\u6240\u6709\u8D85\u53C2\u6570\u548C\u914D\u7F6E\u9009\u9879\uFF0C\u4F7F\u5F97\u6A21\u578B\u7684\u914D\u7F6E\u66F4\u52A0\u7075\u6D3B\u548C\u53EF\u91CD\u7528\u3002</p><p>User: B,T,C = x.shape # x \u7684\u5C3A\u5BF8\uFF1A(B,T,C) q, k, v = self.qkv_atten(x).split(self.n_embed,dim = 2) # B,T,C</p><pre><code>    q = q.view(B,T,self.n_head,self.head_size).transpose(1,2)
    # (B,T,C) -&gt; (B,T,n_head,head_size) -&gt; (B,n_head,T,head_size)
    k = k.view(B,T,self.n_head,self.head_size).transpose(1,2)
    v = v.view(B,T,self.n_head,self.head_size).transpose(1,2)
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u662F\u591A\u5934\u81EA\u6CE8\u610F\u529B\u673A\u5236\u7684\u4E00\u90E8\u5206\uFF0C\u7528\u4E8E\u5904\u7406\u8F93\u5165\u5F20\u91CF <code>x</code> \u5E76\u51C6\u5907 Query\uFF08Q\uFF09\u3001Key\uFF08K\uFF09\u548C Value\uFF08V\uFF09\u7684\u8868\u793A\u3002\u4E0B\u9762\u662F\u4EE3\u7801\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ol><li><p><code>B, T, C = x.shape</code>: \u8FD9\u884C\u4EE3\u7801\u4ECE\u8F93\u5165\u5F20\u91CF <code>x</code> \u4E2D\u83B7\u53D6\u5176\u5F62\u72B6\uFF0C\u5E76\u5C06\u5176\u5206\u89E3\u4E3A\u4E09\u4E2A\u7EF4\u5EA6\uFF1A</p><ul><li><code>B</code>\uFF1A\u6279\u6B21\u5927\u5C0F\uFF08Batch size\uFF09\uFF0C\u8868\u793A\u540C\u65F6\u5904\u7406\u7684\u6570\u636E\u6837\u672C\u6570\u91CF\u3002</li><li><code>T</code>\uFF1A\u5E8F\u5217\u957F\u5EA6\uFF08Sequence length\uFF09\uFF0C\u5728\u81EA\u7136\u8BED\u8A00\u5904\u7406\u4E2D\u901A\u5E38\u5BF9\u5E94\u4E8E\u53E5\u5B50\u6216\u6587\u672C\u5E8F\u5217\u7684\u957F\u5EA6\u3002</li><li><code>C</code>\uFF1A\u7279\u5F81\u7EF4\u5EA6\uFF08Feature dimension\uFF09\uFF0C\u8868\u793A\u6BCF\u4E2A\u5E8F\u5217\u5143\u7D20\u7684\u7279\u5F81\u6570\u91CF\uFF0C\u4F8B\u5982\u5728 Transformer \u6A21\u578B\u4E2D\u5BF9\u5E94\u4E8E\u5D4C\u5165\u7EF4\u5EA6\u3002</li></ul></li><li><p><code>q, k, v = self.qkv_atten(x).split(self.n_embed, dim=2)</code>: \u8FD9\u884C\u4EE3\u7801\u9996\u5148\u901A\u8FC7 <code>self.qkv_atten</code> \u7EBF\u6027\u5C42\u5C06\u8F93\u5165 <code>x</code> \u6620\u5C04\u5230\u4E00\u4E2A\u65B0\u5F20\u91CF\uFF0C\u8BE5\u5F20\u91CF\u7684\u6700\u540E\u4E00\u4E2A\u7EF4\u5EA6\u662F <code>3 * C</code>\uFF0C\u7136\u540E\u6CBF\u7740\u6700\u540E\u4E00\u4E2A\u7EF4\u5EA6\u5C06\u8FD9\u4E2A\u65B0\u5F20\u91CF\u5206\u5272\u6210\u4E09\u4E2A\u90E8\u5206\uFF1AQ\u3001K \u548C V\uFF0C\u6BCF\u4E2A\u90E8\u5206\u7684\u7EF4\u5EA6\u90FD\u662F <code>B, T, self.n_embed</code>\u3002</p></li><li><p><code>q = q.view(B, T, self.n_head, self.head_size).transpose(1, 2)</code>: \u8FD9\u884C\u4EE3\u7801\u9996\u5148\u5C06 Q \u91CD\u5851\u4E3A <code>(B, T, self.n_head, self.head_size)</code> \u7684\u5F62\u72B6\uFF0C\u7136\u540E\u901A\u8FC7 <code>transpose</code> \u51FD\u6570\u4EA4\u6362\u7B2C\u4E8C\u7EF4\u548C\u7B2C\u4E09\u7EF4\uFF0C\u5F97\u5230 <code>(B, self.n_head, T, self.head_size)</code> \u7684\u5F62\u72B6\u3002\u8FD9\u662F\u4E3A\u4E86\u5C06 Q \u51C6\u5907\u4E3A\u591A\u5934\u6CE8\u610F\u529B\u673A\u5236\u4E2D\u7684\u9002\u5F53\u5F62\u72B6\u3002</p></li><li><p>\u7C7B\u4F3C\u7684\uFF0C<code>k.view(...).transpose(...)</code> \u548C <code>v.view(...).transpose(...)</code> \u5C06 K \u548C V \u4E5F\u91CD\u5851\u5E76\u8F6C\u7F6E\u5230 <code>(B, self.n_head, T, self.head_size)</code> \u7684\u5F62\u72B6\u3002</p></li></ol><p>\u8FD9\u4E9B\u64CD\u4F5C\u7684\u76EE\u7684\u662F\u5C06\u8F93\u5165\u5F20\u91CF <code>x</code> \u8F6C\u6362\u4E3A\u9002\u5408\u591A\u5934\u6CE8\u610F\u529B\u8BA1\u7B97\u7684\u5F62\u5F0F\u3002\u5728\u591A\u5934\u6CE8\u610F\u529B\u4E2D\uFF0C\u8F93\u5165\u88AB\u5206\u5272\u6210\u591A\u4E2A &quot;\u5934&quot;\uFF0C\u6BCF\u4E2A\u5934\u5B66\u4E60\u5230\u5E8F\u5217\u7684\u4E0D\u540C\u8868\u793A\u3002\u901A\u8FC7\u8FD9\u79CD\u65B9\u5F0F\uFF0C\u6A21\u578B\u53EF\u4EE5\u5E76\u884C\u5730\u4ECE\u4E0D\u540C\u7684\u5B50\u7A7A\u95F4\u6355\u6349\u4FE1\u606F\uFF0C\u589E\u5F3A\u6A21\u578B\u7684\u8868\u8FBE\u80FD\u529B\u3002</p><p><code>self.n_head</code> \u662F\u6A21\u578B\u4E2D\u5934\u7684\u6570\u91CF\uFF0C<code>self.head_size</code> \u662F\u6BCF\u4E2A\u5934\u7684\u7279\u5F81\u7EF4\u5EA6\u5927\u5C0F\uFF0C\u4E14 <code>self.n_embed</code> \u5FC5\u987B\u80FD\u88AB <code>self.n_head</code> \u6574\u9664\uFF0C\u4EE5\u786E\u4FDD\u6BCF\u4E2A\u5934\u90FD\u80FD\u83B7\u5F97\u76F8\u540C\u6570\u91CF\u7684\u7279\u5F81\u3002\u8FD9\u79CD\u5206\u5272\u548C\u91CD\u5851\u64CD\u4F5C\u662F\u5B9E\u73B0\u591A\u5934\u6CE8\u610F\u529B\u7684\u5173\u952E\u6B65\u9AA4\u3002</p><p>User: y = nn.functional.scaled_dot_product_attention(q,k,v,attn_mask=None, dropout_p = self.dropout if self.training else 0, is_causal=True)</p><p>Kimi: \u5728\u8FD9\u6BB5\u4EE3\u7801\u4E2D\uFF0C<code>scaled_dot_product_attention</code> \u51FD\u6570\u662F PyTorch \u5E93\u4E2D\u7528\u4E8E\u8BA1\u7B97\u81EA\u6CE8\u610F\u529B\uFF08Self-Attention\uFF09\u7684\u51FD\u6570\u3002\u8FD9\u4E2A\u51FD\u6570\u5B9E\u73B0\u4E86 Transformer \u6A21\u578B\u4E2D\u7684\u6CE8\u610F\u529B\u673A\u5236\uFF0C\u5B83\u901A\u8FC7\u8BA1\u7B97 Query\uFF08Q\uFF09\u3001Key\uFF08K\uFF09\u548C Value\uFF08V\uFF09\u4E4B\u95F4\u7684\u70B9\u79EF\u6765\u8861\u91CF\u5B83\u4EEC\u4E4B\u95F4\u7684\u76F8\u5173\u6027\u3002\u4E0B\u9762\u662F\u53C2\u6570\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ul><li><p><code>q</code>: \u67E5\u8BE2\u5F20\u91CF\uFF0C\u5176\u5F62\u72B6\u901A\u5E38\u662F <code>(B, N, H, D)</code>\uFF0C\u5176\u4E2D <code>B</code> \u662F\u6279\u6B21\u5927\u5C0F\uFF0C<code>N</code> \u662F\u5E8F\u5217\u957F\u5EA6\uFF0C<code>H</code> \u662F\u5934\u7684\u6570\u91CF\uFF0C<code>D</code> \u662F\u6BCF\u4E2A\u5934\u7684\u7279\u5F81\u7EF4\u5EA6\u3002</p></li><li><p><code>k</code>: \u952E\u5F20\u91CF\uFF0C\u5F62\u72B6\u5E94\u4E0E <code>q</code> \u76F8\u540C\u3002</p></li><li><p><code>v</code>: \u503C\u5F20\u91CF\uFF0C\u5F62\u72B6\u4E5F\u5E94\u4E0E <code>q</code> \u76F8\u540C\u3002</p></li><li><p><code>attn_mask</code>: \u4E00\u4E2A\u53EF\u9009\u53C2\u6570\uFF0C\u7528\u4E8E\u5C4F\u853D\uFF08masking\uFF09\u6CE8\u610F\u529B\u8BA1\u7B97\u4E2D\u7684\u67D0\u4E9B\u90E8\u5206\u3002\u4F8B\u5982\uFF0C\u5728\u5904\u7406\u5E8F\u5217\u65F6\uFF0C\u53EF\u4EE5\u4F7F\u7528\u63A9\u7801\u6765\u9632\u6B62\u672A\u6765\u4F4D\u7F6E\u7684\u4FE1\u606F\u6D41\u5165\u5F53\u524D\u4F4D\u7F6E\u3002</p></li><li><p><code>dropout_p</code>: \u8FD9\u662F dropout \u7684\u6982\u7387\u503C\u3002\u5982\u679C\u6A21\u578B\u5904\u4E8E\u8BAD\u7EC3\u6A21\u5F0F\uFF08<code>self.training</code> \u4E3A <code>True</code>\uFF09\uFF0C\u5219\u4F7F\u7528 <code>self.dropout</code> \u6307\u5B9A\u7684\u503C\uFF1B\u5982\u679C\u5904\u4E8E\u8BC4\u4F30\u6A21\u5F0F\uFF08<code>self.training</code> \u4E3A <code>False</code>\uFF09\uFF0C\u5219\u5C06 dropout \u8BBE\u7F6E\u4E3A 0\uFF0C\u4EE5\u786E\u4FDD\u5728\u63A8\u7406\u65F6\u4FDD\u6301\u4E00\u81F4\u6027\u3002</p></li><li><p><code>is_causal</code>: \u4E00\u4E2A\u5E03\u5C14\u503C\uFF0C\u5982\u679C\u8BBE\u7F6E\u4E3A <code>True</code>\uFF0C\u5219\u5B9E\u73B0\u56E0\u679C\uFF08Causal\uFF09\u6CE8\u610F\u529B\uFF0C\u5373\u53EA\u5141\u8BB8\u5E8F\u5217\u4E2D\u7684\u4F4D\u7F6E i \u4E0E i \u4E4B\u524D\u7684\u4F4D\u7F6E\u5EFA\u7ACB\u8FDE\u63A5\u3002\u8FD9\u5728\u751F\u6210\u4EFB\u52A1\u4E2D\u5F88\u6709\u7528\uFF0C\u5982\u6587\u672C\u751F\u6210\u6216\u8BED\u8A00\u6A21\u578B\uFF0C\u56E0\u4E3A\u5B83\u786E\u4FDD\u4E86\u751F\u6210\u7684\u6BCF\u4E2A\u5143\u7D20\u53EA\u4F9D\u8D56\u4E8E\u5B83\u4E4B\u524D\u7684\u6240\u6709\u5143\u7D20\u3002</p></li></ul><p><code>scaled_dot_product_attention</code> \u51FD\u6570\u7684\u5DE5\u4F5C\u65B9\u5F0F\u5982\u4E0B\uFF1A</p><ol><li><p>\u9996\u5148\uFF0C\u5B83\u8BA1\u7B97 Query \u548C Key \u4E4B\u95F4\u7684\u70B9\u79EF\uFF0C\u7136\u540E\u901A\u8FC7\u9664\u4EE5\u7F29\u653E\u56E0\u5B50\uFF08\u901A\u5E38\u662F Key \u7EF4\u5EA6\u7684\u5E73\u65B9\u6839\uFF09\u6765\u7F29\u653E\u8FD9\u4E9B\u70B9\u79EF\uFF0C\u4EE5\u9632\u6B62\u68AF\u5EA6\u8FC7\u5C0F\u3002</p></li><li><p>\u5982\u679C\u63D0\u4F9B\u4E86 <code>attn_mask</code>\uFF0C\u5219\u5C06\u63A9\u7801\u5E94\u7528\u4E8E\u70B9\u79EF\u7ED3\u679C\uFF0C\u901A\u5E38\u662F\u901A\u8FC7\u6DFB\u52A0\u4E00\u4E2A\u975E\u5E38\u5927\u7684\u8D1F\u6570\uFF08\u5982\u901A\u8FC7 <code>-1e9</code> \u5B9E\u73B0\uFF09\uFF0C\u8FD9\u6837\u5728\u5E94\u7528 softmax \u51FD\u6570\u65F6\uFF0C\u63A9\u7801\u4F4D\u7F6E\u7684\u6743\u91CD\u4F1A\u63A5\u8FD1\u4E8E 0\u3002</p></li><li><p>\u63A5\u7740\uFF0C\u4F7F\u7528 softmax \u51FD\u6570\u5BF9\u7F29\u653E\u540E\u7684\u70B9\u79EF\u8FDB\u884C\u5F52\u4E00\u5316\uFF0C\u5F97\u5230\u6CE8\u610F\u529B\u6743\u91CD\u3002</p></li><li><p>\u6700\u540E\uFF0C\u8FD9\u4E9B\u6CE8\u610F\u529B\u6743\u91CD\u4E0E Value \u5F20\u91CF\u76F8\u4E58\uFF0C\u7136\u540E\u6C42\u548C\uFF0C\u5F97\u5230\u6700\u7EC8\u7684\u8F93\u51FA\u3002</p></li></ol><p>\u8FD9\u4E2A\u51FD\u6570\u7684\u8F93\u51FA\u662F\u4E00\u4E2A\u5F20\u91CF\uFF0C\u5176\u5305\u542B\u4E86\u52A0\u6743\u7684 Value\uFF0C\u5373\u7ECF\u8FC7\u6CE8\u610F\u529B\u52A0\u6743\u7684\u5E8F\u5217\u8868\u793A\u3002\u8FD9\u4E2A\u8F93\u51FA\u53EF\u4EE5\u8FDB\u4E00\u6B65\u7528\u4E8E\u4E0B\u6E38\u4EFB\u52A1\uFF0C\u5982\u7F16\u7801\u6216\u89E3\u7801\u3002\u5728\u4F60\u7684 <code>flash_att</code> \u7C7B\u4E2D\uFF0C\u8FD9\u4E2A\u51FD\u6570\u88AB\u7528\u6765\u5B9E\u73B0\u5FEB\u901F\u7684\u6CE8\u610F\u529B\u8BA1\u7B97\uFF0C\u53EF\u80FD\u4E0E Flash Attention \u6709\u5173\uFF0C\u8FD9\u662F\u4E00\u79CD\u4F18\u5316\u7684\u6CE8\u610F\u529B\u673A\u5236\uFF0C\u65E8\u5728\u51CF\u5C11\u8BA1\u7B97\u91CF\u548C\u63D0\u9AD8\u6548\u7387\u3002</p><p>User: # \u8BAD\u7EC3\u65F6 dropout # (B, nh, T, T) x (B, nh, T, hs) -&gt; (B, nh, T, hs) # \u4E4B\u540E\u8981 transpose \u4E00\u4E0B\u8BA9\u5B83\u53D8\u6210(B,T,nh,hs) y = y.transpose(1,2)# (B,T,nh,hs) # .contiguous()\u65B9\u6CD5\u4F1A\u8FD4\u56DE\u4E00\u4E2A\u5F20\u91CF\uFF0C\u4FDD\u8BC1\u4E86\u5176\u5728\u5185\u5B58\u4E2D\u7684\u8FDE\u7EED\u6027 y = y.contiguous().view(B,T,C) # (B,T,C)</p><pre><code>    # \u8F93\u51FA\u65F6\u7ECF\u8FC7\u6295\u5F71\u5C42\u540Edropout
    return self.att_dropout(self.c_proj(y))
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u662F\u591A\u5934\u81EA\u6CE8\u610F\u529B\u673A\u5236\u540E\u5904\u7406\u7684\u4E00\u90E8\u5206\uFF0C\u5B83\u63CF\u8FF0\u4E86\u5982\u4F55\u5C06\u6CE8\u610F\u529B\u673A\u5236\u7684\u8F93\u51FA\u8F6C\u6362\u4E3A\u6700\u7EC8\u7684\u5C42\u8F93\u51FA\u3002\u4EE5\u4E0B\u662F\u4EE3\u7801\u7684\u8BE6\u7EC6\u6B65\u9AA4\u548C\u89E3\u91CA\uFF1A</p><ol><li><p><strong>\u8F6C\u7F6E\u6CE8\u610F\u529B\u8F93\u51FA</strong>\uFF1A<code>y = y.transpose(1, 2)</code> \u8FD9\u884C\u4EE3\u7801\u5C06 <code>scaled_dot_product_attention</code> \u51FD\u6570\u7684\u8F93\u51FA <code>y</code> \u8FDB\u884C\u8F6C\u7F6E\u3002\u539F\u59CB\u8F93\u51FA\u7684\u5F62\u72B6\u662F <code>(B, nh, T, T)</code>\uFF0C\u5176\u4E2D <code>B</code> \u662F\u6279\u6B21\u5927\u5C0F\uFF0C<code>nh</code> \u662F\u5934\u7684\u6570\u91CF\uFF0C<code>T</code> \u662F\u5E8F\u5217\u957F\u5EA6\uFF0C\u7B2C\u4E8C\u4E2A <code>T</code> \u8868\u793A\u81EA\u6CE8\u610F\u529B\uFF0C\u5373\u6BCF\u4E2A\u5143\u7D20\u90FD\u4E0E\u5E8F\u5217\u4E2D\u7684\u6BCF\u4E2A\u5176\u4ED6\u5143\u7D20\u8BA1\u7B97\u6CE8\u610F\u529B\u3002\u8F6C\u7F6E\u64CD\u4F5C\u5C06\u5F62\u72B6\u53D8\u4E3A <code>(B, T, nh, hs)</code>\uFF0C\u5176\u4E2D <code>hs</code> \u662F\u6BCF\u4E2A\u5934\u7684\u5C3A\u5BF8\u3002</p></li><li><p><strong>\u5185\u5B58\u8FDE\u7EED\u6027</strong>\uFF1A<code>y = y.contiguous()</code> \u8FD9\u884C\u4EE3\u7801\u786E\u4FDD\u5F20\u91CF <code>y</code> \u5728\u5185\u5B58\u4E2D\u662F\u8FDE\u7EED\u7684\u3002\u8FD9\u901A\u5E38\u5728\u8FDB\u884C\u89C6\u56FE\u64CD\u4F5C\uFF08view\uFF09\u4E4B\u524D\u4F7F\u7528\uFF0C\u4EE5\u907F\u514D\u7531\u4E8E\u975E\u8FDE\u7EED\u5185\u5B58\u5BFC\u81F4\u7684\u6027\u80FD\u95EE\u9898\u3002</p></li><li><p><strong>\u91CD\u5851\u8F93\u51FA</strong>\uFF1A<code>y = y.view(B, T, C)</code> \u8FD9\u884C\u4EE3\u7801\u5C06\u8F6C\u7F6E\u540E\u7684\u5F20\u91CF\u91CD\u5851\u4E3A <code>(B, T, C)</code> \u7684\u5F62\u72B6\uFF0C\u5176\u4E2D <code>C</code> \u662F\u539F\u59CB\u8F93\u5165\u7684\u7279\u5F81\u7EF4\u5EA6\uFF0C\u7B49\u4E8E <code>nh * hs</code>\u3002\u8FD9\u6837\uFF0C\u8F93\u51FA\u7684\u5F62\u72B6\u4E0E\u539F\u59CB\u8F93\u5165 <code>x</code> \u7684\u5F62\u72B6\u76F8\u5339\u914D\uFF0C\u4F46\u5185\u5BB9\u5DF2\u7ECF\u901A\u8FC7\u6CE8\u610F\u529B\u673A\u5236\u8FDB\u884C\u4E86\u52A0\u6743\u3002</p></li><li><p><strong>\u5E94\u7528\u6295\u5F71\u5C42</strong>\uFF1A<code>self.c_proj(y)</code> \u8FD9\u884C\u4EE3\u7801\u5C06\u8F93\u51FA <code>y</code> \u901A\u8FC7\u4E00\u4E2A\u7EBF\u6027\u5C42\uFF08\u4E5F\u79F0\u4E3A\u5168\u8FDE\u63A5\u5C42\u6216\u7A20\u5BC6\u5C42\uFF09\u8FDB\u884C\u6295\u5F71\u3002\u8FD9\u4E2A\u6295\u5F71\u5C42\u5C06\u7279\u5F81\u7EF4\u5EA6\u4ECE <code>C</code> \u6620\u5C04\u56DE\u539F\u59CB\u7684\u7279\u5F81\u7EF4\u5EA6\uFF0C\u786E\u4FDD\u8F93\u51FA\u53EF\u4EE5\u4E0E\u6A21\u578B\u7684\u4E0B\u4E00\u5C42\u517C\u5BB9\u3002</p></li><li><p><strong>\u5E94\u7528 Dropout</strong>\uFF1A<code>self.att_dropout</code> \u662F\u4E00\u4E2A <code>nn.Dropout</code> \u5B9E\u4F8B\uFF0C\u5B83\u5728\u8F93\u51FA\u4E0A\u5E94\u7528 dropout \u64CD\u4F5C\u3002\u5982\u679C\u6A21\u578B\u5904\u4E8E\u8BAD\u7EC3\u6A21\u5F0F\uFF08<code>self.training</code> \u4E3A <code>True</code>\uFF09\uFF0C\u5219\u4F7F\u7528 <code>self.dropout</code> \u6307\u5B9A\u7684\u6982\u7387\u8FDB\u884C dropout\uFF1B\u5982\u679C\u5904\u4E8E\u8BC4\u4F30\u6A21\u5F0F\uFF0C\u5219 dropout \u6982\u7387\u4E3A 0\uFF0C\u5373\u4E0D\u8FDB\u884C dropout\u3002</p></li><li><p><strong>\u8FD4\u56DE\u6700\u7EC8\u8F93\u51FA</strong>\uFF1A\u6700\u540E\uFF0C<code>return self.att_dropout(self.c_proj(y))</code> \u8FD9\u884C\u4EE3\u7801\u8FD4\u56DE\u7ECF\u8FC7\u6295\u5F71\u5C42\u548C dropout \u5904\u7406\u540E\u7684\u6700\u7EC8\u8F93\u51FA\u3002</p></li></ol><p>\u8FD9\u4E2A\u8FC7\u7A0B\u662F Transformer \u6A21\u578B\u4E2D\u81EA\u6CE8\u610F\u529B\u673A\u5236\u7684\u6807\u51C6\u540E\u5904\u7406\u6B65\u9AA4\uFF0C\u5B83\u786E\u4FDD\u4E86\u6CE8\u610F\u529B\u673A\u5236\u7684\u8F93\u51FA\u53EF\u4EE5\u88AB\u8FDB\u4E00\u6B65\u5904\u7406\uFF0C\u5E76\u4E14\u901A\u8FC7 dropout \u589E\u52A0\u4E86\u6A21\u578B\u7684\u6CDB\u5316\u80FD\u529B\u3002</p><p>User: class MLP(nn.Module): # MLP \u90E8\u5206\u53C2\u8003 llama MLP \u7ED3\u6784 def <strong>init</strong>(self,args): super().<strong>init</strong>() self.dropout = nn.Dropout(args.dropout) self.up_proj = nn.Linear(args.n_embed, 4<em>args.n_embed, bias = args.bias) self.down_c_proj = nn.Linear(4</em>args.n_embed, args.n_embed, bias = args.bias) # \u4F7F\u7528 relu self.act_func = nn.functional.relu # \u5B66\u4E60 llama \u589E\u52A0\u4E00\u4E2A\u95E8\u63A7 self.gate = nn.Linear(args.n_embed, 4*args.n_embed, bias = args.bias)</p><pre><code>def forward(self, x):
    # llama\u4EE3\u7801\u628AMLP\u8F93\u5165X\u5207\u7247\u6210slice\uFF0C\u6211\u8FD9\u91CC\u5C31\u4E0D\u5207\u7247\u4E86
    gate_proj = self.gate(x)
    x = self.up_proj(x)

    # llama\u4E2D\u7684\u4EE3\u7801\uFF1A
    # intermediate_states = (self.act_fn(gate_proj) * up_proj).split(slice, dim=2)
    # nanogpt\u7684
    # x = self.act_func(x)
    # \u53D1\u73B0\u8FD9\u91CC\u533A\u522B\u4E3B\u8981\u5728\uFF0Cnanogpt\u5BF9upproj\u7684x\u4F7F\u7528\u6FC0\u6D3B\u51FD\u6570\uFF0Cllama\u5219\u662F\u5BF9gate\u4F7F\u7528

    x = self.act_func(gate_proj)*x # \u548C\u95E8\u63A7gate\u6309\u7167\u5BF9\u5E94\u4F4D\u7F6E\u76F8\u4E58
    x = self.down_c_proj(x)
    return self.dropout(x)
</code></pre><p>class Block(nn.Module): # \u4E4B\u540E\u7528\u6765\u5806\u53E0\u7684 block def <strong>init</strong>(self, args): super().<strong>init</strong>() self.norm = RMS_Norm(args.n_embed) self.attn = flash_att(args) self.mlp = MLP(args)</p><pre><code>def forward(self,x):
    # \u4F7F\u7528pre norm
    x = x + self.attn(self.norm(x))# residual
    return x + self.mlp(self.norm(x)) # \u6B8B\u5DEE\u94FE\u63A5
</code></pre><p>class GPT(nn.Module): # llama \u548C GPT2 \u7684\u7F1D\u5408\u602A def <strong>init</strong>(self, args): super().<strong>init</strong>()</p><pre><code>    self.args = args
    self.transformer = nn.ModuleDict(dict(
        wte = nn.Embedding(args.vocab_size, args.n_embed),
        # \u83B7\u53D6token_embed
        wpe = nn.Embedding(args.block_size, args.n_embed),
        # \u4F7F\u7528\u4E00\u7EC4\u53EF\u5B66\u4E60\u7684\u4F4D\u7F6E\u7F16\u7801pos_embed
        drop = nn.Dropout(args.dropout),
        h = nn.ModuleList([Block(args) for i in range(args.n_layer)]),
        norm = RMS_Norm(args.n_embed)
    ))

    self.lm_head = nn.Linear(args.n_embed, args.vocab_size,bias=False)
    self.transformer.wte.weight = self.lm_head.weight
    # \u8FD9\u91CC\u4E0D\u662F\u7B80\u7B80\u5355\u5355\u7684\u8D4B\u503C\uFF0C\u800C\u662Fwte\u548Clm_head\u5171\u4EAB\u53C2\u6570
    # lm_head (n_embed,vocab_size)\u76F8\u5F53\u4E8E\u4ECE\u8BCD\u5411\u91CF\u5230token\u7684\u9884\u6D4B
    # wte ()

    self.apply(self._init_weights) # \u521D\u59CB\u5316\u6743\u91CD
    n_sum = 0
    # \u6B63\u6001\u5206\u5E03\u521D\u59CB\u5316attention\u7684\u6295\u5F71\u5C42\u548CMLP\u7684\u4E0B\u91C7\u6837
    for pname,p in self.named_parameters():
        n_sum = n_sum + p.numel() # \u987A\u5E26\u7EDF\u8BA1\u4E00\u4E0B\u53C2\u6570
        if pname.endswith(&#39;c_proj.weight&#39;):# c_proj\u662F\u4E0A\u4E0B\u6587\u611F\u77E5\u7684\u6295\u5F71\u5C42
            torch.nn.init.normal_(p,mean=0.0, std=0.02/math.sqrt(2*args.n_layer))

    print(f&quot;\u6A21\u578B\u53C2\u6570\u91CF\uFF1A{n_sum}&quot;)

def _init_weights(self,module):# \u521D\u59CB\u5316\u5148\u884C\u5C42\u548Cembedding
    if isinstance(module, nn.Linear):
        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
        if module.bias is not None:
            torch.nn.init.zeros_(module.bias)
    elif isinstance(module, nn.Embedding):
        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)

def forward(self, idx, targets = None): # targets\u662F\u8BAD\u7EC3\u65F6\u4F20\u5165\u7684\u76EE\u6807\uFF0C\u7528\u6765\u8BA1\u7B97\u4EA4\u53C9\u71B5loss
    device = idx.device
    B,T = idx.size()
    pos = torch.arange(0,T,dtype=torch.long,device=device) # \u4F4D\u7F6E

    # embedding
    token_embed = self.transformer.wte(idx) # (B,T,n_embed)
    pos_embed = self.transformer.wpe(pos)# (t,n_embed)
    # \u4F4D\u7F6Eembed\u53EF\u5B66\u4E60

    x = self.transformer.drop(token_embed+pos_embed) # \u5408\u5E76token\u548Cpos
    for block in self.transformer.h:
        x = block(x)
    x = self.transformer.norm(x)

    # \u7ECF\u8FC7lm_head
    # target= True \u8868\u793A\u6A21\u578B\u6B63\u5728\u8BAD\u7EC3\u9636\u6BB5\uFF0C\u9700\u8981\u56DE\u4F20loss
    # logits\u53D6\u6700\u540E\u4E00\u4E2A\uFF08-1\uFF09\u5373\u751F\u6210\u51FA\u6765\u7684\u4E1C\u897F\uFF0C\u8FD9\u6837\u548C\u76EE\u6807\u7684\u4E00\u4E2Atoken\u7EF4\u5EA6\u76F8\u540C\uFF0C\u624D\u597D\u8BA1\u7B97\u635F\u5931

    if targets is not None:
        logits = self.lm_head(x)
        # \u7528-1\u53D6\u6700\u540E\u4E00\u7EF4\u5EA6\u4E2A\uFF0C\u628A\u524D\u9762\u7684t\u4E22\u6389(t,vocab_size)-&gt;(vocab_size)
        loss = F.cross_entropy(logits.view(-1,logits.size(-1)),targets.view(-1),ignore_index=-1) # \u4EA4\u53C9\u71B5\u635F\u5931
    else: # generate\u65F6\u4F7F\u7528
        logits = self.lm_head(x)
        loss = None

    return logits,loss

def configure_optimizers(self,weight_decay,learning_rate,betas,device_type):
    # \u5EFA\u7ACB\u4E00\u4E2A\u4ECE\u53C2\u6570\u540D\u5230\u53C2\u6570\u7684dict
    param_dict = {pn:p for pn,p in self.named_parameters()}
    # \u518D\u53BB\u6389\u4E0D\u7528\u8BA1\u7B97\u68AF\u5EA6\u7684\u90E8\u5206
    param_dict = {pn:p for pn,p in param_dict.items() if p.requires_grad }

    # weight decay
    # \u5BF9\u4E8C\u7EF4\u7684\u53C2\u6570\u4F7F\u7528weight decay\uFF0C\u5176\u4ED6\u4E0D\u7528\uFF0C\u8FD9\u6837\u5206\u6210\u4E24\u7EC4
    decay_params = [p for pn,p in param_dict.items() if p.dim() &gt;= 2]
    nodecay_params = [p for pn,p in param_dict.items() if p.dim() &lt; 2]
    # dict.items()\u662F\u8FD4\u56DE\u4E00\u4E2Akey\u548Cvalue\u5143\u7EC4\u7684list [(k1,v1),(k2,v2)]
    optim_groups = [
        {&#39;params&#39;: decay_params, &#39;weight_decay&#39;: weight_decay},
        {&#39;params&#39;: nodecay_params, &#39;weight_decay&#39;: 0.0}
    ]
    # \u7EDF\u8BA1\u4E00\u4E0Bdecay\u548C\u4E0Ddecay\u7684\u53C2\u6570\u91CF
    num_decay = sum(p.numel() for p in decay_params)
    num_nodecay = sum(p.numel() for p in nodecay_params)
    print(f&quot;\u4F7F\u7528weight decay\u7684\u53C2\u6570\u91CF\u4E3A{num_decay},\u4E0D\u4F7F\u7528weight decay\u7684\u53C2\u6570\u91CF\u4E3A{num_nodecay}&quot;)

    # \u8FD9\u6BB5\u662F\u5EFA\u7ACB\u4E00\u4E2AAdamW\u4F18\u5316\u5668\uFF0C\u770B\u7248\u672C\u662F\u5426\u652F\u6301fused\u878D\u5408
    # \u5224\u65ADAdam\u7684\u53C2\u6570\u5B57\u5178\u4E2D\u662F\u5426\u5305\u542Bfused\uFF0C\u5982\u679C\u6709\uFF0C\u628A\u5B83\u6DFB\u52A0\u5230extra args\u4E2D
    fused_avail = &#39;fused&#39; in inspect.signature(torch.optim.AdamW).parameters
    # inspect.signature(fn).parameters\u8FD4\u56DE\u53C2\u6570list
    use_fused = fused_avail and device_type == &#39;cuda&#39; # \u5E76\u4E14\u8981\u6709gpu
    if use_fused:
        print(&quot;AdamW optimiser use fused!&quot;)
    extra_args = {&#39;fused&#39;:True} if use_fused else dict()
    optimizer = torch.optim.AdamW(optim_groups,lr = learning_rate,betas = betas,**extra_args)
    # betas:\u8BA1\u7B97\u68AF\u5EA6\u4EE5\u53CA\u68AF\u5EA6\u5E73\u65B9\u7684\u8FD0\u884C\u5E73\u5747\u503C\u7684\u7CFB\u6570
    # ** \u7528\u4E8E\u5C06\u4E00\u4E2A\u5B57\u5178\u89E3\u5305\u6210\u5173\u952E\u5B57\u53C2\u6570\u4F20\u9012\u7ED9\u51FD\u6570

    return optimizer

def generate(self, idx, max_generate_tokens, tempreture=1.0, top_k=None):
    # topp\uFF0Ctopk\u548Ctempreture\u7684\u6982\u5FF5
    # max_generate_tokens\u4E3A\u751F\u6210\u7684\u65B0tokens\u7684\u6700\u5927\u6570\u91CF
    for _ in range(max_generate_tokens):
        idx = idx if idx.shape[1] &lt;= self.args.block_size else idx[:,-self.args.block_size:]
        # \u5982\u679C\u5927\u4E8E\u4F20\u5165\u7684\u6700\u5927\u5927\u5C0F\u5219\u622A\u53D6\u540E\u9762\u4E00\u6BB5
        # \u5176\u5B9E\u8FD9\u91CC\u6211\u6709\u70B9\u4E0D\u61C2\uFF0C\u5982\u679Cidx\u957F\u5EA6\u4E0D\u8DB3blocksize\uFF0C\u662F\u54EA\u4E00\u6B65\u7ED9\u4ED6\u586B\u5145\u5230blocksize\u5927\u5C0F\u7684\u5462\uFF1F
        logits, _ = self(idx)
        logits = logits[:,-1,:]/tempreture #(B,T,C)\u53D6\u6700\u540E\u4E00\u4E2A\u5373\u65B0\u751F\u6210\u7684
        # tempreture\u66F4\u9AD8\uFF0C\u751F\u6210\u7684\u968F\u673A\u6027\u66F4\u9AD8
        # \u4ECE\u8FD9\u91CC\u80FD\u77E5\u9053\uFF0C\u662Fsoftmax\u7684\u6027\u8D28\u51B3\u5B9A\u7684\uFF0C\u6307\u6570\u51FD\u6570\u5C0F\u7684\u65F6\u5019\u53D8\u5316\u5C0F\uFF0C\u4E0D\u540Ctoken\u7684probs\u5DEE\u8DDD\u4F1A\u88AB\u51CF\u5C11\uFF0C\u968F\u673A\u6027\u5C31\u5F3A\u4E86

        if top_k is not None:
            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))
            logits[logits &lt; v[:, [-1]]] = -float(&#39;Inf&#39;) # \u5FFD\u7565topk\u540D\u4EE5\u540E\u7684token

        probs = F.softmax(logits,dim=-1)
        idx_next = torch.multinomial(probs, num_samples=1) # \u6309\u7167probs\u6982\u7387\u9009\u4E00\u4E2A
        idx = torch.cat((idx, idx_next), dim=1)

    return idx
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u5B9A\u4E49\u4E86\u4E00\u4E2A\u57FA\u4E8E Transformer \u67B6\u6784\u7684 GPT\uFF08General Purpose Transformer\uFF09\u6A21\u578B\uFF0C\u5305\u62EC\u51E0\u4E2A\u5173\u952E\u7EC4\u4EF6\uFF1A\u4E00\u4E2A\u591A\u5C42\u611F\u77E5\u5668\uFF08MLP\uFF09\u6A21\u5757\u3001\u4E00\u4E2A Transformer \u5757\uFF08Block\uFF09\u3001\u4EE5\u53CA\u6574\u4E2A GPT \u6A21\u578B\u672C\u8EAB\u3002\u6B64\u5916\uFF0C\u8FD8\u63D0\u4F9B\u4E86\u4E00\u4E2A\u751F\u6210\u6587\u672C\u7684\u65B9\u6CD5\u3002\u4E0B\u9762\u662F\u6BCF\u4E2A\u90E8\u5206\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><h3 id="mlp-\u7C7B" tabindex="-1">MLP \u7C7B <a class="header-anchor" href="#mlp-\u7C7B" aria-hidden="true">#</a></h3><ul><li><code>MLP</code> \u7C7B\u5B9E\u73B0\u4E86\u4E00\u4E2A\u4E24\u5C42\u7684\u524D\u9988\u795E\u7ECF\u7F51\u7EDC\uFF0C\u4F7F\u7528\u4E86 ReLU \u6FC0\u6D3B\u51FD\u6570\u548C\u4E00\u4E2A\u95E8\u63A7\u673A\u5236\uFF0C\u8FD9\u662F\u57FA\u4E8E &quot;llama&quot; \u6A21\u578B\u7684\u7ED3\u6784\u3002</li></ul><h3 id="block-\u7C7B" tabindex="-1">Block \u7C7B <a class="header-anchor" href="#block-\u7C7B" aria-hidden="true">#</a></h3><ul><li><code>Block</code> \u7C7B\u5B9A\u4E49\u4E86\u4E00\u4E2A Transformer \u5757\uFF0C\u5305\u62EC\u5C42\u5F52\u4E00\u5316\uFF08<code>RMS_Norm</code>\uFF09\u3001\u4E00\u4E2A Flash Attention \u673A\u5236\uFF08<code>flash_att</code>\uFF09\u548C\u4E00\u4E2A MLP\u3002\u8FD9\u4E2A\u5757\u4F7F\u7528\u4E86\u6B8B\u5DEE\u8FDE\u63A5\u548C\u5C42\u5F52\u4E00\u5316\u6765\u63D0\u9AD8\u6A21\u578B\u7684\u8868\u8FBE\u80FD\u529B\u548C\u7A33\u5B9A\u6027\u3002</li></ul><h3 id="gpt-\u7C7B" tabindex="-1">GPT \u7C7B <a class="header-anchor" href="#gpt-\u7C7B" aria-hidden="true">#</a></h3><ul><li><code>GPT</code> \u7C7B\u6784\u5EFA\u4E86\u6574\u4E2A\u6A21\u578B\uFF0C\u5305\u62EC\u8BCD\u5D4C\u5165\uFF08<code>wte</code>\uFF09\u3001\u4F4D\u7F6E\u7F16\u7801\uFF08<code>wpe</code>\uFF09\u3001\u591A\u4E2A Transformer \u5757\uFF08<code>h</code>\uFF09\u3001\u4E00\u4E2A\u6700\u7EC8\u7684\u5C42\u5F52\u4E00\u5316\uFF08<code>norm</code>\uFF09\u548C\u4E00\u4E2A\u7EBF\u6027\u8F93\u51FA\u5C42\uFF08<code>lm_head</code>\uFF09\u3002\u5B83\u8FD8\u5B9E\u73B0\u4E86\u6743\u91CD\u521D\u59CB\u5316\u3001\u524D\u5411\u4F20\u64AD\u548C\u4F18\u5316\u5668\u914D\u7F6E\u3002</li></ul><h4 id="\u521D\u59CB\u5316\u548C\u6743\u91CD\u914D\u7F6E" tabindex="-1">\u521D\u59CB\u5316\u548C\u6743\u91CD\u914D\u7F6E <a class="header-anchor" href="#\u521D\u59CB\u5316\u548C\u6743\u91CD\u914D\u7F6E" aria-hidden="true">#</a></h4><ul><li>\u5728\u521D\u59CB\u5316\u8FC7\u7A0B\u4E2D\uFF0C<code>GPT</code> \u7C7B\u4F7F\u7528 <code>nn.ModuleDict</code> \u6765\u5B58\u50A8\u6A21\u578B\u7684\u5404\u4E2A\u7EC4\u4EF6\uFF0C\u5E76\u5B9E\u73B0\u4E86\u6743\u91CD\u5171\u4EAB\uFF0C\u5176\u4E2D\u8BCD\u5D4C\u5165\uFF08<code>wte</code>\uFF09\u548C\u8BED\u8A00\u6A21\u578B\u5934\u90E8\uFF08<code>lm_head</code>\uFF09\u5171\u4EAB\u76F8\u540C\u7684\u6743\u91CD\u3002</li><li><code>_init_weights</code> \u65B9\u6CD5\u7528\u4E8E\u521D\u59CB\u5316\u6A21\u578B\u7684\u6743\u91CD\uFF0C\u4F7F\u7528\u4E86\u6B63\u6001\u5206\u5E03\u3002</li></ul><h4 id="\u524D\u5411\u4F20\u64AD" tabindex="-1">\u524D\u5411\u4F20\u64AD <a class="header-anchor" href="#\u524D\u5411\u4F20\u64AD" aria-hidden="true">#</a></h4><ul><li><code>forward</code> \u65B9\u6CD5\u5B9E\u73B0\u4E86\u6A21\u578B\u7684\u524D\u5411\u4F20\u64AD\u3002\u5B83\u9996\u5148\u5C06\u8F93\u5165\u7684\u7D22\u5F15\uFF08<code>idx</code>\uFF09\u8F6C\u6362\u4E3A\u8BCD\u5D4C\u5165\u548C\u4F4D\u7F6E\u7F16\u7801\uFF0C\u7136\u540E\u901A\u8FC7 Dropout\u3001\u591A\u4E2A Transformer \u5757\u548C\u6700\u7EC8\u7684\u5C42\u5F52\u4E00\u5316\u3002\u5982\u679C\u63D0\u4F9B\u4E86\u76EE\u6807\uFF08<code>targets</code>\uFF09\uFF0C\u5B83\u8FD8\u4F1A\u8BA1\u7B97\u4EA4\u53C9\u71B5\u635F\u5931\u3002</li></ul><h4 id="\u751F\u6210\u65B9\u6CD5" tabindex="-1">\u751F\u6210\u65B9\u6CD5 <a class="header-anchor" href="#\u751F\u6210\u65B9\u6CD5" aria-hidden="true">#</a></h4><ul><li><code>generate</code> \u65B9\u6CD5\u7528\u4E8E\u751F\u6210\u6587\u672C\u3002\u5B83\u63A5\u53D7\u521D\u59CB\u7D22\u5F15\uFF08<code>idx</code>\uFF09\u3001\u6700\u5927\u751F\u6210\u4EE4\u724C\u6570\uFF08<code>max_generate_tokens</code>\uFF09\u3001\u6E29\u5EA6\u53C2\u6570\uFF08<code>tempreture</code>\uFF09\u548C\u53EF\u9009\u7684 <code>top_k</code> \u53C2\u6570\u3002\u8FD9\u4E2A\u65B9\u6CD5\u901A\u8FC7\u91C7\u6837\u4ECE\u6A21\u578B\u751F\u6210\u65B0\u7684\u4EE4\u724C\uFF0C\u53EF\u4EE5\u9009\u62E9\u6027\u5730\u5E94\u7528\u6E29\u5EA6\u8C03\u6574\u548C top-k \u91C7\u6837\u6765\u63A7\u5236\u751F\u6210\u8FC7\u7A0B\u7684\u968F\u673A\u6027\u548C\u591A\u6837\u6027\u3002</li></ul><h4 id="\u4F18\u5316\u5668\u914D\u7F6E" tabindex="-1">\u4F18\u5316\u5668\u914D\u7F6E <a class="header-anchor" href="#\u4F18\u5316\u5668\u914D\u7F6E" aria-hidden="true">#</a></h4><ul><li><code>configure_optimizers</code> \u65B9\u6CD5\u7528\u4E8E\u914D\u7F6E AdamW \u4F18\u5316\u5668\uFF0C\u5B83\u6839\u636E\u53C2\u6570\u7684\u7EF4\u5EA6\u5C06\u53C2\u6570\u5206\u4E3A\u4E24\u7EC4\uFF0C\u5E76\u5BF9\u4E0D\u540C\u7EC4\u7684\u53C2\u6570\u5E94\u7528\u4E0D\u540C\u7684\u6743\u91CD\u8870\u51CF\u7B56\u7565\u3002</li></ul><p>\u6574\u4F53\u6765\u770B\uFF0C\u8FD9\u6BB5\u4EE3\u7801\u5C55\u793A\u4E86\u5982\u4F55\u6784\u5EFA\u548C\u4F7F\u7528\u4E00\u4E2A\u57FA\u4E8E Transformer \u7684\u8BED\u8A00\u6A21\u578B\uFF0C\u5305\u62EC\u5176\u8BAD\u7EC3\u548C\u751F\u6210\u6587\u672C\u7684\u80FD\u529B\u3002\u4EE3\u7801\u4E2D\u8FD8\u5305\u542B\u4E86\u4E00\u4E9B\u6CE8\u91CA\uFF0C\u6709\u52A9\u4E8E\u7406\u89E3\u6BCF\u4E2A\u90E8\u5206\u7684\u4F5C\u7528\u548C\u5B9E\u73B0\u7EC6\u8282\u3002</p><p>User: def <strong>init</strong>(self, args): super().<strong>init</strong>()</p><pre><code>    self.args = args
    self.transformer = nn.ModuleDict(dict(
        wte = nn.Embedding(args.vocab_size, args.n_embed),
        # \u83B7\u53D6token_embed
        wpe = nn.Embedding(args.block_size, args.n_embed),
        # \u4F7F\u7528\u4E00\u7EC4\u53EF\u5B66\u4E60\u7684\u4F4D\u7F6E\u7F16\u7801pos_embed
        drop = nn.Dropout(args.dropout),
        h = nn.ModuleList([Block(args) for i in range(args.n_layer)]),
        norm = RMS_Norm(args.n_embed)
    ))

    self.lm_head = nn.Linear(args.n_embed, args.vocab_size,bias=False)
    self.transformer.wte.weight = self.lm_head.weight
    # \u8FD9\u91CC\u4E0D\u662F\u7B80\u7B80\u5355\u5355\u7684\u8D4B\u503C\uFF0C\u800C\u662Fwte\u548Clm_head\u5171\u4EAB\u53C2\u6570
    # lm_head (n_embed,vocab_size)\u76F8\u5F53\u4E8E\u4ECE\u8BCD\u5411\u91CF\u5230token\u7684\u9884\u6D4B
    # wte ()

    self.apply(self._init_weights) # \u521D\u59CB\u5316\u6743\u91CD
    n_sum = 0
    # \u6B63\u6001\u5206\u5E03\u521D\u59CB\u5316attention\u7684\u6295\u5F71\u5C42\u548CMLP\u7684\u4E0B\u91C7\u6837
    for pname,p in self.named_parameters():
        n_sum = n_sum + p.numel() # \u987A\u5E26\u7EDF\u8BA1\u4E00\u4E0B\u53C2\u6570
        if pname.endswith(&#39;c_proj.weight&#39;):# c_proj\u662F\u4E0A\u4E0B\u6587\u611F\u77E5\u7684\u6295\u5F71\u5C42
            torch.nn.init.normal_(p,mean=0.0, std=0.02/math.sqrt(2*args.n_layer))

    print(f&quot;\u6A21\u578B\u53C2\u6570\u91CF\uFF1A{n_sum}&quot;)
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u662F GPT \u6A21\u578B\u7684\u521D\u59CB\u5316\u65B9\u6CD5 <code>__init__</code>\uFF0C\u5B83\u914D\u7F6E\u4E86\u6A21\u578B\u7684\u4E3B\u8981\u7EC4\u4EF6\u5E76\u521D\u59CB\u5316\u4E86\u6743\u91CD\u3002\u4EE5\u4E0B\u662F\u8BE6\u7EC6\u6B65\u9AA4\u548C\u5173\u952E\u70B9\uFF1A</p><ol><li><p><strong>\u7EE7\u627F\u548C\u521D\u59CB\u5316</strong>: <code>super().__init__()</code> \u8C03\u7528\u4E86\u57FA\u7C7B <code>nn.Module</code> \u7684\u6784\u9020\u51FD\u6570\uFF0C\u521D\u59CB\u5316\u4E86\u6A21\u578B\u3002</p></li><li><p><strong>\u53C2\u6570\u5B58\u50A8</strong>: <code>self.args</code> \u5B58\u50A8\u4E86\u6A21\u578B\u53C2\u6570\uFF0C\u8FD9\u4E9B\u53C2\u6570\u901A\u8FC7 <code>args</code> \u5BF9\u8C61\u4F20\u9012\u8FDB\u6765\u3002</p></li><li><p><strong>ModuleDict \u521B\u5EFA</strong>: \u4F7F\u7528 <code>nn.ModuleDict</code> \u521B\u5EFA\u4E86\u4E00\u4E2A\u540D\u4E3A <code>self.transformer</code> \u7684\u5B57\u5178\uFF0C\u5B83\u5C06\u6A21\u578B\u7EC4\u4EF6\u540D\u79F0\u6620\u5C04\u5230\u76F8\u5E94\u7684\u6A21\u5757\u3002</p><ul><li><code>wte</code>: \u8BCD\u5D4C\u5165\u5C42\uFF0C\u5C06\u8BCD\u6C47\u6620\u5C04\u5230\u5D4C\u5165\u7A7A\u95F4\u3002</li><li><code>wpe</code>: \u4F4D\u7F6E\u7F16\u7801\u5C42\uFF0C\u4E3A\u5E8F\u5217\u4E2D\u6BCF\u4E2A\u4F4D\u7F6E\u63D0\u4F9B\u53EF\u5B66\u4E60\u7684\u5D4C\u5165\u3002</li><li><code>drop</code>: Dropout \u5C42\uFF0C\u7528\u4E8E\u6B63\u5219\u5316\u4EE5\u9632\u6B62\u8FC7\u62DF\u5408\u3002</li><li><code>h</code>: \u4E00\u4E2A\u7531\u591A\u4E2A <code>Block</code> \u7EC4\u6210\u7684\u5217\u8868\uFF0C\u6BCF\u4E2A <code>Block</code> \u5305\u542B\u6CE8\u610F\u529B\u673A\u5236\u548C MLP\u3002</li><li><code>norm</code>: \u6700\u7EC8\u7684\u5C42\u5F52\u4E00\u5316\u5C42\uFF0C\u7528\u4E8E\u89C4\u8303\u5316\u6A21\u578B\u8F93\u51FA\u3002</li></ul></li><li><p><strong>\u5171\u4EAB\u6743\u91CD</strong>: <code>self.lm_head</code> \u662F\u4E00\u4E2A\u7EBF\u6027\u5C42\uFF0C\u7528\u4E8E\u5C06\u6A21\u578B\u7684\u8F93\u51FA\u8F6C\u6362\u4E3A\u8BCD\u6C47\u8868\u4E0A\u7684\u6982\u7387\u5206\u5E03\u3002\u901A\u8FC7 <code>self.transformer.wte.weight = self.lm_head.weight</code>\uFF0C\u5B9E\u73B0\u4E86\u8BCD\u5D4C\u5165\u5C42 (<code>wte</code>) \u548C\u8BED\u8A00\u6A21\u578B\u5934\u90E8 (<code>lm_head)</code> \u7684\u6743\u91CD\u5171\u4EAB\u3002</p></li><li><p><strong>\u6743\u91CD\u521D\u59CB\u5316</strong>: <code>self.apply(self._init_weights)</code> \u5E94\u7528\u4E86\u81EA\u5B9A\u4E49\u7684\u6743\u91CD\u521D\u59CB\u5316\u65B9\u6CD5 <code>_init_weights</code> \u5230\u6A21\u578B\u7684\u6240\u6709\u5B50\u6A21\u5757\u3002</p></li><li><p><strong>\u53C2\u6570\u91CF\u7EDF\u8BA1</strong>: <code>n_sum</code> \u53D8\u91CF\u7528\u4E8E\u7EDF\u8BA1\u6A21\u578B\u7684\u603B\u53C2\u6570\u91CF\u3002\u521D\u59CB\u5316\u8FC7\u7A0B\u4E2D\uFF0C\u901A\u8FC7\u904D\u5386\u6A21\u578B\u7684\u547D\u540D\u53C2\u6570\u5E76\u4F7F\u7528 <code>p.numel()</code> \u8BA1\u7B97\u6BCF\u4E2A\u53C2\u6570\u7684\u5143\u7D20\u6570\u91CF\u6765\u5B9E\u73B0\u3002</p></li><li><p><strong>\u7279\u6B8A\u521D\u59CB\u5316</strong>: \u5BF9\u4E8E\u4EE5 &#39;c_proj.weight&#39; \u7ED3\u5C3E\u7684\u53C2\u6570\u540D\uFF08\u5373\u4E0A\u4E0B\u6587\u611F\u77E5\u7684\u6295\u5F71\u5C42\uFF09\uFF0C\u4F7F\u7528\u6B63\u6001\u5206\u5E03\u8FDB\u884C\u521D\u59CB\u5316\uFF0C\u5176\u6807\u51C6\u5DEE\u662F\u4F9D\u636E\u53C2\u6570\u7684\u7EF4\u5EA6\u548C\u5C42\u6570\u6765\u8C03\u6574\u7684\u3002</p></li><li><p><strong>\u6253\u5370\u53C2\u6570\u91CF</strong>: \u6700\u540E\uFF0C\u6253\u5370\u51FA\u6A21\u578B\u7684\u603B\u53C2\u6570\u91CF\uFF0C\u8FD9\u6709\u52A9\u4E8E\u4E86\u89E3\u6A21\u578B\u7684\u5927\u5C0F\u3002</p></li></ol><p>\u901A\u8FC7\u8FD9\u79CD\u65B9\u5F0F\uFF0CGPT \u6A21\u578B\u88AB\u914D\u7F6E\u4E3A\u5177\u6709\u591A\u4E2A Transformer \u5757\uFF0C\u6BCF\u5757\u90FD\u5305\u542B\u81EA\u6CE8\u610F\u529B\u548C\u524D\u9988\u7F51\u7EDC\uFF0C\u4EE5\u53CA\u8BCD\u5D4C\u5165\u548C\u4F4D\u7F6E\u7F16\u7801\u5C42\u3002\u6743\u91CD\u5171\u4EAB\u51CF\u5C11\u4E86\u6A21\u578B\u7684\u53C2\u6570\u6570\u91CF\uFF0C\u800C\u5B9A\u5236\u7684\u521D\u59CB\u5316\u65B9\u6CD5\u6709\u52A9\u4E8E\u6A21\u578B\u7684\u5B66\u4E60\u3002</p><p>User: self.transformer = nn.ModuleDict(dict( wte = nn.Embedding(args.vocab_size, args.n_embed), # \u83B7\u53D6 token_embed wpe = nn.Embedding(args.block_size, args.n_embed), # \u4F7F\u7528\u4E00\u7EC4\u53EF\u5B66\u4E60\u7684\u4F4D\u7F6E\u7F16\u7801 pos_embed drop = nn.Dropout(args.dropout), h = nn.ModuleList([Block(args) for i in range(args.n_layer)]), norm = RMS_Norm(args.n_embed) ))</p><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u4F7F\u7528 PyTorch \u7684 <code>nn.ModuleDict</code> \u521B\u5EFA\u4E86\u4E00\u4E2A\u5305\u542B\u6A21\u578B\u5404\u4E2A\u7EC4\u4EF6\u7684\u5B57\u5178\uFF0C\u6BCF\u4E2A\u7EC4\u4EF6\u90FD\u6620\u5C04\u5230\u4E00\u4E2A\u552F\u4E00\u7684\u540D\u79F0\u3002<code>ModuleDict</code> \u7EE7\u627F\u81EA Python \u7684\u5B57\u5178\uFF0C\u5E76\u6DFB\u52A0\u4E86\u5BF9\u952E\u4E3A\u6A21\u5757\u540D\u79F0\u3001\u503C\u4E3A <code>nn.Module</code> \u7684\u7279\u6B8A\u5904\u7406\u3002\u4E0B\u9762\u662F\u5BF9\u5404\u4E2A\u7EC4\u4EF6\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ol><li><p><strong>wte (Word Token Embedding)</strong>:</p><ul><li><code>nn.Embedding(args.vocab_size, args.n_embed)</code> \u521B\u5EFA\u4E86\u4E00\u4E2A\u8BCD\u5D4C\u5165\u5C42\uFF0C\u5B83\u5C06\u8BCD\u6C47\u8868\u4E2D\u7684\u6BCF\u4E2A\u5355\u8BCD\uFF08token\uFF09\u6620\u5C04\u5230\u4E00\u4E2A\u56FA\u5B9A\u5927\u5C0F\u7684\u5D4C\u5165\u5411\u91CF\u3002<code>args.vocab_size</code> \u662F\u8BCD\u6C47\u8868\u7684\u5927\u5C0F\uFF0C\u800C <code>args.n_embed</code> \u662F\u5D4C\u5165\u5411\u91CF\u7684\u7EF4\u5EA6\u3002</li></ul></li><li><p><strong>wpe (Weighted Positional Encoding)</strong>:</p><ul><li><code>nn.Embedding(args.block_size, args.n_embed)</code> \u521B\u5EFA\u4E86\u4F4D\u7F6E\u7F16\u7801\u5C42\uFF0C\u4E3A\u8F93\u5165\u5E8F\u5217\u4E2D\u7684\u6BCF\u4E2A\u4F4D\u7F6E\u63D0\u4F9B\u4E00\u7EC4\u53EF\u5B66\u4E60\u7684\u5D4C\u5165\u5411\u91CF\u3002<code>args.block_size</code> \u662F\u6A21\u578B\u5904\u7406\u7684\u6700\u5927\u5E8F\u5217\u957F\u5EA6\uFF0C<code>args.n_embed</code> \u662F\u5D4C\u5165\u5411\u91CF\u7684\u7EF4\u5EA6\u3002</li></ul></li><li><p><strong>drop (Dropout)</strong>:</p><ul><li><code>nn.Dropout(args.dropout)</code> \u521B\u5EFA\u4E86\u4E00\u4E2A Dropout \u5C42\uFF0C\u7528\u4E8E\u5728\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\u968F\u673A\u4E22\u5F03\u4E00\u4E9B\u6FC0\u6D3B\u503C\uFF0C\u4EE5\u51CF\u5C11\u8FC7\u62DF\u5408\u7684\u98CE\u9669\u3002<code>args.dropout</code> \u662F\u4E22\u5F03\u7684\u6982\u7387\u3002</li></ul></li><li><p><strong>h (Hidden Layers)</strong>:</p><ul><li><code>nn.ModuleList([Block(args) for i in range(args.n_layer)])</code> \u521B\u5EFA\u4E86\u4E00\u4E2A\u7531\u591A\u4E2A <code>Block</code> \u7EC4\u6210\u7684\u5217\u8868\uFF0C\u6BCF\u4E2A <code>Block</code> \u5B9E\u4F8B\u5316\u4E86\u4E00\u4E2A Transformer \u5C42\uFF0C\u5305\u542B\u81EA\u6CE8\u610F\u529B\u673A\u5236\u548C\u524D\u9988\u7F51\u7EDC\u3002<code>args.n_layer</code> \u6307\u5B9A\u4E86\u6A21\u578B\u4E2D Transformer \u5C42\u7684\u6570\u91CF\u3002</li></ul></li><li><p><strong>norm (Normalization)</strong>:</p><ul><li><code>RMS_Norm(args.n_embed)</code> \u521B\u5EFA\u4E86\u4E00\u4E2A\u5C42\u5F52\u4E00\u5316\u5C42\uFF0C\u7528\u4E8E\u89C4\u8303\u5316\u6A21\u578B\u7684\u8F93\u51FA\uFF0C\u4EE5\u7A33\u5B9A\u8BAD\u7EC3\u8FC7\u7A0B\u3002<code>args.n_embed</code> \u662F\u5F52\u4E00\u5316\u5C42\u7684\u8F93\u5165\u7EF4\u5EA6\u3002</li></ul></li></ol><p>\u4F7F\u7528 <code>nn.ModuleDict</code> \u7684\u597D\u5904\u662F\u5B83\u63D0\u4F9B\u4E86\u4E00\u79CD\u6E05\u6670\u7684\u65B9\u5F0F\u6765\u8BBF\u95EE\u548C\u64CD\u4F5C\u6A21\u578B\u7684\u5404\u4E2A\u7EC4\u4EF6\u3002\u4F8B\u5982\uFF0C\u5982\u679C\u4F60\u60F3\u8981\u83B7\u53D6\u8BCD\u5D4C\u5165\u5C42\uFF0C\u4F60\u53EF\u4EE5\u76F4\u63A5\u901A\u8FC7\u540D\u79F0 <code>self.transformer[&#39;wte&#39;]</code> \u6765\u8BBF\u95EE\u5B83\u3002\u6B64\u5916\uFF0C<code>ModuleDict</code> \u4F1A\u81EA\u52A8\u5C06\u5B57\u5178\u4E2D\u7684\u6240\u6709\u6A21\u5757\u6CE8\u518C\u4E3A\u6A21\u578B\u7684\u5B50\u6A21\u5757\uFF0C\u8FD9\u610F\u5473\u7740\u5B83\u4EEC\u5C06\u88AB\u6B63\u786E\u5730\u7EB3\u5165\u6A21\u578B\u7684\u53C2\u6570\u5217\u8868\uFF0C\u5E76\u4E14 PyTorch \u7684\u4F18\u5316\u5668\u548C\u8BAD\u7EC3\u5FAA\u73AF\u5C06\u80FD\u591F\u8BC6\u522B\u5E76\u64CD\u4F5C\u5B83\u4EEC\u3002</p><p>\u8FD9\u79CD\u7EC4\u7EC7\u65B9\u5F0F\u4F7F\u5F97\u6A21\u578B\u7684\u7ED3\u6784\u66F4\u52A0\u6A21\u5757\u5316\uFF0C\u6613\u4E8E\u7406\u89E3\u548C\u7EF4\u62A4\u3002\u540C\u65F6\uFF0C\u5B83\u4E5F\u65B9\u4FBF\u4E86\u6A21\u578B\u7EC4\u4EF6\u7684\u6269\u5C55\u548C\u4FEE\u6539\u3002</p><p>User: nn.Embedding</p><p>Kimi: <code>nn.Embedding</code> \u662F PyTorch \u4E2D\u7684\u4E00\u4E2A\u6A21\u5757\uFF0C\u7528\u4E8E\u5C06\u79BB\u6563\u7684\u8F93\u5165\u6570\u636E\uFF08\u5982\u5355\u8BCD\u6216\u5B57\u7B26\u7684\u7D22\u5F15\uFF09\u5D4C\u5165\u5230\u8FDE\u7EED\u7684\u5411\u91CF\u7A7A\u95F4\u4E2D\u3002\u8FD9\u79CD\u5D4C\u5165\u901A\u5E38\u7528\u4E8E\u5904\u7406\u81EA\u7136\u8BED\u8A00\u5904\u7406\uFF08NLP\uFF09\u4E2D\u7684\u8BCD\u6C47\u8868\uFF0C\u4EE5\u53CA\u5176\u4ED6\u7C7B\u578B\u7684\u5206\u7C7B\u6570\u636E\u3002</p><p>\u4EE5\u4E0B\u662F <code>nn.Embedding</code> \u7684\u4E00\u4E9B\u5173\u952E\u7279\u6027\u548C\u7528\u6CD5\uFF1A</p><ol><li><p><strong>\u53C2\u6570</strong>:</p><ul><li><code>num_embeddings</code>: \u8BCD\u6C47\u8868\u7684\u5927\u5C0F\uFF0C\u5373\u9700\u8981\u5D4C\u5165\u7684\u4E0D\u540C\u5143\u7D20\u7684\u6570\u91CF\u3002</li><li><code>embedding_dim</code>: \u6BCF\u4E2A\u5143\u7D20\u5D4C\u5165\u5411\u91CF\u7684\u7EF4\u5EA6\u3002</li></ul></li><li><p><strong>\u6743\u91CD</strong>:</p><ul><li><code>nn.Embedding</code> \u6709\u4E00\u4E2A\u53EF\u5B66\u4E60\u7684\u6743\u91CD\u77E9\u9635\uFF0C\u5176\u5F62\u72B6\u4E3A <code>(num_embeddings, embedding_dim)</code>\u3002\u8FD9\u4E2A\u77E9\u9635\u5728\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\u88AB\u4F18\u5316\uFF0C\u4EE5\u6700\u597D\u5730\u8868\u793A\u8F93\u5165\u6570\u636E\u3002</li></ul></li><li><p><strong>\u4F7F\u7528</strong>:</p><ul><li>\u5C06\u4E00\u4E2A\u5305\u542B\u7D22\u5F15\u7684\u5F20\u91CF\u4F5C\u4E3A\u8F93\u5165\uFF0C<code>nn.Embedding</code> \u4F1A\u8F93\u51FA\u4E00\u4E2A\u5F62\u72B6\u4E3A <code>(batch_size, num_embeddings, embedding_dim)</code> \u7684\u5F20\u91CF\uFF0C\u5176\u4E2D <code>batch_size</code> \u662F\u8F93\u5165\u5F20\u91CF\u4E2D\u7D22\u5F15\u5E8F\u5217\u7684\u6570\u91CF\u3002</li></ul></li><li><p><strong>\u521D\u59CB\u5316</strong>:</p><ul><li>\u5D4C\u5165\u6743\u91CD\u901A\u5E38\u4F7F\u7528\u968F\u673A\u521D\u59CB\u5316\uFF0C\u4F46 PyTorch \u4E5F\u63D0\u4F9B\u4E86\u4E0D\u540C\u7684\u521D\u59CB\u5316\u65B9\u6CD5\uFF0C\u5982\u5747\u5300\u5206\u5E03\u3001\u6B63\u6001\u5206\u5E03\u7B49\uFF0C\u53EF\u4EE5\u901A\u8FC7 <code>torch.nn.init</code> \u6A21\u5757\u8FDB\u884C\u3002</li></ul></li><li><p><strong>\u5171\u4EAB\u6743\u91CD</strong>:</p><ul><li>\u5728\u67D0\u4E9B\u60C5\u51B5\u4E0B\uFF0C\u4F60\u53EF\u80FD\u5E0C\u671B\u4E24\u4E2A\u4E0D\u540C\u7684\u5D4C\u5165\u5C42\u5171\u4EAB\u76F8\u540C\u7684\u6743\u91CD\u77E9\u9635\u3002\u8FD9\u53EF\u4EE5\u901A\u8FC7\u76F4\u63A5\u5C06\u4E00\u4E2A\u5D4C\u5165\u5C42\u7684\u6743\u91CD\u8D4B\u503C\u7ED9\u53E6\u4E00\u4E2A\u5C42\u6765\u5B9E\u73B0\u3002</li></ul></li><li><p><strong>\u7A00\u758F\u6027</strong>:</p><ul><li>\u5982\u679C\u8BCD\u6C47\u8868\u975E\u5E38\u5927\uFF0C\u4F7F\u7528 <code>nn.Embedding</code> \u53EF\u80FD\u4F1A\u5360\u7528\u5927\u91CF\u5185\u5B58\u3002\u5728\u8FD9\u79CD\u60C5\u51B5\u4E0B\uFF0C\u53EF\u4EE5\u8003\u8651\u4F7F\u7528\u7A00\u758F\u5D4C\u5165\u6765\u51CF\u5C11\u5185\u5B58\u4F7F\u7528\u3002</li></ul></li><li><p><strong>\u4F18\u5316</strong>:</p><ul><li>\u67D0\u4E9B\u786C\u4EF6\u5E73\u53F0\uFF08\u5982 GPU\uFF09\u5BF9\u5D4C\u5165\u5C42\u7684\u4F18\u5316\u53EF\u4EE5\u63D0\u9AD8\u6027\u80FD\u3002PyTorch \u4F1A\u81EA\u52A8\u5229\u7528\u8FD9\u4E9B\u4F18\u5316\uFF0C\u4F46\u6839\u636E\u5177\u4F53\u60C5\u51B5\uFF0C\u53EF\u80FD\u9700\u8981\u8C03\u6574\u6279\u6B21\u5927\u5C0F\u6216\u5176\u4ED6\u53C2\u6570\u4EE5\u83B7\u5F97\u6700\u4F73\u6027\u80FD\u3002</li></ul></li></ol><p>\u4E0B\u9762\u662F\u4E00\u4E2A\u7B80\u5355\u7684\u4F7F\u7528\u793A\u4F8B\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> torch</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> torch</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">nn </span><span style="color:#F97583;">as</span><span style="color:#B392F0;"> nn</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6B737C;"># \u5047\u8BBE\u6211\u4EEC\u6709\u4E00\u4E2A\u8BCD\u6C47\u8868\u5927\u5C0F\u4E3A1000\uFF0C\u5D4C\u5165\u7EF4\u5EA6\u4E3A300</span></span>
<span class="line"><span style="color:#B392F0;">vocab_size </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">1000</span></span>
<span class="line"><span style="color:#B392F0;">embedding_dim </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">300</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6B737C;"># \u521B\u5EFA\u5D4C\u5165\u5C42</span></span>
<span class="line"><span style="color:#B392F0;">embedding_layer </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> nn</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">Embedding</span><span style="color:#BBBBBB;">(num_embeddings</span><span style="color:#F97583;">=</span><span style="color:#BBBBBB;">vocab_size, embedding_dim</span><span style="color:#F97583;">=</span><span style="color:#BBBBBB;">embedding_dim)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6B737C;"># \u5047\u8BBE\u6211\u4EEC\u6709\u4E00\u4E9B\u5355\u8BCD\u7D22\u5F15\uFF0C\u5F62\u72B6\u4E3A (batch_size, sequence_length)</span></span>
<span class="line"><span style="color:#B392F0;">input_indices </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> torch</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">randint</span><span style="color:#BBBBBB;">(</span><span style="color:#F8F8F8;">0</span><span style="color:#BBBBBB;">, vocab_size, (</span><span style="color:#F8F8F8;">2</span><span style="color:#BBBBBB;">, </span><span style="color:#F8F8F8;">5</span><span style="color:#BBBBBB;">))</span><span style="color:#B392F0;">  </span><span style="color:#6B737C;"># \u968F\u673A\u751F\u6210\u4E00\u4E9B\u7D22\u5F15\u4F5C\u4E3A\u793A\u4F8B</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6B737C;"># \u901A\u8FC7\u5D4C\u5165\u5C42\u83B7\u53D6\u5D4C\u5165\u5411\u91CF</span></span>
<span class="line"><span style="color:#B392F0;">embedded_vectors </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> embedding_layer</span><span style="color:#BBBBBB;">(input_indices)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#B392F0;">print</span><span style="color:#BBBBBB;">(embedded_vectors.shape)</span><span style="color:#B392F0;">  </span><span style="color:#6B737C;"># \u8F93\u51FA: (batch_size, sequence_length, embedding_dim)</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><p>\u5728\u8FD9\u4E2A\u793A\u4F8B\u4E2D\uFF0C<code>input_indices</code> \u662F\u4E00\u4E2A\u5305\u542B\u968F\u673A\u7D22\u5F15\u7684\u5F20\u91CF\uFF0C\u4EE3\u8868\u4E00\u6279\u5E8F\u5217\u3002<code>embedding_layer</code> \u5C06\u8FD9\u4E9B\u7D22\u5F15\u8F6C\u6362\u4E3A\u5BF9\u5E94\u7684\u5D4C\u5165\u5411\u91CF\u3002</p><p>User: nn.ModuleDict</p><p>Kimi: <code>nn.ModuleDict</code> \u662F PyTorch \u4E2D\u7684\u4E00\u4E2A\u5BB9\u5668\u7C7B\uFF0C\u7528\u4E8E\u5B58\u50A8\u548C\u7BA1\u7406\u4E00\u4E2A\u6709\u5E8F\u5B57\u5178\uFF08OrderedDict\uFF09\u7684 <code>nn.Module</code> \u5BF9\u8C61\u3002\u5B83\u7EE7\u627F\u81EA Python \u7684\u5B57\u5178\uFF0C\u5E76\u6DFB\u52A0\u4E86\u5BF9\u6A21\u578B\u7EC4\u4EF6\u7684\u7279\u6B8A\u5904\u7406\uFF0C\u4F7F\u5F97\u8FD9\u4E9B\u7EC4\u4EF6\u53EF\u4EE5\u4F5C\u4E3A\u795E\u7ECF\u7F51\u7EDC\u6A21\u578B\u7684\u5B50\u6A21\u5757\u8FDB\u884C\u6CE8\u518C\u548C\u8DDF\u8E2A\u3002\u4EE5\u4E0B\u662F <code>nn.ModuleDict</code> \u7684\u4E00\u4E9B\u5173\u952E\u7279\u6027\uFF1A</p><ol><li><p><strong>\u6709\u5E8F\u6027</strong>: <code>ModuleDict</code> \u4FDD\u7559\u4E86\u952E\u7684\u987A\u5E8F\uFF0C\u8FD9\u610F\u5473\u7740\u5728\u8FED\u4EE3\u6216\u5904\u7406\u5B57\u5178\u4E2D\u7684\u6A21\u5757\u65F6\uFF0C\u5B83\u4EEC\u5C06\u6309\u7167\u5B83\u4EEC\u88AB\u6DFB\u52A0\u7684\u987A\u5E8F\u51FA\u73B0\u3002</p></li><li><p><strong>\u6A21\u5757\u6CE8\u518C</strong>: \u5F53\u4F60\u5411 <code>ModuleDict</code> \u6DFB\u52A0\u4E00\u4E2A <code>nn.Module</code> \u5BF9\u8C61\u65F6\uFF0C\u8FD9\u4E2A\u5BF9\u8C61\u4F1A\u81EA\u52A8\u88AB\u6CE8\u518C\u4E3A\u6A21\u578B\u7684\u5B50\u6A21\u5757\u3002\u8FD9\u4F7F\u5F97 PyTorch \u7684\u8BAD\u7EC3\u5FAA\u73AF\u80FD\u591F\u8BC6\u522B\u5E76\u66F4\u65B0\u8FD9\u4E9B\u5B50\u6A21\u5757\u7684\u53C2\u6570\u3002</p></li><li><p><strong>\u8BBF\u95EE\u5B50\u6A21\u5757</strong>: \u4F60\u53EF\u4EE5\u4F7F\u7528\u6807\u51C6\u7684\u5B57\u5178\u8BED\u6CD5\u901A\u8FC7\u952E\u6765\u8BBF\u95EE <code>ModuleDict</code> \u4E2D\u7684\u6A21\u5757\u3002\u4F8B\u5982\uFF0C<code>module_dict[key]</code> \u5C06\u8FD4\u56DE\u4E0E\u952E\u76F8\u5173\u8054\u7684\u6A21\u5757\u3002</p></li><li><p><strong>\u7279\u6B8A\u65B9\u6CD5</strong>: <code>ModuleDict</code> \u91CD\u5199\u4E86 <code>__getattr__</code> \u548C <code>__setattr__</code> \u65B9\u6CD5\uFF0C\u4EE5\u4FBF\u53EF\u4EE5\u76F4\u63A5\u901A\u8FC7\u5C5E\u6027\u8BBF\u95EE\u6216\u8BBE\u7F6E\u5B57\u5178\u4E2D\u7684\u952E\u503C\u5BF9\u3002</p></li><li><p><strong>\u5D4C\u5957\u7ED3\u6784</strong>: <code>ModuleDict</code> \u53EF\u4EE5\u5305\u542B\u5176\u4ED6 <code>ModuleDict</code> \u6216 <code>nn.ModuleList</code>\uFF0C\u4ECE\u800C\u652F\u6301\u590D\u6742\u7684\u6A21\u578B\u7ED3\u6784\u3002</p></li><li><p><strong>\u8BAD\u7EC3\u548C\u8BC4\u4F30\u6A21\u5F0F</strong>: <code>ModuleDict</code> \u4E2D\u7684\u6A21\u5757\u53EF\u4EE5\u7EDF\u4E00\u5730\u5207\u6362\u5230\u8BAD\u7EC3\u6A21\u5F0F\u6216\u8BC4\u4F30\u6A21\u5F0F\uFF0C\u4F7F\u7528 <code>.train()</code> \u6216 <code>.eval()</code> \u65B9\u6CD5\u3002</p></li><li><p><strong>\u53C2\u6570\u8FED\u4EE3</strong>: \u5F53\u4F60\u8FED\u4EE3 <code>ModuleDict</code> \u7684\u53C2\u6570\u65F6\uFF0C\u5B83\u5C06\u8FED\u4EE3\u6240\u6709\u5B50\u6A21\u5757\u7684\u53C2\u6570\uFF0C\u8FD9\u5728\u81EA\u5B9A\u4E49\u521D\u59CB\u5316\u6216\u5904\u7406\u53C2\u6570\u65F6\u975E\u5E38\u6709\u7528\u3002</p></li><li><p><strong>\u4FDD\u5B58\u548C\u52A0\u8F7D</strong>: <code>ModuleDict</code> \u4E0E PyTorch \u7684\u4FDD\u5B58\u548C\u52A0\u8F7D\u673A\u5236\u517C\u5BB9\uFF0C\u53EF\u4EE5\u5F88\u5BB9\u6613\u5730\u4FDD\u5B58\u6574\u4E2A\u6A21\u578B\u7684\u72B6\u6001\u6216\u8005\u52A0\u8F7D\u9884\u8BAD\u7EC3\u7684\u6743\u91CD\u3002</p></li></ol><p>\u4E0B\u9762\u662F\u4E00\u4E2A\u7B80\u5355\u7684\u4F7F\u7528\u793A\u4F8B\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> torch</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> torch</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">nn </span><span style="color:#F97583;">as</span><span style="color:#B392F0;"> nn</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#B392F0;"> MyModel(nn</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">Module):</span></span>
<span class="line"><span style="color:#B392F0;">    </span><span style="color:#F97583;">def</span><span style="color:#B392F0;"> __init__(</span><span style="color:#FF9800;">self</span><span style="color:#B392F0;">):</span></span>
<span class="line"><span style="color:#B392F0;">        </span><span style="color:#79B8FF;">super</span><span style="color:#BBBBBB;">(MyModel, self).</span><span style="color:#B392F0;">__init__</span><span style="color:#BBBBBB;">()</span></span>
<span class="line"><span style="color:#B392F0;">        self</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">features </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> nn</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">ModuleDict</span><span style="color:#BBBBBB;">({</span></span>
<span class="line"><span style="color:#BBBBBB;">            </span><span style="color:#FFAB70;">&#39;conv1&#39;</span><span style="color:#BBBBBB;">: nn.</span><span style="color:#B392F0;">Conv2d</span><span style="color:#BBBBBB;">(</span><span style="color:#F8F8F8;">1</span><span style="color:#BBBBBB;">, </span><span style="color:#F8F8F8;">20</span><span style="color:#BBBBBB;">, </span><span style="color:#F8F8F8;">5</span><span style="color:#BBBBBB;">),</span></span>
<span class="line"><span style="color:#BBBBBB;">            </span><span style="color:#FFAB70;">&#39;conv2&#39;</span><span style="color:#BBBBBB;">: nn.</span><span style="color:#B392F0;">Conv2d</span><span style="color:#BBBBBB;">(</span><span style="color:#F8F8F8;">20</span><span style="color:#BBBBBB;">, </span><span style="color:#F8F8F8;">20</span><span style="color:#BBBBBB;">, </span><span style="color:#F8F8F8;">5</span><span style="color:#BBBBBB;">)</span></span>
<span class="line"><span style="color:#BBBBBB;">        })</span></span>
<span class="line"></span>
<span class="line"><span style="color:#B392F0;">model </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> MyModel</span><span style="color:#BBBBBB;">()</span></span>
<span class="line"><span style="color:#B392F0;">print</span><span style="color:#BBBBBB;">(model.features)</span><span style="color:#B392F0;">  </span><span style="color:#6B737C;"># \u8F93\u51FA: ModuleDict with keys: [&#39;conv1&#39;, &#39;conv2&#39;]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6B737C;"># \u8BBF\u95EE\u7279\u5B9A\u7684\u6A21\u5757</span></span>
<span class="line"><span style="color:#B392F0;">conv1 </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> model</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">features</span><span style="color:#BBBBBB;">[</span><span style="color:#FFAB70;">&#39;conv1&#39;</span><span style="color:#BBBBBB;">]</span></span>
<span class="line"><span style="color:#B392F0;">print</span><span style="color:#BBBBBB;">(conv1)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6B737C;"># \u5207\u6362\u5230\u8BAD\u7EC3\u6A21\u5F0F</span></span>
<span class="line"><span style="color:#B392F0;">model</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">train</span><span style="color:#BBBBBB;">()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6B737C;"># \u5207\u6362\u5230\u8BC4\u4F30\u6A21\u5F0F</span></span>
<span class="line"><span style="color:#B392F0;">model</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">eval</span><span style="color:#BBBBBB;">()</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br></div></div><p>\u5728\u8FD9\u4E2A\u793A\u4F8B\u4E2D\uFF0C<code>MyModel</code> \u5B9A\u4E49\u4E86\u4E00\u4E2A\u5305\u542B\u4E24\u4E2A\u5377\u79EF\u5C42\u7684 <code>ModuleDict</code>\u3002\u901A\u8FC7 <code>ModuleDict</code>\uFF0C\u6211\u4EEC\u53EF\u4EE5\u65B9\u4FBF\u5730\u8BBF\u95EE\u548C\u7BA1\u7406\u6A21\u578B\u7684\u4E0D\u540C\u90E8\u5206\u3002</p><p>User: self.lm_head = nn.Linear(args.n_embed, args.vocab_size,bias=False) self.transformer.wte.weight = self.lm_head.weight # \u8FD9\u91CC\u4E0D\u662F\u7B80\u7B80\u5355\u5355\u7684\u8D4B\u503C\uFF0C\u800C\u662F wte \u548C lm_head \u5171\u4EAB\u53C2\u6570 # lm_head (n_embed,vocab_size)\u76F8\u5F53\u4E8E\u4ECE\u8BCD\u5411\u91CF\u5230 token \u7684\u9884\u6D4B # wte ()</p><p>Kimi: \u5728\u8FD9\u6BB5\u4EE3\u7801\u4E2D\uFF0C<code>lm_head</code> \u662F\u4E00\u4E2A\u7EBF\u6027\u5C42\uFF08<code>nn.Linear</code>\uFF09\uFF0C\u7528\u4E8E\u5C06 Transformer \u6A21\u578B\u7684\u8F93\u51FA\uFF08\u5373\u8BCD\u5411\u91CF\uFF09\u6620\u5C04\u5230\u8BCD\u6C47\u8868\u4E0A\u7684\u6982\u7387\u5206\u5E03\u3002\u8FD9\u91CC\u6709\u4E24\u4E2A\u5173\u952E\u64CD\u4F5C\uFF1A</p><ol><li><p><strong>\u521B\u5EFA\u8BED\u8A00\u6A21\u578B\u5934\u90E8</strong> (<code>self.lm_head</code>):</p><ul><li><code>nn.Linear(args.n_embed, args.vocab_size, bias=False)</code> \u521B\u5EFA\u4E86\u4E00\u4E2A\u7EBF\u6027\u5C42\uFF0C\u5176\u8F93\u5165\u7EF4\u5EA6\u662F <code>args.n_embed</code>\uFF08\u6A21\u578B\u7684\u5D4C\u5165\u7EF4\u5EA6\uFF09\uFF0C\u8F93\u51FA\u7EF4\u5EA6\u662F <code>args.vocab_size</code>\uFF08\u8BCD\u6C47\u8868\u7684\u5927\u5C0F\uFF09\u3002<code>bias=False</code> \u8868\u793A\u4E0D\u4F7F\u7528\u504F\u7F6E\u9879\uFF0C\u8FD9\u610F\u5473\u7740\u7EBF\u6027\u53D8\u6362\u53EA\u5305\u542B\u6743\u91CD\u77E9\u9635\u4E58\u4EE5\u8F93\u5165\uFF0C\u6CA1\u6709\u989D\u5916\u7684\u504F\u7F6E\u5411\u91CF\u52A0\u548C\u3002</li></ul></li><li><p><strong>\u5171\u4EAB\u6743\u91CD</strong> (<code>self.transformer.wte.weight = self.lm_head.weight</code>):</p><ul><li>\u8FD9\u884C\u4EE3\u7801\u5C06\u8BCD\u5D4C\u5165\u5C42\uFF08<code>wte</code>\uFF09\u7684\u6743\u91CD\u8BBE\u7F6E\u4E3A\u4E0E <code>lm_head</code> \u7684\u6743\u91CD\u76F8\u540C\u3002\u8FD9\u4E0D\u662F\u7B80\u5355\u7684\u8D4B\u503C\u64CD\u4F5C\uFF0C\u800C\u662F\u8BA9\u4E24\u4E2A\u5C42\u5171\u4EAB\u76F8\u540C\u7684\u6743\u91CD\u77E9\u9635\u3002\u8FD9\u610F\u5473\u7740\uFF0C\u867D\u7136 <code>wte</code> \u548C <code>lm_head</code> \u5728\u6A21\u578B\u4E2D\u6709\u4E0D\u540C\u7684\u4F5C\u7528\uFF08\u4E00\u4E2A\u7528\u4E8E\u5C06\u8F93\u5165\u7684\u7D22\u5F15\u8F6C\u6362\u4E3A\u8BCD\u5411\u91CF\uFF0C\u53E6\u4E00\u4E2A\u7528\u4E8E\u5C06\u8BCD\u5411\u91CF\u6620\u5C04\u5230\u8F93\u51FA\u6982\u7387\uFF09\uFF0C\u4F46\u5B83\u4EEC\u4F7F\u7528\u76F8\u540C\u7684\u53C2\u6570\u96C6\u6765\u6267\u884C\u8FD9\u4E9B\u64CD\u4F5C\u3002</li></ul></li></ol><p>\u5171\u4EAB\u6743\u91CD\u7684\u597D\u5904\u5305\u62EC\uFF1A</p><ul><li><strong>\u53C2\u6570\u6548\u7387</strong>: \u7531\u4E8E <code>wte</code> \u548C <code>lm_head</code> \u5171\u4EAB\u6743\u91CD\uFF0C\u6A21\u578B\u7684\u53C2\u6570\u6570\u91CF\u51CF\u5C11\uFF0C\u8FD9\u6709\u52A9\u4E8E\u51CF\u5C11\u6A21\u578B\u7684\u590D\u6742\u6027\u548C\u8FC7\u62DF\u5408\u7684\u98CE\u9669\u3002</li><li><strong>\u4E00\u81F4\u6027</strong>: \u5171\u4EAB\u6743\u91CD\u786E\u4FDD\u4E86\u6A21\u578B\u5728\u5904\u7406\u8F93\u5165\u548C\u751F\u6210\u8F93\u51FA\u65F6\u4F7F\u7528\u4E00\u81F4\u7684\u8BCD\u5411\u91CF\u8868\u793A\uFF0C\u8FD9\u6709\u52A9\u4E8E\u6A21\u578B\u5B66\u4E60\u5230\u66F4\u52A0\u4E00\u81F4\u548C\u6CDB\u5316\u7684\u7279\u5F81\u8868\u793A\u3002</li><li><strong>\u6027\u80FD</strong>: \u5728\u8BAD\u7EC3\u548C\u63A8\u7406\u65F6\uFF0C\u5171\u4EAB\u6743\u91CD\u53EF\u4EE5\u51CF\u5C11\u5185\u5B58\u5360\u7528\u548C\u8BA1\u7B97\u91CF\uFF0C\u4ECE\u800C\u63D0\u9AD8\u6A21\u578B\u7684\u6027\u80FD\u3002</li></ul><p>\u8FD9\u79CD\u6743\u91CD\u5171\u4EAB\u673A\u5236\u5728\u81EA\u7136\u8BED\u8A00\u5904\u7406\u4EFB\u52A1\u4E2D\u975E\u5E38\u5E38\u89C1\uFF0C\u7279\u522B\u662F\u5728 Transformer \u67B6\u6784\u7684\u6A21\u578B\u4E2D\uFF0C\u5982 GPT\u3001BERT \u7B49\u3002\u5B83\u5141\u8BB8\u6A21\u578B\u66F4\u6709\u6548\u5730\u5B66\u4E60\u548C\u4F7F\u7528\u8BCD\u6C47\u8868\u7684\u5D4C\u5165\u8868\u793A\u3002</p><p>User: self.apply(self.<em>init_weights) # \u521D\u59CB\u5316\u6743\u91CD n_sum = 0 # \u6B63\u6001\u5206\u5E03\u521D\u59CB\u5316 attention \u7684\u6295\u5F71\u5C42\u548C MLP \u7684\u4E0B\u91C7\u6837 for pname,p in self.named_parameters(): n_sum = n_sum + p.numel() # \u987A\u5E26\u7EDF\u8BA1\u4E00\u4E0B\u53C2\u6570 if pname.endswith(&#39;c_proj.weight&#39;):# c_proj \u662F\u4E0A\u4E0B\u6587\u611F\u77E5\u7684\u6295\u5F71\u5C42 torch.nn.init.normal</em>(p,mean=0.0, std=0.02/math.sqrt(2*args.n_layer))</p><pre><code>    print(f&quot;\u6A21\u578B\u53C2\u6570\u91CF\uFF1A{n_sum}&quot;)
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u662F GPT \u6A21\u578B\u4E2D\u7528\u4E8E\u521D\u59CB\u5316\u6743\u91CD\u548C\u7EDF\u8BA1\u6A21\u578B\u53C2\u6570\u91CF\u7684\u4EE3\u7801\u5757\u3002\u4E0B\u9762\u662F\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ol><li><p><strong>\u6743\u91CD\u521D\u59CB\u5316</strong>:</p><ul><li><code>self.apply(self._init_weights)</code>: \u8FD9\u884C\u4EE3\u7801\u5E94\u7528\u4E86\u81EA\u5B9A\u4E49\u7684\u521D\u59CB\u5316\u65B9\u6CD5 <code>_init_weights</code> \u5230\u6A21\u578B\u7684\u6240\u6709\u5B50\u6A21\u5757\u3002<code>_init_weights</code> \u5E94\u8BE5\u662F\u5728\u6A21\u578B\u7C7B\u4E2D\u5B9A\u4E49\u7684\u4E00\u4E2A\u65B9\u6CD5\uFF0C\u7528\u4E8E\u8BBE\u7F6E\u6743\u91CD\u7684\u521D\u59CB\u503C\u3002</li></ul></li><li><p><strong>\u53C2\u6570\u91CF\u7EDF\u8BA1</strong>:</p><ul><li><code>n_sum = 0</code>: \u521D\u59CB\u5316\u4E00\u4E2A\u8BA1\u6570\u5668\uFF0C\u7528\u4E8E\u7EDF\u8BA1\u6A21\u578B\u4E2D\u7684\u603B\u53C2\u6570\u91CF\u3002</li><li><code>for pname, p in self.named_parameters()</code>: \u8FD9\u4E2A\u5FAA\u73AF\u904D\u5386\u6A21\u578B\u7684\u6240\u6709\u547D\u540D\u53C2\u6570\u3002<code>named_parameters</code> \u8FD4\u56DE\u4E00\u4E2A\u5305\u542B\u53C2\u6570\u540D\u548C\u53C2\u6570\u5F20\u91CF\u7684\u8FED\u4EE3\u5668\u3002</li></ul></li><li><p><strong>\u7D2F\u52A0\u53C2\u6570\u91CF</strong>:</p><ul><li><code>n_sum = n_sum + p.numel()</code>: \u5BF9\u4E8E\u6BCF\u4E2A\u53C2\u6570\u5F20\u91CF <code>p</code>\uFF0C\u4F7F\u7528 <code>numel()</code> \u65B9\u6CD5\u8BA1\u7B97\u5176\u5143\u7D20\u6570\u91CF\uFF0C\u5E76\u7D2F\u52A0\u5230 <code>n_sum</code> \u4E2D\uFF0C\u4ECE\u800C\u5F97\u5230\u6A21\u578B\u7684\u603B\u53C2\u6570\u91CF\u3002</li></ul></li><li><p><strong>\u7279\u6B8A\u53C2\u6570\u521D\u59CB\u5316</strong>:</p><ul><li><code>if pname.endswith(&#39;c_proj.weight&#39;)</code>: \u5982\u679C\u53C2\u6570\u540D\u4EE5 <code>&#39;c_proj.weight&#39;</code> \u7ED3\u5C3E\uFF0C\u8FD9\u901A\u5E38\u6307\u7684\u662F Transformer \u5757\u4E2D\u7684 MLP \u90E8\u5206\u7684\u4E0B\u91C7\u6837\uFF08down-projection\uFF09\u5C42\u7684\u6743\u91CD\u3002</li><li><code>torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2*args.n_layer))</code>: \u5BF9\u4E8E\u8FD9\u4E9B\u7279\u5B9A\u7684\u6743\u91CD\uFF0C\u4F7F\u7528\u6B63\u6001\u5206\u5E03\u8FDB\u884C\u521D\u59CB\u5316\u3002\u521D\u59CB\u5316\u7684\u5747\u503C\u4E3A 0.0\uFF0C\u6807\u51C6\u5DEE\u4E3A <code>0.02 / sqrt(2 * args.n_layer)</code>\u3002\u8FD9\u79CD\u521D\u59CB\u5316\u65B9\u6CD5\u6709\u52A9\u4E8E\u5728\u6A21\u578B\u8BAD\u7EC3\u7684\u65E9\u671F\u9636\u6BB5\u4FDD\u6301\u6FC0\u6D3B\u7684\u65B9\u5DEE\u7A33\u5B9A\u3002</li></ul></li><li><p><strong>\u6253\u5370\u6A21\u578B\u53C2\u6570\u91CF</strong>:</p><ul><li><code>print(f&quot;\u6A21\u578B\u53C2\u6570\u91CF\uFF1A{n_sum}&quot;)</code>: \u6700\u540E\uFF0C\u6253\u5370\u51FA\u7EDF\u8BA1\u5F97\u5230\u7684\u6A21\u578B\u603B\u53C2\u6570\u91CF\uFF0C\u8FD9\u6709\u52A9\u4E8E\u4E86\u89E3\u6A21\u578B\u7684\u5927\u5C0F\u548C\u590D\u6742\u5EA6\u3002</li></ul></li></ol><p>\u8FD9\u79CD\u521D\u59CB\u5316\u548C\u53C2\u6570\u7EDF\u8BA1\u7684\u65B9\u6CD5\u5728\u6DF1\u5EA6\u5B66\u4E60\u6A21\u578B\u4E2D\u5F88\u5E38\u89C1\uFF0C\u7279\u522B\u662F\u5728\u81EA\u5B9A\u4E49\u6A21\u578B\u65F6\uFF0C\u5B83\u6709\u52A9\u4E8E\u786E\u4FDD\u6743\u91CD\u4EE5\u4E00\u79CD\u6709\u52A9\u4E8E\u6A21\u578B\u5B66\u4E60\u7684\u65B9\u5F0F\u5F00\u59CB\u8BAD\u7EC3\uFF0C\u5E76\u4E14\u53EF\u4EE5\u76D1\u63A7\u6A21\u578B\u7684\u5927\u5C0F\uFF0C\u4EE5\u4FBF\u4E8E\u8C03\u6574\u548C\u4F18\u5316\u3002</p><p>User: def <em>init_weights(self,module):# \u521D\u59CB\u5316\u5148\u884C\u5C42\u548C embedding if isinstance(module, nn.Linear): torch.nn.init.normal</em>(module.weight, mean=0.0, std=0.02) if module.bias is not None: torch.nn.init.zeros*(module.bias) elif isinstance(module, nn.Embedding): torch.nn.init.normal*(module.weight, mean=0.0, std=0.02)</p><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u5B9A\u4E49\u4E86\u4E00\u4E2A\u540D\u4E3A <code>_init_weights</code> \u7684\u81EA\u5B9A\u4E49\u6743\u91CD\u521D\u59CB\u5316\u65B9\u6CD5\uFF0C\u5B83\u662F\u6A21\u578B\u521D\u59CB\u5316\u8FC7\u7A0B\u4E2D\u7684\u4E00\u90E8\u5206\u3002\u8FD9\u4E2A\u65B9\u6CD5\u901A\u8FC7\u9012\u5F52\u5730\u8BBF\u95EE\u6A21\u578B\u4E2D\u7684\u6BCF\u4E2A\u6A21\u5757\uFF0C\u5E76\u6839\u636E\u6A21\u5757\u7684\u7C7B\u578B\u5E94\u7528\u7279\u5B9A\u7684\u521D\u59CB\u5316\u7B56\u7565\u3002\u4EE5\u4E0B\u662F\u8BE5\u65B9\u6CD5\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ol><li><p><strong>\u65B9\u6CD5\u5B9A\u4E49</strong>:</p><ul><li><code>def _init_weights(self, module):</code> \u5B9A\u4E49\u4E86\u4E00\u4E2A\u65B9\u6CD5\uFF0C\u5B83\u63A5\u53D7\u4E00\u4E2A\u6A21\u5757\u4F5C\u4E3A\u53C2\u6570\u3002\u8FD9\u4E2A\u65B9\u6CD5\u662F\u6A21\u578B\u7C7B\u7684\u6210\u5458\u51FD\u6570\uFF0C\u56E0\u6B64 <code>self</code> \u5F15\u7528\u5F53\u524D\u7684\u6A21\u578B\u5B9E\u4F8B\u3002</li></ul></li><li><p><strong>\u68C0\u67E5\u6A21\u5757\u7C7B\u578B</strong>:</p><ul><li><code>if isinstance(module, nn.Linear):</code> \u8FD9\u4E2A\u6761\u4EF6\u5224\u65AD\u5F53\u524D\u6A21\u5757\u662F\u5426\u662F <code>nn.Linear</code> \u7C7B\u7684\u5B9E\u4F8B\uFF0C\u5373\u662F\u5426\u4E3A\u7EBF\u6027\u5C42\u3002</li></ul></li><li><p><strong>\u7EBF\u6027\u5C42\u6743\u91CD\u521D\u59CB\u5316</strong>:</p><ul><li><code>torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)</code> \u5BF9\u4E8E\u7EBF\u6027\u5C42\u7684\u6743\u91CD\uFF0C\u4F7F\u7528\u6B63\u6001\u5206\u5E03\u8FDB\u884C\u521D\u59CB\u5316\uFF0C\u5747\u503C\u8BBE\u4E3A 0.0\uFF0C\u6807\u51C6\u5DEE\u8BBE\u4E3A 0.02\u3002\u8FD9\u662F\u4E00\u79CD\u5E38\u89C1\u7684\u521D\u59CB\u5316\u65B9\u6CD5\uFF0C\u6709\u52A9\u4E8E\u5728\u8BAD\u7EC3\u5F00\u59CB\u65F6\u4E3A\u6743\u91CD\u63D0\u4F9B\u4E00\u4E2A\u8F83\u5C0F\u7684\u968F\u673A\u503C\u3002</li></ul></li><li><p><strong>\u7EBF\u6027\u5C42\u504F\u7F6E\u521D\u59CB\u5316</strong>:</p><ul><li><code>if module.bias is not None:</code> \u8FD9\u4E2A\u6761\u4EF6\u68C0\u67E5\u7EBF\u6027\u5C42\u662F\u5426\u6709\u504F\u7F6E\u9879\u3002</li><li><code>torch.nn.init.zeros_(module.bias)</code> \u5982\u679C\u5B58\u5728\u504F\u7F6E\u9879\uFF0C\u5219\u5C06\u5176\u521D\u59CB\u5316\u4E3A 0\u3002\u8FD9\u901A\u5E38\u610F\u5473\u7740\u504F\u7F6E\u88AB\u521D\u59CB\u5316\u4E3A\u5747\u503C 0\uFF0C\u6709\u52A9\u4E8E\u6A21\u578B\u4ECE\u96F6\u5F00\u59CB\u5B66\u4E60\u3002</li></ul></li><li><p><strong>\u5D4C\u5165\u5C42\u6743\u91CD\u521D\u59CB\u5316</strong>:</p><ul><li><code>elif isinstance(module, nn.Embedding):</code> \u8FD9\u4E2A\u6761\u4EF6\u5224\u65AD\u5F53\u524D\u6A21\u5757\u662F\u5426\u662F <code>nn.Embedding</code> \u7C7B\u7684\u5B9E\u4F8B\uFF0C\u5373\u662F\u5426\u4E3A\u5D4C\u5165\u5C42\u3002</li><li><code>torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)</code> \u5BF9\u4E8E\u5D4C\u5165\u5C42\u7684\u6743\u91CD\uFF0C\u4E5F\u4F7F\u7528\u6B63\u6001\u5206\u5E03\u8FDB\u884C\u521D\u59CB\u5316\uFF0C\u4E0E\u7EBF\u6027\u5C42\u7684\u6743\u91CD\u521D\u59CB\u5316\u65B9\u6CD5\u76F8\u540C\u3002</li></ul></li><li><p><strong>\u9012\u5F52\u521D\u59CB\u5316</strong>:</p><ul><li>\u7531\u4E8E <code>_init_weights</code> \u65B9\u6CD5\u4F7F\u7528 <code>self.apply</code> \u8C03\u7528\uFF0C\u5B83\u4F1A\u9012\u5F52\u5730\u5BF9\u6A21\u578B\u4E2D\u7684\u6240\u6709\u5B50\u6A21\u5757\u6267\u884C\u521D\u59CB\u5316\u3002\u8FD9\u610F\u5473\u7740\u65E0\u8BBA\u6A21\u578B\u7ED3\u6784\u591A\u4E48\u590D\u6742\uFF0C\u6240\u6709\u5B50\u6A21\u5757\u7684\u6743\u91CD\u90FD\u4F1A\u6309\u7167\u5B9A\u4E49\u7684\u7B56\u7565\u8FDB\u884C\u521D\u59CB\u5316\u3002</li></ul></li></ol><p>\u8FD9\u79CD\u521D\u59CB\u5316\u65B9\u6CD5\u7684\u597D\u5904\u662F\u786E\u4FDD\u4E86\u6A21\u578B\u4E2D\u7684\u53C2\u6570\u4ECE\u4E00\u4E2A\u5408\u7406\u7684\u8D77\u70B9\u5F00\u59CB\u8BAD\u7EC3\uFF0C\u6709\u52A9\u4E8E\u907F\u514D\u68AF\u5EA6\u6D88\u5931\u6216\u7206\u70B8\u7684\u95EE\u9898\uFF0C\u7279\u522B\u662F\u5728\u6DF1\u5EA6\u795E\u7ECF\u7F51\u7EDC\u4E2D\u3002\u901A\u8FC7\u81EA\u5B9A\u4E49\u521D\u59CB\u5316\u65B9\u6CD5\uFF0C\u5F00\u53D1\u8005\u53EF\u4EE5\u7075\u6D3B\u5730\u63A7\u5236\u6A21\u578B\u53C2\u6570\u7684\u521D\u59CB\u72B6\u6001\uFF0C\u4EE5\u9002\u5E94\u4E0D\u540C\u7684\u6A21\u578B\u67B6\u6784\u548C\u8BAD\u7EC3\u7B56\u7565\u3002</p><p>User: def forward(self, idx, targets = None): # targets \u662F\u8BAD\u7EC3\u65F6\u4F20\u5165\u7684\u76EE\u6807\uFF0C\u7528\u6765\u8BA1\u7B97\u4EA4\u53C9\u71B5 loss device = idx.device B,T = idx.size() pos = torch.arange(0,T,dtype=torch.long,device=device) # \u4F4D\u7F6E</p><pre><code>    # embedding
    token_embed = self.transformer.wte(idx) # (B,T,n_embed)
    pos_embed = self.transformer.wpe(pos)# (t,n_embed)
    # \u4F4D\u7F6Eembed\u53EF\u5B66\u4E60

    x = self.transformer.drop(token_embed+pos_embed) # \u5408\u5E76token\u548Cpos
    for block in self.transformer.h:
        x = block(x)
    x = self.transformer.norm(x)

    # \u7ECF\u8FC7lm_head
    # target= True \u8868\u793A\u6A21\u578B\u6B63\u5728\u8BAD\u7EC3\u9636\u6BB5\uFF0C\u9700\u8981\u56DE\u4F20loss
    # logits\u53D6\u6700\u540E\u4E00\u4E2A\uFF08-1\uFF09\u5373\u751F\u6210\u51FA\u6765\u7684\u4E1C\u897F\uFF0C\u8FD9\u6837\u548C\u76EE\u6807\u7684\u4E00\u4E2Atoken\u7EF4\u5EA6\u76F8\u540C\uFF0C\u624D\u597D\u8BA1\u7B97\u635F\u5931

    if targets is not None:
        logits = self.lm_head(x)
        # \u7528-1\u53D6\u6700\u540E\u4E00\u7EF4\u5EA6\u4E2A\uFF0C\u628A\u524D\u9762\u7684t\u4E22\u6389(t,vocab_size)-&gt;(vocab_size)
        loss = F.cross_entropy(logits.view(-1,logits.size(-1)),targets.view(-1),ignore_index=-1) # \u4EA4\u53C9\u71B5\u635F\u5931
    else: # generate\u65F6\u4F7F\u7528
        logits = self.lm_head(x)
        loss = None

    return logits,loss
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u662F GPT \u6A21\u578B\u7684\u524D\u5411\u4F20\u64AD\u65B9\u6CD5 <code>forward</code>\uFF0C\u5B83\u5B9A\u4E49\u4E86\u6A21\u578B\u5982\u4F55\u5904\u7406\u8F93\u5165\u6570\u636E\u5E76\u8BA1\u7B97\u8F93\u51FA\u3002\u4EE5\u4E0B\u662F\u8BE6\u7EC6\u6B65\u9AA4\u548C\u5173\u952E\u70B9\uFF1A</p><ol><li><p><strong>\u65B9\u6CD5\u5B9A\u4E49</strong>:</p><ul><li><code>def forward(self, idx, targets=None)</code>: \u5B9A\u4E49\u4E86\u524D\u5411\u4F20\u64AD\u51FD\u6570\uFF0C\u63A5\u53D7\u8F93\u5165 <code>idx</code>\uFF08\u901A\u5E38\u662F\u8BCD\u6C47\u8868\u7D22\u5F15\u7684\u5F20\u91CF\uFF09\u548C\u53EF\u9009\u7684 <code>targets</code> \u53C2\u6570\uFF08\u8BAD\u7EC3\u65F6\u7684\u76EE\u6807\u5F20\u91CF\uFF09\u3002</li></ul></li><li><p><strong>\u8BBE\u5907\u4E00\u81F4\u6027</strong>:</p><ul><li><code>device = idx.device</code>: \u83B7\u53D6\u8F93\u5165\u6570\u636E <code>idx</code> \u7684\u8BBE\u5907\uFF08CPU \u6216 GPU\uFF09\uFF0C\u786E\u4FDD\u6240\u6709\u7684\u64CD\u4F5C\u90FD\u5728\u76F8\u540C\u7684\u8BBE\u5907\u4E0A\u6267\u884C\u3002</li></ul></li><li><p><strong>\u8F93\u5165\u5C3A\u5BF8</strong>:</p><ul><li><code>B,T = idx.size()</code>: \u83B7\u53D6\u8F93\u5165 <code>idx</code> \u7684\u5C3A\u5BF8\uFF0C\u5176\u4E2D <code>B</code> \u662F\u6279\u6B21\u5927\u5C0F\uFF0C<code>T</code> \u662F\u5E8F\u5217\u957F\u5EA6\u3002</li></ul></li><li><p><strong>\u4F4D\u7F6E\u7F16\u7801</strong>:</p><ul><li><code>pos = torch.arange(0, T, dtype=torch.long, device=device)</code>: \u521B\u5EFA\u4E00\u4E2A\u4ECE 0 \u5230 <code>T-1</code> \u7684\u4F4D\u7F6E\u7D22\u5F15\u5F20\u91CF\uFF0C\u7528\u4E8E\u4F4D\u7F6E\u7F16\u7801\u3002</li></ul></li><li><p><strong>\u5D4C\u5165\u5C42</strong>:</p><ul><li><code>token_embed = self.transformer.wte(idx)</code>: \u5C06\u8F93\u5165\u7684\u7D22\u5F15 <code>idx</code> \u901A\u8FC7\u8BCD\u5D4C\u5165\u5C42 <code>wte</code> \u8F6C\u6362\u4E3A\u8BCD\u5411\u91CF\u3002</li><li><code>pos_embed = self.transformer.wpe(pos)</code>: \u5C06\u4F4D\u7F6E\u7D22\u5F15 <code>pos</code> \u901A\u8FC7\u4F4D\u7F6E\u7F16\u7801\u5C42 <code>wpe</code> \u8F6C\u6362\u4E3A\u4F4D\u7F6E\u7F16\u7801\u5411\u91CF\u3002</li></ul></li><li><p><strong>\u5408\u5E76\u5D4C\u5165</strong>:</p><ul><li><code>x = self.transformer.drop(token_embed + pos_embed)</code>: \u5C06\u8BCD\u5D4C\u5165\u548C\u4F4D\u7F6E\u7F16\u7801\u5411\u91CF\u76F8\u52A0\uFF0C\u5E76\u901A\u8FC7 Dropout \u5C42 <code>drop</code>\u3002</li></ul></li><li><p><strong>Transformer \u5757\u5904\u7406</strong>:</p><ul><li><code>for block in self.transformer.h:</code>: \u904D\u5386\u6240\u6709\u7684 Transformer \u5757\uFF0C\u5E76\u5C06\u6570\u636E <code>x</code> \u4F20\u9012\u7ED9\u6BCF\u4E2A\u5757\u8FDB\u884C\u5904\u7406\u3002</li></ul></li><li><p><strong>\u5C42\u5F52\u4E00\u5316</strong>:</p><ul><li><code>x = self.transformer.norm(x)</code>: \u4F7F\u7528\u5C42\u5F52\u4E00\u5316 <code>norm</code> \u5BF9\u6700\u7EC8\u7684\u8F93\u51FA\u8FDB\u884C\u5F52\u4E00\u5316\u3002</li></ul></li><li><p><strong>\u8F93\u51FA\u5C42</strong>:</p><ul><li><code>logits = self.lm_head(x)</code>: \u5C06\u5F52\u4E00\u5316\u540E\u7684\u8F93\u51FA <code>x</code> \u901A\u8FC7\u7EBF\u6027\u5C42 <code>lm_head</code> \u8F6C\u6362\u4E3A logits\uFF0C\u5373\u8BCD\u6C47\u8868\u4E0A\u7684\u6982\u7387\u5206\u5E03\u3002</li></ul></li><li><p><strong>\u8BAD\u7EC3\u4E0E\u63A8\u7406</strong>:</p><ul><li>\u5982\u679C <code>targets</code> \u4E0D\u4E3A <code>None</code>\uFF08\u5373\u6A21\u578B\u5904\u4E8E\u8BAD\u7EC3\u9636\u6BB5\uFF09\uFF0C\u5219\u8BA1\u7B97\u4EA4\u53C9\u71B5\u635F\u5931\uFF1A <ul><li><code>loss = F.cross_entropy(...)</code>: \u4F7F\u7528 <code>logits</code> \u548C <code>targets</code> \u8BA1\u7B97\u4EA4\u53C9\u71B5\u635F\u5931\u3002<code>ignore_index=-1</code> \u8868\u793A\u5728\u8BA1\u7B97\u635F\u5931\u65F6\u5FFD\u7565\u503C\u4E3A -1 \u7684\u76EE\u6807\u7D22\u5F15\u3002</li></ul></li><li>\u5982\u679C <code>targets</code> \u4E3A <code>None</code>\uFF08\u5373\u6A21\u578B\u5904\u4E8E\u63A8\u7406\u9636\u6BB5\uFF09\uFF0C\u5219\u4E0D\u8BA1\u7B97\u635F\u5931\uFF0C\u53EA\u8FD4\u56DE logits\u3002</li></ul></li><li><p><strong>\u8FD4\u56DE\u503C</strong>:</p><ul><li><code>return logits, loss</code>: \u8FD4\u56DE\u6A21\u578B\u7684 logits \u548C\uFF08\u5982\u679C\u63D0\u4F9B <code>targets</code>\uFF09\u635F\u5931\u503C\u3002</li></ul></li></ol><p>\u8FD9\u4E2A\u65B9\u6CD5\u7ED3\u5408\u4E86\u6A21\u578B\u7684\u6240\u6709\u7EC4\u4EF6\uFF0C\u5305\u62EC\u5D4C\u5165\u5C42\u3001Transformer \u5757\u3001\u5C42\u5F52\u4E00\u5316\u548C\u8F93\u51FA\u5C42\uFF0C\u4EE5\u53CA\u8BAD\u7EC3\u548C\u63A8\u7406\u65F6\u7684\u4E0D\u540C\u884C\u4E3A\u3002\u901A\u8FC7\u8FD9\u79CD\u65B9\u5F0F\uFF0CGPT \u6A21\u578B\u53EF\u4EE5\u5904\u7406\u8F93\u5165\u6570\u636E\uFF0C\u5E76\u5728\u8BAD\u7EC3\u65F6\u63D0\u4F9B\u635F\u5931\u503C\uFF0C\u4EE5\u4FBF\u8FDB\u884C\u68AF\u5EA6\u4E0B\u964D\u4F18\u5316\u3002\u5728\u63A8\u7406\u65F6\uFF0C\u5B83\u751F\u6210 logits\uFF0C\u53EF\u4EE5\u7528\u4E8E\u751F\u6210\u6587\u672C\u6216\u5176\u4ED6\u4E0B\u6E38\u4EFB\u52A1\u3002</p>`,193),p=a("p",{"pn:p":"",for:"","pn,p":"",in:"","param_dict.items()":"",if:"","p.requires_grad":""},"User: def configure_optimizers(self,weight_decay,learning_rate,betas,device_type): # \u5EFA\u7ACB\u4E00\u4E2A\u4ECE\u53C2\u6570\u540D\u5230\u53C2\u6570\u7684 dict param_dict = {pn:p for pn,p in self.named_parameters()} # \u518D\u53BB\u6389\u4E0D\u7528\u8BA1\u7B97\u68AF\u5EA6\u7684\u90E8\u5206 param_dict =",-1),r=e(`<pre><code>    # weight decay
    # \u5BF9\u4E8C\u7EF4\u7684\u53C2\u6570\u4F7F\u7528weight decay\uFF0C\u5176\u4ED6\u4E0D\u7528\uFF0C\u8FD9\u6837\u5206\u6210\u4E24\u7EC4
    decay_params = [p for pn,p in param_dict.items() if p.dim() &gt;= 2]
    nodecay_params = [p for pn,p in param_dict.items() if p.dim() &lt; 2]
    # dict.items()\u662F\u8FD4\u56DE\u4E00\u4E2Akey\u548Cvalue\u5143\u7EC4\u7684list [(k1,v1),(k2,v2)]
    optim_groups = [
        {&#39;params&#39;: decay_params, &#39;weight_decay&#39;: weight_decay},
        {&#39;params&#39;: nodecay_params, &#39;weight_decay&#39;: 0.0}
    ]
    # \u7EDF\u8BA1\u4E00\u4E0Bdecay\u548C\u4E0Ddecay\u7684\u53C2\u6570\u91CF
    num_decay = sum(p.numel() for p in decay_params)
    num_nodecay = sum(p.numel() for p in nodecay_params)
    print(f&quot;\u4F7F\u7528weight decay\u7684\u53C2\u6570\u91CF\u4E3A{num_decay},\u4E0D\u4F7F\u7528weight decay\u7684\u53C2\u6570\u91CF\u4E3A{num_nodecay}&quot;)

    # \u8FD9\u6BB5\u662F\u5EFA\u7ACB\u4E00\u4E2AAdamW\u4F18\u5316\u5668\uFF0C\u770B\u7248\u672C\u662F\u5426\u652F\u6301fused\u878D\u5408
    # \u5224\u65ADAdam\u7684\u53C2\u6570\u5B57\u5178\u4E2D\u662F\u5426\u5305\u542Bfused\uFF0C\u5982\u679C\u6709\uFF0C\u628A\u5B83\u6DFB\u52A0\u5230extra args\u4E2D
    fused_avail = &#39;fused&#39; in inspect.signature(torch.optim.AdamW).parameters
    # inspect.signature(fn).parameters\u8FD4\u56DE\u53C2\u6570list
    use_fused = fused_avail and device_type == &#39;cuda&#39; # \u5E76\u4E14\u8981\u6709gpu
    if use_fused:
        print(&quot;AdamW optimiser use fused!&quot;)
    extra_args = {&#39;fused&#39;:True} if use_fused else dict()
    optimizer = torch.optim.AdamW(optim_groups,lr = learning_rate,betas = betas,**extra_args)
    # betas:\u8BA1\u7B97\u68AF\u5EA6\u4EE5\u53CA\u68AF\u5EA6\u5E73\u65B9\u7684\u8FD0\u884C\u5E73\u5747\u503C\u7684\u7CFB\u6570
    # ** \u7528\u4E8E\u5C06\u4E00\u4E2A\u5B57\u5178\u89E3\u5305\u6210\u5173\u952E\u5B57\u53C2\u6570\u4F20\u9012\u7ED9\u51FD\u6570

    return optimizer
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u5B9A\u4E49\u4E86\u4E00\u4E2A\u540D\u4E3A <code>configure_optimizers</code> \u7684\u65B9\u6CD5\uFF0C\u7528\u4E8E\u914D\u7F6E\u548C\u8FD4\u56DE\u4E00\u4E2A\u4F18\u5316\u5668\uFF0C\u5B83\u662F\u6A21\u578B\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\u7528\u4E8E\u66F4\u65B0\u6A21\u578B\u53C2\u6570\u7684\u5173\u952E\u7EC4\u4EF6\u3002\u4EE5\u4E0B\u662F\u8BE5\u65B9\u6CD5\u7684\u8BE6\u7EC6\u6B65\u9AA4\u548C\u5173\u952E\u70B9\uFF1A</p><ol><li><p><strong>\u53C2\u6570\u5B57\u5178</strong>:</p><ul><li><code>param_dict = {pn: p for pn, p in self.named_parameters()}</code>: \u521B\u5EFA\u4E00\u4E2A\u5B57\u5178\uFF0C\u5305\u542B\u6A21\u578B\u7684\u6240\u6709\u547D\u540D\u53C2\u6570\u53CA\u5176\u5BF9\u5E94\u7684\u53C2\u6570\u5F20\u91CF\u3002</li></ul></li><li><p><strong>\u8FC7\u6EE4\u53C2\u6570</strong>:</p><ul><li><code>param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}</code>: \u8FC7\u6EE4\u6389\u4E0D\u9700\u8981\u8BA1\u7B97\u68AF\u5EA6\u7684\u53C2\u6570\u3002</li></ul></li><li><p><strong>\u5206\u7EC4\u53C2\u6570</strong>:</p><ul><li><code>decay_params = [p for pn, p in param_dict.items() if p.dim() &gt;= 2]</code>: \u9009\u62E9\u9700\u8981\u4F7F\u7528\u6743\u91CD\u8870\u51CF\uFF08weight decay\uFF09\u7684\u53C2\u6570\uFF0C\u901A\u5E38\u662F\u4E8C\u7EF4\u5F20\u91CF\uFF0C\u5982\u6743\u91CD\u77E9\u9635\u3002</li><li><code>nodecay_params = [p for pn, p in param_dict.items() if p.dim() &lt; 2]</code>: \u9009\u62E9\u4E0D\u9700\u8981\u6743\u91CD\u8870\u51CF\u7684\u53C2\u6570\uFF0C\u5982\u504F\u7F6E\u9879\u3002</li></ul></li><li><p><strong>\u4F18\u5316\u5668\u5206\u7EC4</strong>:</p><ul><li><code>optim_groups</code>: \u521B\u5EFA\u4E24\u4E2A\u4F18\u5316\u5668\u53C2\u6570\u7EC4\uFF0C\u4E00\u4E2A\u5305\u542B\u9700\u8981\u6743\u91CD\u8870\u51CF\u7684\u53C2\u6570\uFF0C\u53E6\u4E00\u4E2A\u5305\u542B\u4E0D\u9700\u8981\u6743\u91CD\u8870\u51CF\u7684\u53C2\u6570\u3002</li></ul></li><li><p><strong>\u6253\u5370\u53C2\u6570\u91CF</strong>:</p><ul><li>\u6253\u5370\u51FA\u4F7F\u7528\u6743\u91CD\u8870\u51CF\u548C\u4E0D\u4F7F\u7528\u6743\u91CD\u8870\u51CF\u7684\u53C2\u6570\u91CF\uFF0C\u4EE5\u4FBF\u4E8E\u76D1\u63A7\u548C\u8C03\u8BD5\u3002</li></ul></li><li><p><strong>\u68C0\u67E5 AdamW \u4F18\u5316\u5668\u9009\u9879</strong>:</p><ul><li>\u4F7F\u7528 <code>inspect.signature</code> \u68C0\u67E5 PyTorch \u662F\u5426\u652F\u6301 AdamW \u4F18\u5316\u5668\u7684 <code>fused</code> \u9009\u9879\u3002</li></ul></li><li><p><strong>\u914D\u7F6E AdamW \u4F18\u5316\u5668</strong>:</p><ul><li>\u5982\u679C <code>device_type</code> \u662F <code>&#39;cuda&#39;</code>\uFF08\u5373\u5728 GPU \u4E0A\u8BAD\u7EC3\uFF09\uFF0C\u5E76\u4E14 PyTorch \u652F\u6301 <code>fused</code>\uFF0C\u5219\u4F7F\u7528\u878D\u5408\u7684 AdamW \u4F18\u5316\u5668\u5B9E\u73B0\uFF0C\u8FD9\u53EF\u4EE5\u63D0\u9AD8\u6027\u80FD\u3002</li><li><code>extra_args</code>: \u5982\u679C\u4F7F\u7528\u878D\u5408\u4F18\u5316\u5668\uFF0C\u5219\u6DFB\u52A0 <code>fused=True</code> \u5230\u989D\u5916\u53C2\u6570\u4E2D\u3002</li></ul></li><li><p><strong>\u521B\u5EFA\u4F18\u5316\u5668</strong>:</p><ul><li><code>optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)</code>: \u4F7F\u7528\u914D\u7F6E\u597D\u7684\u53C2\u6570\u7EC4\u3001\u5B66\u4E60\u7387\u3001\u52A8\u91CF\u53C2\u6570\uFF08betas\uFF09\u548C\u989D\u5916\u53C2\u6570\u521B\u5EFA AdamW \u4F18\u5316\u5668\u5B9E\u4F8B\u3002</li></ul></li><li><p><strong>\u8FD4\u56DE\u4F18\u5316\u5668</strong>:</p><ul><li><code>return optimizer</code>: \u8FD4\u56DE\u521B\u5EFA\u7684\u4F18\u5316\u5668\u5B9E\u4F8B\uFF0C\u4EE5\u4FBF\u5728\u8BAD\u7EC3\u5FAA\u73AF\u4E2D\u4F7F\u7528\u3002</li></ul></li></ol><p>AdamW \u4F18\u5316\u5668\u662F Adam \u4F18\u5316\u5668\u7684\u4E00\u4E2A\u53D8\u4F53\uFF0C\u5B83\u5728\u6807\u51C6 Adam \u4F18\u5316\u5668\u7684\u57FA\u7840\u4E0A\u6DFB\u52A0\u4E86\u6743\u91CD\u8870\u51CF\u3002\u901A\u8FC7\u5C06\u6743\u91CD\u8870\u51CF\u76F4\u63A5\u6574\u5408\u5230\u4F18\u5316\u5668\u6B65\u9AA4\u4E2D\uFF0CAdamW \u53EF\u4EE5\u66F4\u6709\u6548\u5730\u5904\u7406\u7A00\u758F\u6570\u636E\u548C\u6DF1\u5C42\u7F51\u7EDC\u3002</p><p><code>configure_optimizers</code> \u65B9\u6CD5\u63D0\u4F9B\u4E86\u4E00\u79CD\u7075\u6D3B\u7684\u65B9\u5F0F\u6765\u914D\u7F6E\u6A21\u578B\u7684\u4F18\u5316\u5668\uFF0C\u5141\u8BB8\u5F00\u53D1\u8005\u6839\u636E\u6A21\u578B\u7684\u7279\u5B9A\u9700\u6C42\u548C\u8BAD\u7EC3\u73AF\u5883\uFF08\u5982\u662F\u5426\u4F7F\u7528 GPU\uFF09\u6765\u8C03\u6574\u4F18\u5316\u5668\u7684\u884C\u4E3A\u3002</p><p>User: def generate(self, idx, max<em>generate_tokens, tempreture=1.0, top_k=None): # topp\uFF0Ctopk \u548C tempreture \u7684\u6982\u5FF5 # max_generate_tokens \u4E3A\u751F\u6210\u7684\u65B0 tokens \u7684\u6700\u5927\u6570\u91CF for * in range(max</em>generate_tokens): idx = idx if idx.shape[1] &lt;= self.args.block_size else idx[:,-self.args.block_size:] # \u5982\u679C\u5927\u4E8E\u4F20\u5165\u7684\u6700\u5927\u5927\u5C0F\u5219\u622A\u53D6\u540E\u9762\u4E00\u6BB5 # \u5176\u5B9E\u8FD9\u91CC\u6211\u6709\u70B9\u4E0D\u61C2\uFF0C\u5982\u679C idx \u957F\u5EA6\u4E0D\u8DB3 blocksize\uFF0C\u662F\u54EA\u4E00\u6B65\u7ED9\u4ED6\u586B\u5145\u5230 blocksize \u5927\u5C0F\u7684\u5462\uFF1F logits, * = self(idx) logits = logits[:,-1,:]/tempreture #(B,T,C)\u53D6\u6700\u540E\u4E00\u4E2A\u5373\u65B0\u751F\u6210\u7684 # tempreture \u66F4\u9AD8\uFF0C\u751F\u6210\u7684\u968F\u673A\u6027\u66F4\u9AD8 # \u4ECE\u8FD9\u91CC\u80FD\u77E5\u9053\uFF0C\u662F softmax \u7684\u6027\u8D28\u51B3\u5B9A\u7684\uFF0C\u6307\u6570\u51FD\u6570\u5C0F\u7684\u65F6\u5019\u53D8\u5316\u5C0F\uFF0C\u4E0D\u540C token \u7684 probs \u5DEE\u8DDD\u4F1A\u88AB\u51CF\u5C11\uFF0C\u968F\u673A\u6027\u5C31\u5F3A\u4E86</p><pre><code>        if top_k is not None:
            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))
            logits[logits &lt; v[:, [-1]]] = -float(&#39;Inf&#39;) # \u5FFD\u7565topk\u540D\u4EE5\u540E\u7684token

        probs = F.softmax(logits,dim=-1)
        idx_next = torch.multinomial(probs, num_samples=1) # \u6309\u7167probs\u6982\u7387\u9009\u4E00\u4E2A
        idx = torch.cat((idx, idx_next), dim=1)

    return idx
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u5B9A\u4E49\u4E86\u4E00\u4E2A\u540D\u4E3A <code>generate</code> \u7684\u65B9\u6CD5\uFF0C\u7528\u4E8E\u751F\u6210\u6587\u672C\u6216\u5E8F\u5217\u6570\u636E\u3002\u8FD9\u4E2A\u65B9\u6CD5\u662F GPT \u6A21\u578B\u7684\u4E00\u90E8\u5206\uFF0C\u901A\u5E38\u7528\u4E8E\u8BED\u8A00\u6A21\u578B\u6216\u5176\u4ED6\u5E8F\u5217\u751F\u6210\u4EFB\u52A1\u3002\u4EE5\u4E0B\u662F\u8BE6\u7EC6\u6B65\u9AA4\u548C\u5173\u952E\u70B9\uFF1A</p><ol><li><p><strong>\u65B9\u6CD5\u5B9A\u4E49</strong>:</p><ul><li><code>def generate(self, idx, max_generate_tokens, temperature=1.0, top_k=None)</code>: \u5B9A\u4E49\u4E86\u751F\u6210\u65B9\u6CD5\uFF0C\u63A5\u53D7\u4EE5\u4E0B\u53C2\u6570\uFF1A <ul><li><code>idx</code>: \u8F93\u5165\u7684\u521D\u59CB\u7D22\u5F15\u5F20\u91CF\uFF0C\u53EF\u4EE5\u662F\u4E00\u4E2A\u8BCD\u6216\u5B57\u7B26\u7684\u5E8F\u5217\u3002</li><li><code>max_generate_tokens</code>: \u8981\u751F\u6210\u7684\u6700\u5927\u65B0 token \u6570\u91CF\u3002</li><li><code>temperature</code>: \u63A7\u5236\u751F\u6210\u8FC7\u7A0B\u4E2D\u968F\u673A\u6027\u7684\u53C2\u6570\u3002\u6E29\u5EA6\u8F83\u9AD8\u65F6\uFF0C\u751F\u6210\u7684\u5E8F\u5217\u66F4\u968F\u673A\uFF1B\u6E29\u5EA6\u8F83\u4F4E\u65F6\uFF0C\u751F\u6210\u7684\u5E8F\u5217\u66F4\u786E\u5B9A\u3002</li><li><code>top_k</code>: \u9650\u5236\u5728 top-k \u6700\u53EF\u80FD\u7684 token \u4E2D\u8FDB\u884C\u91C7\u6837\uFF0C\u4EE5\u63A7\u5236\u751F\u6210\u7684\u591A\u6837\u6027\u3002</li></ul></li></ul></li><li><p><strong>\u5E8F\u5217\u622A\u53D6</strong>:</p><ul><li><code>idx = idx if idx.shape[1] &lt;= self.args.block_size else idx[:,-self.args.block_size:]</code>: \u5982\u679C\u8F93\u5165\u5E8F\u5217\u957F\u5EA6\u8D85\u8FC7\u6A21\u578B\u7684 <code>block_size</code>\uFF0C\u5219\u53EA\u4FDD\u7559\u6700\u540E <code>block_size</code> \u4E2A token\u3002</li></ul></li><li><p><strong>\u6A21\u578B\u524D\u5411\u4F20\u64AD</strong>:</p><ul><li><code>logits, _ = self(idx)</code>: \u4F7F\u7528\u6A21\u578B\u7684\u524D\u5411\u4F20\u64AD\u65B9\u6CD5\u8BA1\u7B97\u8F93\u5165 <code>idx</code> \u7684 logits\u3002</li></ul></li><li><p><strong>\u5E94\u7528\u6E29\u5EA6\u53C2\u6570</strong>:</p><ul><li><code>logits = logits[:,-1,:]/temperature</code>: \u5E94\u7528\u6E29\u5EA6\u53C2\u6570\u8C03\u6574 logits\uFF0C\u5F71\u54CD\u751F\u6210\u7684\u968F\u673A\u6027\u3002</li></ul></li><li><p><strong>Top-k \u91C7\u6837</strong>:</p><ul><li>\u5982\u679C\u8BBE\u7F6E\u4E86 <code>top_k</code>\uFF0C\u5219\u53EA\u8003\u8651\u6982\u7387\u6700\u9AD8\u7684 <code>top_k</code> \u4E2A token\uFF1A <ul><li><code>v, _ = torch.topk(logits, min(top_k, logits.size(-1)))</code>: \u83B7\u53D6 top-k \u7684 logits \u503C\u3002</li><li><code>logits[logits &lt; v[:, [-1]]] = -float(&#39;Inf&#39;)</code>: \u5C06\u6392\u540D\u5728 top-k \u4E4B\u5916\u7684 token \u7684 logits \u8BBE\u7F6E\u4E3A\u8D1F\u65E0\u7A77\uFF0C\u8FD9\u6837\u5728\u5E94\u7528 softmax \u65F6\u5B83\u4EEC\u7684\u6982\u7387\u5C06\u63A5\u8FD1\u96F6\u3002</li></ul></li></ul></li><li><p><strong>\u8BA1\u7B97\u6982\u7387\u5206\u5E03</strong>:</p><ul><li><code>probs = F.softmax(logits, dim=-1)</code>: \u5BF9\u8C03\u6574\u540E\u7684 logits \u5E94\u7528 softmax \u51FD\u6570\uFF0C\u5F97\u5230\u6982\u7387\u5206\u5E03\u3002</li></ul></li><li><p><strong>\u91C7\u6837\u65B0 token</strong>:</p><ul><li><code>idx_next = torch.multinomial(probs, num_samples=1)</code>: \u4F7F\u7528\u6982\u7387\u5206\u5E03 <code>probs</code> \u8FDB\u884C\u91C7\u6837\uFF0C\u5F97\u5230\u4E0B\u4E00\u4E2A token \u7684\u7D22\u5F15\u3002</li></ul></li><li><p><strong>\u66F4\u65B0\u7D22\u5F15\u5E8F\u5217</strong>:</p><ul><li><code>idx = torch.cat((idx, idx_next), dim=1)</code>: \u5C06\u65B0\u91C7\u6837\u7684 token \u7D22\u5F15\u6DFB\u52A0\u5230\u8F93\u5165\u5E8F\u5217\u7684\u672B\u5C3E\u3002</li></ul></li><li><p><strong>\u5FAA\u73AF\u751F\u6210</strong>:</p><ul><li>\u5FAA\u73AF <code>max_generate_tokens</code> \u6B21\uFF0C\u6BCF\u6B21\u751F\u6210\u4E00\u4E2A\u65B0\u7684 token \u5E76\u5C06\u5176\u6DFB\u52A0\u5230\u5E8F\u5217\u4E2D\u3002</li></ul></li><li><p><strong>\u8FD4\u56DE\u751F\u6210\u7684\u5E8F\u5217</strong>:</p><ul><li><code>return idx</code>: \u8FD4\u56DE\u751F\u6210\u7684\u5B8C\u6574\u5E8F\u5217\u7684\u7D22\u5F15\u3002</li></ul></li></ol><p>\u8FD9\u4E2A\u65B9\u6CD5\u5B9E\u73B0\u4E86\u4E00\u4E2A\u7B80\u5355\u7684\u6587\u672C\u751F\u6210\u5FAA\u73AF\uFF0C\u901A\u8FC7\u9010\u6B65\u91C7\u6837\u65B0 token \u5E76\u5C06\u5176\u6DFB\u52A0\u5230\u5E8F\u5217\u4E2D\uFF0C\u76F4\u5230\u8FBE\u5230\u6700\u5927\u751F\u6210\u957F\u5EA6\u6216\u6EE1\u8DB3\u5176\u4ED6\u505C\u6B62\u6761\u4EF6\u3002\u6E29\u5EA6\u53C2\u6570\u548C top-k \u91C7\u6837\u662F\u63A7\u5236\u751F\u6210\u8FC7\u7A0B\u548C\u7ED3\u679C\u591A\u6837\u6027\u7684\u5E38\u7528\u6280\u672F\u3002</p><p>User: import os import numpy as np import torch import torch.nn as nn import math from model import Model_args,GPT import time</p><h1 id="\u6A21\u578B\u53C2\u6570" tabindex="-1">\u6A21\u578B\u53C2\u6570 <a class="header-anchor" href="#\u6A21\u578B\u53C2\u6570" aria-hidden="true">#</a></h1><p>block_size = 128 # \u7A97\u53E3\u5927\u5C0F GPT2 \u4E3A 1024 batch_size = 32 # \u6682\u5B9A\uFF0C\u4E4B\u540E\u518D\u770B\u663E\u5B58\u5360\u7528 n_layer = 12 n_head = 6 n_embed = 768 bias = False dropout = 0.0 dataset_path = &#39;./data/sherlock&#39; init_from = &#39;scratch&#39; # &#39;scratch&#39; or &#39;resume&#39; # \u4ECE\u5934\u8BAD\u7EC3\u8FD8\u662F\u7EE7\u7EED checkpoint_save_dir = &#39;./checkpoints&#39; eval_iters = 200 eval_interval = 2000 # \u6BCF n \u6B65 eval \u548C\u4FDD\u5B58 checkpoint \u4E00\u6B21</p><h1 id="\u5B66\u4E60\u7387\u8870\u51CF" tabindex="-1">\u5B66\u4E60\u7387\u8870\u51CF <a class="header-anchor" href="#\u5B66\u4E60\u7387\u8870\u51CF" aria-hidden="true">#</a></h1><p>learning_rate = 6e-4 warmup_iters = 2000 lr_decay_iters = 8000 min_lr = 6e-5</p><h1 id="\u4F18\u5316\u5668\u53C2\u6570" tabindex="-1">\u4F18\u5316\u5668\u53C2\u6570 <a class="header-anchor" href="#\u4F18\u5316\u5668\u53C2\u6570" aria-hidden="true">#</a></h1><p>max_iters = 6000 # \u8BAD\u7EC3\u591A\u5C11\u4E2A iter weight_decay = 1e-1 betas = (0.9,0.95) grad_clip = 1.0 # \u68AF\u5EA6\u88C1\u526A</p><h1 id="system" tabindex="-1">system <a class="header-anchor" href="#system" aria-hidden="true">#</a></h1><p>device = &#39;cuda&#39; device_type = &#39;cuda&#39; dtype = &#39;bfloat16&#39; if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else &#39;float16&#39;</p><h1 id="\u68C0\u67E5-cuda-\u662F\u5426\u652F\u6301-bfloat16-\u6570\u636E\u7C7B\u578B" tabindex="-1">\u68C0\u67E5 cuda \u662F\u5426\u652F\u6301 bfloat16 \u6570\u636E\u7C7B\u578B <a class="header-anchor" href="#\u68C0\u67E5-cuda-\u662F\u5426\u652F\u6301-bfloat16-\u6570\u636E\u7C7B\u578B" aria-hidden="true">#</a></h1><p>ptdtype = {&#39;float32&#39;: torch.float32, &#39;bfloat16&#39;: torch.bfloat16, &#39;float16&#39;: torch.float16}[dtype] ctx = torch.amp.autocast(device_type=device_type, dtype=ptdtype)</p><h1 id="torch-amp-autocast-\u6DF7\u5408\u7CBE\u5EA6" tabindex="-1">torch.amp.autocast \u6DF7\u5408\u7CBE\u5EA6 <a class="header-anchor" href="#torch-amp-autocast-\u6DF7\u5408\u7CBE\u5EA6" aria-hidden="true">#</a></h1><h1 id="dataloader" tabindex="-1">dataloader <a class="header-anchor" href="#dataloader" aria-hidden="true">#</a></h1><p>data_dir = os.path.join(dataset_path) def get_batch(split): # nanogpt \u4F5C\u8005\u8BF4\uFF0Cmemmap \u6BCF\u4E2A batch \u90FD\u8981\u7528\u4E00\u6B21\uFF0C\u8FD9\u6837\u624D\u4E0D\u4F1A\u5185\u5B58\u6CC4\u6F0F # <a href="https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122" target="_blank" rel="noreferrer">https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122</a><br> if split == &#39;train&#39;: data = np.memmap(os.path.join(data_dir, &#39;train.bin&#39;), dtype=np.uint16, mode=&#39;r&#39;) else: data = np.memmap(os.path.join(data_dir, &#39;val.bin&#39;), dtype=np.uint16, mode=&#39;r&#39;)</p><pre><code>ix = torch.randint(len(data)-block_size,(batch_size,)) #
# torch.randint(a, b, (size,))\u5373\u5728\uFF08a,b\uFF09\u8303\u56F4\u5185\u751F\u6210size\u4E2A\u968F\u673A\u6570
x = torch.stack([torch.from_numpy((data[i:i+block_size].astype(np.int64))) for i in ix]) # \u6839\u636Eix\u4ECEdata\u91CC\u9762\u53D6x,y
y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size].astype(np.int64))) for i in ix])
# torch.stack(inputs, dim=0),dim\u4E3A\u62FC\u63A5\u7684\u65B0\u7684\u7EF4\u5EA6

x,y = x.pin_memory().to(device,non_blocking=True),y.pin_memory().to(device,non_blocking=True)
# pin_memory()\u5C06\u5F20\u91CF\u9501\u5B9A\u5728\u5185\u5B58\u4E2D\uFF0Cnon_blocking=True\u6570\u636E\u4F20\u8F93\u662F\u975E\u963B\u585E\u7684\uFF0C\u4E0D\u4F1A\u963B\u585E\u5F53\u524D\u7EBF\u7A0B
return x,y
</code></pre><p>model_args = dict(n_layer=n_layer, n_head=n_head, n_embed=n_embed, block_size=block_size, bias=bias, vocab_size=None, dropout=dropout)</p><p>iter_num = 0 # resume \u7684\u8BDD\u4F1A\u8986\u76D6\u6389 0 best_val_loss = 1e9</p><p>assert init_from == &#39;scratch&#39; or init_from == &#39;resume&#39; if init_from == &#39;scratch&#39;: print(&quot;\u4ECE\u5934\u8BAD\u7EC3\u6A21\u578B&quot;) model_args[&#39;vocab_size&#39;] = 50304 # gpt2 tokenizer \u8BCD\u8868\u5927\u5C0F # \u8FD9\u91CC\u76F4\u63A5\u4F7F\u7528 GPT-2 \u7684\u8BCD\u8868\uFF0C\u5728 <a href="http://prepare.py" target="_blank" rel="noreferrer">prepare.py</a> \u4E2D\uFF0C\u8C03\u7528 tiktoken.get_encoding(&#39;gpt2&#39;)\u6765 tokenize gpt_args = Model_args(**model_args) model = GPT(gpt_args) # \u521B\u5EFA\u6A21\u578B</p><p>elif init_from == &#39;resume&#39;: # \u7EE7\u7EED\u8BAD\u7EC3 print(&quot;\u7EE7\u7EED\u8BAD\u7EC3\u6A21\u578B&quot;) ckpt_path = os.path.join(checkpoint_save_dir,&#39;<a href="http://checkpoint.pt" target="_blank" rel="noreferrer">checkpoint.pt</a>&#39;) # \u8BFB\u53D6 checkpoint \u8DEF\u5F84 checkpoint = torch.load(ckpt_path, map_location=device) checkpoint_model_args = checkpoint[&#39;model_args&#39;]# \u4ECE checkpoint \u91CC\u9762\u8BFB\u53D6\u6A21\u578B\u53C2\u6570 for k in [&#39;n_layer&#39;, &#39;n_head&#39;, &#39;n_embed&#39;, &#39;block_size&#39;, &#39;bias&#39;, &#39;vocab_size&#39;]: model_args[k] = checkpoint_model_args[k] gpt_args = Model_args(**model_args) model = GPT(gpt_args) state_dict = checkpoint[&#39;model&#39;] # \u6A21\u578B\u6743\u91CD model.load_state_dict(state_dict)</p><pre><code>iter_num = checkpoint[&#39;iter_num&#39;] # \u8FED\u4EE3\u5668\u6B65\u6570
best_val_loss = checkpoint[&#39;best_val_loss&#39;]
</code></pre><p>scaler = torch.cuda.amp.GradScaler(enabled=(dtype == &#39;float16&#39;))</p><h1 id="\u4F18\u5316\uFF1A\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3\uFF0C\u5927\u90E8\u5206\u4F7F\u7528-float16\uFF0C\u5C11\u90E8\u5206\u7528-float32" tabindex="-1">\u4F18\u5316\uFF1A\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3\uFF0C\u5927\u90E8\u5206\u4F7F\u7528 float16\uFF0C\u5C11\u90E8\u5206\u7528 float32 <a class="header-anchor" href="#\u4F18\u5316\uFF1A\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3\uFF0C\u5927\u90E8\u5206\u4F7F\u7528-float16\uFF0C\u5C11\u90E8\u5206\u7528-float32" aria-hidden="true">#</a></h1><p><a href="http://model.to" target="_blank" rel="noreferrer">model.to</a>(device) optimizer = model.configure_optimizers(weight_decay,learning_rate,betas,device_type) if init_from == &#39;resume&#39;: optimizer.load_state_dict(checkpoint[&#39;optimizer&#39;]) checkpoint = None# \u8FD9\u65F6\u5019 checkpoint \u5DF2\u7ECF\u8BFB\u597D\u4E86\uFF0C\u7ED9\u4ED6\u6E05\u7A7A\u4E00\u4E0B</p><h1 id="nanogpt-\u8FD8\u6709\u4E2A-torch-compile-\u7684\u4F18\u5316\uFF0C\u6211\u8FD9\u91CC\u6682\u65F6\u5148\u4E0D\u505A\u4E86" tabindex="-1">nanogpt \u8FD8\u6709\u4E2A torch.compile \u7684\u4F18\u5316\uFF0C\u6211\u8FD9\u91CC\u6682\u65F6\u5148\u4E0D\u505A\u4E86 <a class="header-anchor" href="#nanogpt-\u8FD8\u6709\u4E2A-torch-compile-\u7684\u4F18\u5316\uFF0C\u6211\u8FD9\u91CC\u6682\u65F6\u5148\u4E0D\u505A\u4E86" aria-hidden="true">#</a></h1><p>def estimate*loss(): model.eval() # eval \u4E0D\u8BA1\u7B97\u68AF\u5EA6 out = {} for split in [&#39;train&#39;,&#39;val&#39;]: # \u8FD9\u91CC\u662F\u8BAD\u7EC3\u96C6\u548C\u9A8C\u8BC1\u96C6\u90FD\u7B97\u4E00\u4E0B loss # \u6211\u53D1\u73B0 nanogpt \u4E2D\u5F88\u591A\u4F20\u53C2\u90FD\u7528 dict \u7684\u65B9\u5F0F losses = torch.zeros(eval_iters) for k in range(eval_iters): # print(f&quot;now_eval in {k}&quot;) X,Y = get_batch(split) with ctx: *,loss = model(X,Y) # x,targets losses[k] = loss.item() out[split] = losses.mean() model.train() # \u9000\u51FA\u65F6\u56DE\u5230 train \u7684\u6A21\u5F0F return out</p><h1 id="nanogpt-\u4F7F\u7528-cos-\u505A-learning-rate-\u7684\u4E0B\u964D" tabindex="-1">nanogpt \u4F7F\u7528 cos \u505A learning rate \u7684\u4E0B\u964D <a class="header-anchor" href="#nanogpt-\u4F7F\u7528-cos-\u505A-learning-rate-\u7684\u4E0B\u964D" aria-hidden="true">#</a></h1><p>def get_lr(now_iter): if(now_iter&lt;warmup_iters):#(1)warmup \u9636\u6BB5\uFF0C\u7EBF\u6027\u4E0A\u5347 return learning_rate<em>now_iter/warmup_iters elif(now_iter&gt;lr_decay_iters):#(2)\u8D85\u8FC7 decay\uFF0C\u5230 min \u4E86 return min_lr else:# (3)\u5728 warmup \u548C decay \u4E4B\u95F4\uFF0C\u7528 cos \u505A lr \u8870\u51CF rate = (now_iter-warmup_iters)/(lr_decay_iters-warmup_iters) # \u8BA1\u7B97\u6240\u5360\u6BD4\u4F8B(0,1) return min_lr + 0.5</em>(1.0+math.cos(math.pi*rate)) * (learning_rate-min_lr)</p><h1 id="\u8BAD\u7EC3\u4EE3\u7801" tabindex="-1">\u8BAD\u7EC3\u4EE3\u7801 <a class="header-anchor" href="#\u8BAD\u7EC3\u4EE3\u7801" aria-hidden="true">#</a></h1><p>X,Y = get_batch(&#39;train&#39;) t_before = time.time()</p><p>while(True): lr = get_lr(iter_num) for param_group in optimizer.param_groups: param_group[&#39;lr&#39;] = lr # \u8BBE\u7F6E\u5B66\u4E60\u7387</p><pre><code>if iter_num&gt;0 and iter_num % eval_interval == 0:
    # eval
    loss_dict = estimate_loss()
    print(f&quot;\u5F53\u524D\u8FDB\u884C{iter_num}\u4E2Aiter,train_loss:{loss_dict[&#39;train&#39;]},val_loss{loss_dict[&#39;val&#39;]}&quot;)
    best_val_loss = min(loss_dict[&#39;val&#39;],best_val_loss)
    # save checkpoint
    checkpoint = {
        &#39;model&#39;:model.state_dict(),
        &#39;optimizer&#39;:optimizer.state_dict,
        &#39;model_args&#39;: model_args,
        &#39;iter_num&#39;:iter_num,
        &#39;best_val_loss&#39;:best_val_loss
    }
    torch.save(checkpoint,os.path.join(checkpoint_save_dir,&#39;checkpoint.pt&#39;))
    print(f&quot;checkpoint\u4FDD\u5B58\u5728{checkpoint_save_dir}/checkpoint.pt&quot;)

with ctx:
    logits,loss = model(X,Y)
    print(f&quot;iter:{iter_num},loss:{loss.item()}&quot;)
    scaler.scale(loss).backward()
    # \u7528scaler\uFF0Cscale loss(FP16)\uFF0Cbackward\u5F97\u5230scaled\u7684\u68AF\u5EA6(FP16)
if grad_clip &gt;0.0:
    scaler.unscale_(optimizer) # unscale\u68AF\u5EA6\u56DEfp32
    nn.utils.clip_grad_norm_(model.parameters(),grad_clip)
    # \u68AF\u5EA6\u8FDB\u884C\u88C1\u526A\uFF0C\u4EE5\u9632\u6B62\u68AF\u5EA6\u7206\u70B8
scaler.step(optimizer) # \u7528scaler\u6267\u884Coptimizer.step()\u529F\u80FD
scaler.update() # scaler factor\u66F4\u65B0
&quot;&quot;&quot;
scaler\u7684\u4F7F\u7528\uFF0C\u627E\u5230\u4E00\u7BC7\u77E5\u4E4E\u7684\u6587\u7AE0https://zhuanlan.zhihu.com/p/348554267

\u4E4B\u524D\u7528\u4E86\u6DF7\u5408\u7CBE\u5EA6\uFF0C\u4F46\u662F\u628AFP32\u5230FP16\u65F6\u53EF\u80FD\u4F1A\u6EA2\u51FA\uFF0C\u6240\u4EE5\u9700\u8981\u4E58\u4E0A\u7CFB\u6570\u63A7\u5236\u8303\u56F4\u3002

GradScaler\u7684\u5DE5\u4F5C\u5C31\u662F\u5728\u53CD\u5411\u4F20\u64AD\u524D\u7ED9 loss \u4E58\u4E00\u4E2A scale factor\uFF0C
\u4E4B\u540E\u53CD\u5411\u4F20\u64AD\u5F97\u5230\u7684\u68AF\u5EA6\u90FD\u4E58\u4E86\u76F8\u540C\u7684 scale factor\u3002
\u5E76\u4E14\u4E3A\u4E86\u4E0D\u5F71\u54CD\u5B66\u4E60\u7387\uFF0C\u5728\u68AF\u5EA6\u66F4\u65B0\u524D\u5C06\u68AF\u5EA6unscale\u3002
\u6B65\u9AA4\u5982\u4E0B\uFF1A
    \u7EF4\u62A4\u4E00\u4E2A FP32 \u6570\u503C\u7CBE\u5EA6\u6A21\u578B\u7684\u526F\u672C
    \u5728\u6BCF\u4E2Aiteration
        \u62F7\u8D1D\u5E76\u4E14\u8F6C\u6362\u6210 FP16 \u6A21\u578B
        \u524D\u5411\u4F20\u64AD\uFF08FP16 \u7684\u6A21\u578B\u53C2\u6570\uFF09
        loss \u4E58 scale factor
        \u53CD\u5411\u4F20\u64AD\uFF08FP16 \u7684\u6A21\u578B\u53C2\u6570\u548C\u53C2\u6570\u68AF\u5EA6\uFF09
        \u53C2\u6570\u68AF\u5EA6\u4E58 1/scale factor
        \u5229\u7528 FP16 \u7684\u68AF\u5EA6\u66F4\u65B0 FP32 \u7684\u6A21\u578B\u53C2\u6570
&quot;&quot;&quot;
optimizer.zero_grad(set_to_none=True) # \u91CA\u653E\u5185\u5B58

t_after = time.time()
dt = t_after-t_before
t_before = t_after

iter_num += 1
if iter_num &gt; max_iters:
    break
</code></pre><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u662F\u4E00\u4E2A\u7528\u4E8E\u8BAD\u7EC3 GPT\uFF08\u4E00\u79CD\u57FA\u4E8E Transformer \u7684\u8BED\u8A00\u6A21\u578B\uFF09\u7684 Python \u811A\u672C\uFF0C\u5B83\u4F7F\u7528\u4E86 PyTorch \u6846\u67B6\u3002\u4EE5\u4E0B\u662F\u5BF9\u4EE3\u7801\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><h3 id="\u5BFC\u5165\u5FC5\u8981\u7684\u5E93" tabindex="-1">\u5BFC\u5165\u5FC5\u8981\u7684\u5E93 <a class="header-anchor" href="#\u5BFC\u5165\u5FC5\u8981\u7684\u5E93" aria-hidden="true">#</a></h3><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> os</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> numpy </span><span style="color:#F97583;">as</span><span style="color:#B392F0;"> np</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> torch</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> torch</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">nn </span><span style="color:#F97583;">as</span><span style="color:#B392F0;"> nn</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> math</span></span>
<span class="line"><span style="color:#F97583;">from</span><span style="color:#B392F0;"> model </span><span style="color:#F97583;">import</span><span style="color:#B392F0;"> Model_args</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> GPT  </span><span style="color:#6B737C;"># \u5047\u8BBE model.py \u4E2D\u5B9A\u4E49\u4E86 Model_args \u548C GPT \u7C7B</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#B392F0;"> time</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="\u8BBE\u7F6E\u6A21\u578B\u548C\u8BAD\u7EC3\u53C2\u6570" tabindex="-1">\u8BBE\u7F6E\u6A21\u578B\u548C\u8BAD\u7EC3\u53C2\u6570 <a class="header-anchor" href="#\u8BBE\u7F6E\u6A21\u578B\u548C\u8BAD\u7EC3\u53C2\u6570" aria-hidden="true">#</a></h3><ul><li>\u5B9A\u4E49\u4E86\u6A21\u578B\u7684\u53C2\u6570\uFF0C\u5982 <code>block_size</code>\uFF0C<code>batch_size</code>\uFF0C<code>n_layer</code>\uFF0C<code>n_head</code>\uFF0C<code>n_embed</code> \u7B49\u3002</li><li>\u8BBE\u7F6E\u4E86\u5B66\u4E60\u7387\u8C03\u5EA6\u53C2\u6570\uFF0C\u4F18\u5316\u5668\u53C2\u6570\uFF0C\u4EE5\u53CA\u6570\u636E\u96C6\u548C\u68C0\u67E5\u70B9\u4FDD\u5B58\u8DEF\u5F84\u3002</li></ul><h3 id="\u8BBE\u5907\u548C\u6DF7\u5408\u7CBE\u5EA6\u914D\u7F6E" tabindex="-1">\u8BBE\u5907\u548C\u6DF7\u5408\u7CBE\u5EA6\u914D\u7F6E <a class="header-anchor" href="#\u8BBE\u5907\u548C\u6DF7\u5408\u7CBE\u5EA6\u914D\u7F6E" aria-hidden="true">#</a></h3><ul><li>\u6839\u636E\u7CFB\u7EDF\u662F\u5426\u652F\u6301\u51B3\u5B9A\u4F7F\u7528 <code>float16</code> \u6216 <code>bfloat16</code>\u3002</li><li>\u4F7F\u7528 <code>torch.amp.autocast</code> \u542F\u7528\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3\u3002</li></ul><h3 id="\u6570\u636E\u52A0\u8F7D\u51FD\u6570" tabindex="-1">\u6570\u636E\u52A0\u8F7D\u51FD\u6570 <a class="header-anchor" href="#\u6570\u636E\u52A0\u8F7D\u51FD\u6570" aria-hidden="true">#</a></h3><ul><li><code>get_batch</code> \u51FD\u6570\u4ECE <code>*.bin</code> \u6587\u4EF6\u4E2D\u52A0\u8F7D\u6570\u636E\uFF0C\u5E76\u4F7F\u7528 <code>np.memmap</code> \u907F\u514D\u5185\u5B58\u6CC4\u6F0F\u3002</li></ul><h3 id="\u6A21\u578B\u521D\u59CB\u5316" tabindex="-1">\u6A21\u578B\u521D\u59CB\u5316 <a class="header-anchor" href="#\u6A21\u578B\u521D\u59CB\u5316" aria-hidden="true">#</a></h3><ul><li>\u6839\u636E <code>init_from</code> \u53C2\u6570\u51B3\u5B9A\u662F\u4ECE\u5934\u5F00\u59CB\u8BAD\u7EC3\u8FD8\u662F\u4ECE\u68C0\u67E5\u70B9\u6062\u590D\u3002</li></ul><h3 id="\u4F18\u5316\u5668\u548C-gradscaler-\u521D\u59CB\u5316" tabindex="-1">\u4F18\u5316\u5668\u548C GradScaler \u521D\u59CB\u5316 <a class="header-anchor" href="#\u4F18\u5316\u5668\u548C-gradscaler-\u521D\u59CB\u5316" aria-hidden="true">#</a></h3><ul><li>\u4F7F\u7528\u6A21\u578B\u7684 <code>configure_optimizers</code> \u65B9\u6CD5\u914D\u7F6E\u4F18\u5316\u5668\u3002</li><li>\u4F7F\u7528 <code>torch.cuda.amp.GradScaler</code> \u7528\u4E8E\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3\u4E2D\u7684\u68AF\u5EA6\u7F29\u653E\u3002</li></ul><h3 id="\u8BC4\u4F30\u51FD\u6570" tabindex="-1">\u8BC4\u4F30\u51FD\u6570 <a class="header-anchor" href="#\u8BC4\u4F30\u51FD\u6570" aria-hidden="true">#</a></h3><ul><li><code>estimate_loss</code> \u51FD\u6570\u8BA1\u7B97\u8BAD\u7EC3\u548C\u9A8C\u8BC1\u96C6\u4E0A\u7684\u635F\u5931\u3002</li></ul><h3 id="\u5B66\u4E60\u7387\u8C03\u5EA6\u51FD\u6570" tabindex="-1">\u5B66\u4E60\u7387\u8C03\u5EA6\u51FD\u6570 <a class="header-anchor" href="#\u5B66\u4E60\u7387\u8C03\u5EA6\u51FD\u6570" aria-hidden="true">#</a></h3><ul><li><code>get_lr</code> \u51FD\u6570\u6839\u636E\u5F53\u524D\u8FED\u4EE3\u6B21\u6570 <code>now_iter</code> \u8BA1\u7B97\u5B66\u4E60\u7387\u3002</li></ul><h3 id="\u8BAD\u7EC3\u5FAA\u73AF" tabindex="-1">\u8BAD\u7EC3\u5FAA\u73AF <a class="header-anchor" href="#\u8BAD\u7EC3\u5FAA\u73AF" aria-hidden="true">#</a></h3><ul><li>\u5728\u8BAD\u7EC3\u5FAA\u73AF\u4E2D\uFF0C\u9996\u5148\u8BBE\u7F6E\u5F53\u524D\u8FED\u4EE3\u7684\u5B66\u4E60\u7387\u3002</li><li>\u4F7F\u7528 <code>torch.amp.autocast</code> \u4E0A\u4E0B\u6587\u7BA1\u7406\u5668\u6765\u542F\u7528\u6DF7\u5408\u7CBE\u5EA6\u3002</li><li>\u6267\u884C\u6A21\u578B\u7684\u524D\u5411\u4F20\u64AD\u548C\u53CD\u5411\u4F20\u64AD\uFF0C\u4F7F\u7528 <code>GradScaler</code> \u6765\u5904\u7406\u68AF\u5EA6\u7F29\u653E\u3002</li><li>\u5982\u679C\u6EE1\u8DB3\u6761\u4EF6\uFF0C\u4FDD\u5B58\u68C0\u67E5\u70B9\u5E76\u8BC4\u4F30\u6A21\u578B\u3002</li></ul><h3 id="\u6027\u80FD\u76D1\u63A7" tabindex="-1">\u6027\u80FD\u76D1\u63A7 <a class="header-anchor" href="#\u6027\u80FD\u76D1\u63A7" aria-hidden="true">#</a></h3><ul><li>\u8BA1\u7B97\u6BCF\u6B21\u8FED\u4EE3\u7684\u65F6\u95F4\uFF0C\u5E76\u5728\u8FED\u4EE3\u7ED3\u675F\u65F6\u66F4\u65B0\u3002</li></ul><h3 id="\u9000\u51FA\u6761\u4EF6" tabindex="-1">\u9000\u51FA\u6761\u4EF6 <a class="header-anchor" href="#\u9000\u51FA\u6761\u4EF6" aria-hidden="true">#</a></h3><ul><li>\u5F53\u8FED\u4EE3\u6B21\u6570 <code>iter_num</code> \u8D85\u8FC7 <code>max_iters</code> \u65F6\u9000\u51FA\u8BAD\u7EC3\u5FAA\u73AF\u3002</li></ul><h3 id="\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3" tabindex="-1">\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3 <a class="header-anchor" href="#\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3" aria-hidden="true">#</a></h3><ul><li>\u4F7F\u7528 <code>GradScaler</code> \u6765\u5904\u7406\u53EF\u80FD\u7684\u6570\u503C\u6EA2\u51FA\u95EE\u9898\uFF0C\u901A\u8FC7\u5728\u53CD\u5411\u4F20\u64AD\u524D\u5BF9\u635F\u5931\u4E58\u4EE5\u4E00\u4E2A\u7F29\u653E\u56E0\u5B50\uFF0C\u7136\u540E\u5728\u53C2\u6570\u66F4\u65B0\u524D\u5C06\u68AF\u5EA6\u9664\u4EE5\u8FD9\u4E2A\u56E0\u5B50\u3002</li></ul><h3 id="\u68C0\u67E5\u70B9\u4FDD\u5B58" tabindex="-1">\u68C0\u67E5\u70B9\u4FDD\u5B58 <a class="header-anchor" href="#\u68C0\u67E5\u70B9\u4FDD\u5B58" aria-hidden="true">#</a></h3><ul><li>\u5B9A\u671F\u4FDD\u5B58\u6A21\u578B\u7684\u72B6\u6001\u5B57\u5178\u3001\u4F18\u5316\u5668\u72B6\u6001\u3001\u6A21\u578B\u53C2\u6570\u3001\u8FED\u4EE3\u6B21\u6570\u548C\u6700\u4F73\u9A8C\u8BC1\u635F\u5931\u3002</li></ul><h3 id="\u65E5\u5FD7\u8BB0\u5F55" tabindex="-1">\u65E5\u5FD7\u8BB0\u5F55 <a class="header-anchor" href="#\u65E5\u5FD7\u8BB0\u5F55" aria-hidden="true">#</a></h3><ul><li>\u6253\u5370\u5F53\u524D\u7684\u8FED\u4EE3\u6B21\u6570\u3001\u635F\u5931\u503C\u548C\u8BAD\u7EC3/\u9A8C\u8BC1\u635F\u5931\u3002</li></ul><p>\u8FD9\u4E2A\u811A\u672C\u5C55\u793A\u4E86\u5982\u4F55\u4F7F\u7528 PyTorch \u548C\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3\u6765\u8BAD\u7EC3\u4E00\u4E2A GPT \u6A21\u578B\u3002\u5B83\u5305\u62EC\u4E86\u6570\u636E\u52A0\u8F7D\u3001\u6A21\u578B\u521D\u59CB\u5316\u3001\u8BAD\u7EC3\u5FAA\u73AF\u3001\u5B66\u4E60\u7387\u8C03\u5EA6\u548C\u6027\u80FD\u76D1\u63A7\u7B49\u5173\u952E\u6B65\u9AA4\u3002</p><p>User: checkpoint = { &#39;model&#39;:model.state_dict(), &#39;optimizer&#39;:optimizer.state_dict, &#39;model_args&#39;: model_args, &#39;iter_num&#39;:iter_num, &#39;best_val_loss&#39;:best_val_loss }</p><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u521B\u5EFA\u4E86\u4E00\u4E2A\u540D\u4E3A <code>checkpoint</code> \u7684\u5B57\u5178\uFF0C\u5B83\u7528\u4E8E\u4FDD\u5B58\u6A21\u578B\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\u7684\u5173\u952E\u4FE1\u606F\uFF0C\u4EE5\u4FBF\u5728\u672A\u6765\u53EF\u4EE5\u6062\u590D\u8BAD\u7EC3\u6216\u8005\u8BC4\u4F30\u6A21\u578B\u7684\u6027\u80FD\u3002\u4EE5\u4E0B\u662F\u5B57\u5178\u4E2D\u5404\u4E2A\u952E\u503C\u5BF9\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ul><li><p><code>&#39;model&#39;</code>: <code>model.state_dict()</code> - \u8FD9\u4E2A\u952E\u5BF9\u5E94\u7684\u503C\u662F\u6A21\u578B\u7684\u72B6\u6001\u5B57\u5178\uFF0C\u5B83\u5305\u542B\u4E86\u6A21\u578B\u4E2D\u6240\u6709\u53C2\u6570\u7684\u5F53\u524D\u503C\u3002<code>state_dict</code> \u662F PyTorch \u4E2D\u7528\u4E8E\u4FDD\u5B58\u548C\u52A0\u8F7D\u6A21\u578B\u53C2\u6570\u7684\u5E38\u7528\u65B9\u6CD5\u3002</p></li><li><p><code>&#39;optimizer&#39;</code>: <code>optimizer.state_dict</code> - \u8FD9\u4E2A\u952E\u5BF9\u5E94\u7684\u503C\u662F\u4F18\u5316\u5668\u7684\u72B6\u6001\u5B57\u5178\uFF0C\u5B83\u4FDD\u5B58\u4E86\u4F18\u5316\u5668\u7684\u5F53\u524D\u72B6\u6001\uFF0C\u5305\u62EC\u53C2\u6570\uFF08\u5982\u5B66\u4E60\u7387\uFF09\u548C\u5185\u90E8\u7F13\u51B2\u533A\uFF08\u5982\u52A8\u91CF\u7D2F\u79EF\uFF09\u3002\u4FDD\u5B58\u4F18\u5316\u5668\u72B6\u6001\u5141\u8BB8\u4ECE\u7279\u5B9A\u7684\u8BAD\u7EC3\u9636\u6BB5\u6062\u590D\u800C\u65E0\u9700\u4ECE\u5934\u5F00\u59CB\u3002</p></li><li><p><code>&#39;model_args&#39;</code>: <code>model_args</code> - \u8FD9\u4E2A\u952E\u5B58\u50A8\u4E86\u7528\u4E8E\u521D\u59CB\u5316\u6A21\u578B\u7684\u53C2\u6570\u3002\u8FD9\u5728\u6062\u590D\u6A21\u578B\u65F6\u5F88\u6709\u7528\uFF0C\u56E0\u4E3A\u4F60\u53EF\u80FD\u9700\u8981\u8FD9\u4E9B\u53C2\u6570\u6765\u91CD\u65B0\u521B\u5EFA\u6A21\u578B\u7684\u5B9E\u4F8B\u3002</p></li><li><p><code>&#39;iter_num&#39;</code>: <code>iter_num</code> - \u8FD9\u4E2A\u952E\u8BB0\u5F55\u4E86\u5F53\u524D\u7684\u8BAD\u7EC3\u8FED\u4EE3\u6B21\u6570\u3002\u8FD9\u5141\u8BB8\u4F60\u5728\u6062\u590D\u8BAD\u7EC3\u65F6\u4ECE\u4E0A\u6B21\u505C\u6B62\u7684\u5730\u65B9\u7EE7\u7EED\u3002</p></li><li><p><code>&#39;best_val_loss&#39;</code>: <code>best_val_loss</code> - \u8FD9\u4E2A\u952E\u8BB0\u5F55\u4E86\u8FC4\u4ECA\u4E3A\u6B62\u5728\u9A8C\u8BC1\u96C6\u4E0A\u89C2\u5BDF\u5230\u7684\u6700\u4F4E\u635F\u5931\u503C\u3002\u8FD9\u4E2A\u6307\u6807\u53EF\u4EE5\u7528\u6765\u76D1\u63A7\u6A21\u578B\u7684\u6CDB\u5316\u80FD\u529B\uFF0C\u5E76\u5728\u6062\u590D\u8BAD\u7EC3\u65F6\u63D0\u4F9B\u4E00\u4E2A\u6027\u80FD\u57FA\u7EBF\u3002</p></li></ul><p>\u5C06\u8FD9\u4E9B\u7EC4\u4EF6\u653E\u5165 <code>checkpoint</code> \u5B57\u5178\u540E\uFF0C\u4F60\u53EF\u4EE5\u4F7F\u7528 <code>torch.save</code> \u51FD\u6570\u5C06\u5176\u4FDD\u5B58\u5230\u6587\u4EF6\u4E2D\uFF0C\u5982\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#B392F0;">torch</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">save</span><span style="color:#BBBBBB;">(checkpoint, os.path.</span><span style="color:#B392F0;">join</span><span style="color:#BBBBBB;">(checkpoint_save_dir, </span><span style="color:#FFAB70;">&#39;checkpoint.pt&#39;</span><span style="color:#BBBBBB;">))</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>\u8FD9\u5C06\u5E8F\u5217\u5316 <code>checkpoint</code> \u5B57\u5178\u5E76\u5C06\u5176\u5199\u5165\u5230\u6307\u5B9A\u7684\u6587\u4EF6\u8DEF\u5F84\u3002\u5728\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\u5B9A\u671F\u4FDD\u5B58\u68C0\u67E5\u70B9\u662F\u4E00\u79CD\u597D\u7684\u5B9E\u8DF5\uFF0C\u5B83\u53EF\u4EE5\u9632\u6B62\u6570\u636E\u4E22\u5931\uFF0C\u5E76\u63D0\u4F9B\u6A21\u578B\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\u7684\u5FEB\u7167\u3002</p><p>\u6062\u590D\u68C0\u67E5\u70B9\u65F6\uFF0C\u4F60\u53EF\u4EE5\u4F7F\u7528 <code>torch.load</code> \u51FD\u6570\u52A0\u8F7D\u8FD9\u4E2A\u5B57\u5178\uFF0C\u5E76\u4F7F\u7528\u5176\u4E2D\u7684\u4FE1\u606F\u6765\u6062\u590D\u6A21\u578B\u548C\u4F18\u5316\u5668\u7684\u72B6\u6001\uFF0C\u4EE5\u53CA\u7EE7\u7EED\u8BAD\u7EC3\u7684\u8FED\u4EE3\u6B21\u6570\u3002\u4F8B\u5982\uFF1A</p><div class="language-python line-numbers-mode"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#6B737C;"># \u52A0\u8F7D\u68C0\u67E5\u70B9</span></span>
<span class="line"><span style="color:#B392F0;">checkpoint </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> torch</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">load</span><span style="color:#BBBBBB;">(ckpt_path, map_location</span><span style="color:#F97583;">=</span><span style="color:#BBBBBB;">device)</span></span>
<span class="line"><span style="color:#6B737C;"># \u6062\u590D\u6A21\u578B\u72B6\u6001</span></span>
<span class="line"><span style="color:#B392F0;">model</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">load_state_dict</span><span style="color:#BBBBBB;">(checkpoint[</span><span style="color:#FFAB70;">&#39;model&#39;</span><span style="color:#BBBBBB;">])</span></span>
<span class="line"><span style="color:#6B737C;"># \u6062\u590D\u4F18\u5316\u5668\u72B6\u6001</span></span>
<span class="line"><span style="color:#B392F0;">optimizer</span><span style="color:#BBBBBB;">.</span><span style="color:#B392F0;">load_state_dict</span><span style="color:#BBBBBB;">(checkpoint[</span><span style="color:#FFAB70;">&#39;optimizer&#39;</span><span style="color:#BBBBBB;">])</span></span>
<span class="line"><span style="color:#6B737C;"># \u6062\u590D\u5176\u4ED6\u8BAD\u7EC3\u53C2\u6570</span></span>
<span class="line"><span style="color:#B392F0;">iter_num </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> checkpoint</span><span style="color:#BBBBBB;">[</span><span style="color:#FFAB70;">&#39;iter_num&#39;</span><span style="color:#BBBBBB;">]</span></span>
<span class="line"><span style="color:#B392F0;">best_val_loss </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> checkpoint</span><span style="color:#BBBBBB;">[</span><span style="color:#FFAB70;">&#39;best_val_loss&#39;</span><span style="color:#BBBBBB;">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>\u8FD9\u6837\uFF0C\u4F60\u5C31\u53EF\u4EE5\u4ECE\u68C0\u67E5\u70B9\u7EE7\u7EED\u8BAD\u7EC3\u6A21\u578B\uFF0C\u800C\u65E0\u9700\u4ECE\u5934\u5F00\u59CB\u3002</p><p>User: <a href="http://model.to" target="_blank" rel="noreferrer">model.to</a>(device) optimizer = model.configure_optimizers(weight_decay,learning_rate,betas,device_type) if init_from == &#39;resume&#39;: optimizer.load_state_dict(checkpoint[&#39;optimizer&#39;]) checkpoint = None# \u8FD9\u65F6\u5019 checkpoint \u5DF2\u7ECF\u8BFB\u597D\u4E86\uFF0C\u7ED9\u4ED6\u6E05\u7A7A\u4E00\u4E0B</p><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u662F\u8BAD\u7EC3\u6D41\u7A0B\u4E2D\u5173\u4E8E\u6A21\u578B\u3001\u4F18\u5316\u5668\u5904\u7406\u548C\u68C0\u67E5\u70B9\u52A0\u8F7D\u7684\u90E8\u5206\u3002\u4EE5\u4E0B\u662F\u5BF9\u4EE3\u7801\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ol><li><p><strong>\u6A21\u578B\u79FB\u52A8\u5230\u8BBE\u5907</strong>:</p><ul><li><code>model.to(device)</code>: \u8FD9\u884C\u4EE3\u7801\u5C06\u6A21\u578B\u79FB\u52A8\u5230\u6307\u5B9A\u7684\u8BBE\u5907\uFF08\u901A\u5E38\u662F GPU\uFF09\uFF0C\u4EE5\u52A0\u901F\u8BA1\u7B97\u3002<code>device</code> \u662F\u4E00\u4E2A\u5B57\u7B26\u4E32\uFF0C\u8868\u793A\u8BA1\u7B97\u5C06\u5728\u54EA\u4E2A\u8BBE\u5907\u4E0A\u6267\u884C\uFF0C\u4F8B\u5982 <code>&#39;cuda&#39;</code> \u8868\u793A GPU\u3002</li></ul></li><li><p><strong>\u914D\u7F6E\u4F18\u5316\u5668</strong>:</p><ul><li><code>optimizer = model.configure_optimizers(weight_decay, learning_rate, betas, device_type)</code>: \u8FD9\u884C\u4EE3\u7801\u8C03\u7528\u6A21\u578B\u7684 <code>configure_optimizers</code> \u65B9\u6CD5\u6765\u521B\u5EFA\u4E00\u4E2A\u4F18\u5316\u5668\u3002\u8FD9\u4E2A\u65B9\u6CD5\u63A5\u6536\u6743\u91CD\u8870\u51CF <code>weight_decay</code>\u3001\u5B66\u4E60\u7387 <code>learning_rate</code>\u3001\u52A8\u91CF\u53C2\u6570 <code>betas</code> \u548C\u8BBE\u5907\u7C7B\u578B <code>device_type</code> \u4F5C\u4E3A\u8F93\u5165\uFF0C\u8FD4\u56DE\u4E00\u4E2A\u914D\u7F6E\u597D\u7684\u4F18\u5316\u5668\u5B9E\u4F8B\u3002</li></ul></li><li><p><strong>\u4ECE\u68C0\u67E5\u70B9\u6062\u590D</strong>:</p><ul><li><code>if init_from == &#39;resume&#39;:</code>: \u5982\u679C\u8BAD\u7EC3\u662F\u4ECE\u5148\u524D\u7684\u72B6\u6001\u6062\u590D\uFF08\u5373 <code>init_from</code> \u88AB\u8BBE\u7F6E\u4E3A <code>&#39;resume&#39;</code>\uFF09\uFF0C\u5219\u6267\u884C\u4EE5\u4E0B\u64CD\u4F5C\uFF1A <ul><li><code>optimizer.load_state_dict(checkpoint[&#39;optimizer&#39;])</code>: \u8FD9\u884C\u4EE3\u7801\u52A0\u8F7D\u5148\u524D\u4FDD\u5B58\u7684\u4F18\u5316\u5668\u72B6\u6001\u3002<code>checkpoint[&#39;optimizer&#39;]</code> \u662F\u4ECE\u68C0\u67E5\u70B9\u6587\u4EF6\u4E2D\u52A0\u8F7D\u7684\u4F18\u5316\u5668\u72B6\u6001\u5B57\u5178\u3002</li></ul></li></ul></li><li><p><strong>\u6E05\u7A7A\u68C0\u67E5\u70B9\u53D8\u91CF</strong>:</p><ul><li><code>checkpoint = None</code>: \u52A0\u8F7D\u5B8C\u68C0\u67E5\u70B9\u540E\uFF0C\u5C06 <code>checkpoint</code> \u53D8\u91CF\u8BBE\u7F6E\u4E3A <code>None</code>\u3002\u8FD9\u6709\u52A9\u4E8E\u907F\u514D\u5728\u5185\u5B58\u4E2D\u5B58\u50A8\u4E0D\u5FC5\u8981\u7684\u5927\u578B\u5BF9\u8C61\uFF0C\u5C24\u5176\u662F\u5728\u957F\u65F6\u95F4\u8FD0\u884C\u7684\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\u3002</li></ul></li><li><p><strong>\u4F7F\u7528\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3</strong>:</p><ul><li>\u4EE3\u7801\u4E2D\u6CA1\u6709\u76F4\u63A5\u663E\u793A\uFF0C\u4F46 <code>model.configure_optimizers</code> \u65B9\u6CD5\u53EF\u80FD\u5DF2\u7ECF\u914D\u7F6E\u4E86\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3\uFF0C\u8FD9\u901A\u5E38\u6D89\u53CA\u5230 <code>torch.cuda.amp</code> \u5DE5\u5177\u7684\u4F7F\u7528\uFF0C\u4F8B\u5982 <code>GradScaler</code>\u3002</li></ul></li><li><p><strong>\u8BBE\u5907\u7C7B\u578B\u548C\u6570\u636E\u7C7B\u578B</strong>:</p><ul><li>\u4EE3\u7801\u4E2D\u6CA1\u6709\u76F4\u63A5\u663E\u793A\uFF0C\u4F46 <code>device_type</code> \u548C <code>dtype</code> \u7684\u8BBE\u7F6E\u53EF\u80FD\u4E0E\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3\u6709\u5173\u3002\u4F8B\u5982\uFF0C\u5982\u679C\u4F7F\u7528 <code>bfloat16</code> \u6570\u636E\u7C7B\u578B\uFF0C\u53EF\u80FD\u9700\u8981\u5728\u4F18\u5316\u5668\u914D\u7F6E\u4E2D\u8003\u8651\u6570\u636E\u7C7B\u578B\u7684\u517C\u5BB9\u6027\u3002</li></ul></li></ol><p>\u8FD9\u6BB5\u4EE3\u7801\u786E\u4FDD\u4E86\u6A21\u578B\u548C\u4F18\u5316\u5668\u80FD\u591F\u88AB\u6B63\u786E\u5730\u521D\u59CB\u5316\u6216\u4ECE\u5148\u524D\u7684\u72B6\u6001\u6062\u590D\uFF0C\u5E76\u4E14\u6A21\u578B\u88AB\u79FB\u52A8\u5230\u4E86\u9002\u5408\u8BAD\u7EC3\u7684\u8BBE\u5907\u4E0A\u3002\u6B64\u5916\uFF0C\u901A\u8FC7\u6E05\u7A7A\u4E0D\u518D\u9700\u8981\u7684\u68C0\u67E5\u70B9\u6570\u636E\uFF0C\u5B83\u8FD8\u6709\u52A9\u4E8E\u4F18\u5316\u5185\u5B58\u4F7F\u7528\u3002</p><p>User: def estimate*loss(): model.eval() # eval \u4E0D\u8BA1\u7B97\u68AF\u5EA6 out = {} for split in [&#39;train&#39;,&#39;val&#39;]: # \u8FD9\u91CC\u662F\u8BAD\u7EC3\u96C6\u548C\u9A8C\u8BC1\u96C6\u90FD\u7B97\u4E00\u4E0B loss # \u6211\u53D1\u73B0 nanogpt \u4E2D\u5F88\u591A\u4F20\u53C2\u90FD\u7528 dict \u7684\u65B9\u5F0F losses = torch.zeros(eval_iters) for k in range(eval_iters): # print(f&quot;now_eval in {k}&quot;) X,Y = get_batch(split) with ctx: *,loss = model(X,Y) # x,targets losses[k] = loss.item() out[split] = losses.mean() model.train() # \u9000\u51FA\u65F6\u56DE\u5230 train \u7684\u6A21\u5F0F return out</p><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u5B9A\u4E49\u4E86\u4E00\u4E2A\u540D\u4E3A <code>estimate_loss</code> \u7684\u51FD\u6570\uFF0C\u7528\u4E8E\u8BC4\u4F30\u6A21\u578B\u5728\u8BAD\u7EC3\u96C6\u548C\u9A8C\u8BC1\u96C6\u4E0A\u7684\u5E73\u5747\u635F\u5931\u3002\u4EE5\u4E0B\u662F\u8BE6\u7EC6\u6B65\u9AA4\u548C\u5173\u952E\u70B9\uFF1A</p><ol><li><p><strong>\u8BBE\u7F6E\u6A21\u578B\u4E3A\u8BC4\u4F30\u6A21\u5F0F</strong>:</p><ul><li><code>model.eval()</code>: \u8C03\u7528\u6A21\u578B\u7684 <code>eval</code> \u65B9\u6CD5\uFF0C\u5C06\u6A21\u578B\u8BBE\u7F6E\u4E3A\u8BC4\u4F30\u6A21\u5F0F\u3002\u5728\u8BC4\u4F30\u6A21\u5F0F\u4E0B\uFF0C\u6A21\u578B\u4E2D\u7684\u67D0\u4E9B\u5C42\uFF08\u5982 Dropout \u548C Batch Normalization\uFF09\u7684\u884C\u4E3A\u4F1A\u6539\u53D8\uFF0C\u4EE5\u9002\u5E94\u8BC4\u4F30\u548C\u63A8\u7406\u8FC7\u7A0B\u3002</li></ul></li><li><p><strong>\u521D\u59CB\u5316\u8F93\u51FA\u5B57\u5178</strong>:</p><ul><li><code>out = {}</code>: \u521B\u5EFA\u4E00\u4E2A\u7A7A\u5B57\u5178\uFF0C\u7528\u4E8E\u5B58\u50A8\u4E0D\u540C\u6570\u636E\u96C6\uFF08\u8BAD\u7EC3\u96C6\u548C\u9A8C\u8BC1\u96C6\uFF09\u7684\u5E73\u5747\u635F\u5931\u3002</li></ul></li><li><p><strong>\u5FAA\u73AF\u5904\u7406\u6570\u636E\u96C6</strong>:</p><ul><li>\u5916\u5C42\u5FAA\u73AF\u904D\u5386 <code>[&#39;train&#39;, &#39;val&#39;]</code>\uFF0C\u5206\u522B\u4EE3\u8868\u8BAD\u7EC3\u96C6\u548C\u9A8C\u8BC1\u96C6\u3002</li></ul></li><li><p><strong>\u521D\u59CB\u5316\u635F\u5931\u6570\u7EC4</strong>:</p><ul><li><code>losses = torch.zeros(eval_iters)</code>: \u5BF9\u4E8E\u6BCF\u4E2A\u6570\u636E\u96C6\uFF0C\u521B\u5EFA\u4E00\u4E2A\u957F\u5EA6\u4E3A <code>eval_iters</code> \u7684\u5F20\u91CF\uFF0C\u7528\u4E8E\u5B58\u50A8\u8FED\u4EE3\u8FC7\u7A0B\u4E2D\u7684\u635F\u5931\u503C\u3002</li></ul></li><li><p><strong>\u8FED\u4EE3\u8BA1\u7B97\u635F\u5931</strong>:</p><ul><li>\u5185\u5C42\u5FAA\u73AF <code>for k in range(eval_iters)</code>: \u6267\u884C <code>eval_iters</code> \u6B21\u8FED\u4EE3\uFF0C\u6BCF\u6B21\u8FED\u4EE3\u90FD\u8BA1\u7B97\u4E00\u6B21\u635F\u5931\u3002</li><li><code>X, Y = get_batch(split)</code>: \u8C03\u7528 <code>get_batch</code> \u51FD\u6570\u83B7\u53D6\u5F53\u524D\u6570\u636E\u96C6\u7684\u4E00\u4E2A\u6279\u6B21\u6570\u636E\u3002</li><li><code>with ctx:</code>: \u4F7F\u7528\u4E0A\u4E0B\u6587\u7BA1\u7406\u5668 <code>ctx</code>\uFF08\u53EF\u80FD\u662F <code>torch.amp.autocast</code>\uFF09\u6765\u542F\u7528\u6DF7\u5408\u7CBE\u5EA6\u8BAD\u7EC3\u3002</li><li><code>_, loss = model(X, Y)</code>: \u8C03\u7528\u6A21\u578B\u7684 <code>forward</code> \u65B9\u6CD5\u8BA1\u7B97\u635F\u5931\uFF0C\u8FD9\u91CC <code>_</code> \u8868\u793A\u6211\u4EEC\u4E0D\u5173\u5FC3\u6A21\u578B\u7684\u8F93\u51FA\uFF08\u4EC5\u5173\u5FC3\u635F\u5931\uFF09\u3002</li></ul></li><li><p><strong>\u8BB0\u5F55\u635F\u5931</strong>:</p><ul><li><code>losses[k] = loss.item()</code>: \u5C06\u8BA1\u7B97\u5F97\u5230\u7684\u635F\u5931\u503C\u8BB0\u5F55\u5230 <code>losses</code> \u5F20\u91CF\u4E2D\u3002</li></ul></li><li><p><strong>\u8BA1\u7B97\u5E73\u5747\u635F\u5931</strong>:</p><ul><li><code>out[split] = losses.mean()</code>: \u8BA1\u7B97\u8BB0\u5F55\u7684\u635F\u5931\u503C\u7684\u5E73\u5747\u503C\uFF0C\u5E76\u5C06\u5176\u5B58\u50A8\u5728 <code>out</code> \u5B57\u5178\u4E2D\uFF0C\u952E\u4E3A\u5F53\u524D\u7684\u6570\u636E\u96C6\u540D\u79F0\uFF08<code>split</code>\uFF09\u3002</li></ul></li><li><p><strong>\u8BBE\u7F6E\u6A21\u578B\u4E3A\u8BAD\u7EC3\u6A21\u5F0F</strong>:</p><ul><li><code>model.train()</code>: \u5728\u51FD\u6570\u7ED3\u675F\u524D\uFF0C\u5C06\u6A21\u578B\u8BBE\u7F6E\u56DE\u8BAD\u7EC3\u6A21\u5F0F\uFF0C\u4EE5\u786E\u4FDD\u6A21\u578B\u5728\u4E0B\u4E00\u6B21\u8C03\u7528 <code>estimate_loss</code> \u4E4B\u524D\u5904\u4E8E\u6B63\u786E\u7684\u72B6\u6001\u3002</li></ul></li><li><p><strong>\u8FD4\u56DE\u7ED3\u679C</strong>:</p><ul><li><code>return out</code>: \u8FD4\u56DE\u5305\u542B\u8BAD\u7EC3\u96C6\u548C\u9A8C\u8BC1\u96C6\u5E73\u5747\u635F\u5931\u7684\u5B57\u5178\u3002</li></ul></li></ol><p>\u8FD9\u4E2A\u51FD\u6570\u5141\u8BB8\u4F60\u8BC4\u4F30\u6A21\u578B\u5728\u4E0D\u540C\u6570\u636E\u96C6\u4E0A\u7684\u6027\u80FD\uFF0C\u901A\u5E38\u7528\u4E8E\u76D1\u63A7\u6A21\u578B\u8BAD\u7EC3\u8FC7\u7A0B\u4E2D\u7684\u635F\u5931\u53D8\u5316\uFF0C\u4EE5\u53CA\u68C0\u67E5\u6A21\u578B\u662F\u5426\u8FC7\u62DF\u5408\u6216\u6B20\u62DF\u5408\u3002\u901A\u8FC7\u5B9A\u671F\u8C03\u7528\u6B64\u51FD\u6570\uFF0C\u4F60\u53EF\u4EE5\u83B7\u5F97\u6A21\u578B\u5728\u8BAD\u7EC3\u548C\u9A8C\u8BC1\u8FC7\u7A0B\u4E2D\u635F\u5931\u7684\u5FEB\u7167\u3002</p><p>User: def get_lr(now_iter): if(now_iter&lt;warmup_iters):#(1)warmup \u9636\u6BB5\uFF0C\u7EBF\u6027\u4E0A\u5347 return learning_rate<em>now_iter/warmup_iters elif(now_iter&gt;lr_decay_iters):#(2)\u8D85\u8FC7 decay\uFF0C\u5230 min \u4E86 return min_lr else:# (3)\u5728 warmup \u548C decay \u4E4B\u95F4\uFF0C\u7528 cos \u505A lr \u8870\u51CF rate = (now_iter-warmup_iters)/(lr_decay_iters-warmup_iters) # \u8BA1\u7B97\u6240\u5360\u6BD4\u4F8B(0,1) return min_lr + 0.5</em>(1.0+math.cos(math.pi*rate)) * (learning_rate-min_lr)</p><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u5B9A\u4E49\u4E86\u4E00\u4E2A\u540D\u4E3A <code>get_lr</code> \u7684\u51FD\u6570\uFF0C\u7528\u4E8E\u6839\u636E\u5F53\u524D\u8FED\u4EE3\u6B21\u6570 <code>now_iter</code> \u8BA1\u7B97\u5B66\u4E60\u7387\u3002\u8FD9\u4E2A\u51FD\u6570\u5B9E\u73B0\u4E86\u4E00\u4E2A\u5B66\u4E60\u7387\u8C03\u5EA6\u7B56\u7565\uFF0C\u901A\u5E38\u7528\u4E8E\u5E2E\u52A9\u6A21\u578B\u5728\u8BAD\u7EC3\u521D\u671F\u5FEB\u901F\u6536\u655B\uFF0C\u5E76\u5728\u540E\u671F\u7A33\u5B9A\u6536\u655B\u901F\u5EA6\u3002\u4EE5\u4E0B\u662F\u8BE5\u51FD\u6570\u7684\u8BE6\u7EC6\u89E3\u91CA\uFF1A</p><ol><li><p><strong>Warmup \u9636\u6BB5</strong>:</p><ul><li>\u5982\u679C <code>now_iter</code> \u5C0F\u4E8E <code>warmup_iters</code>\uFF0C\u5219\u5904\u4E8E\u9884\u70ED\u9636\u6BB5\uFF08warmup phase\uFF09\u3002\u5728\u8FD9\u4E2A\u9636\u6BB5\uFF0C\u5B66\u4E60\u7387\u4ECE 0 \u5F00\u59CB\u7EBF\u6027\u589E\u52A0\u5230\u521D\u59CB\u5B66\u4E60\u7387 <code>learning_rate</code>\u3002\u8BA1\u7B97\u516C\u5F0F\u4E3A\uFF1A [ \\text{learning_rate} \\times \\left(\\frac{\\text{now_iter}}{\\text{warmup_iters}}\\right) ]</li><li>\u8FD9\u79CD\u65B9\u6CD5\u53EF\u4EE5\u9632\u6B62\u8BAD\u7EC3\u521D\u671F\u7531\u4E8E\u5B66\u4E60\u7387\u8FC7\u9AD8\u5BFC\u81F4\u7684\u4E0D\u7A33\u5B9A\u3002</li></ul></li><li><p><strong>\u5B66\u4E60\u7387\u8870\u51CF</strong>:</p><ul><li>\u5982\u679C <code>now_iter</code> \u5927\u4E8E <code>lr_decay_iters</code>\uFF0C\u5219\u5DF2\u7ECF\u8D85\u51FA\u4E86\u8870\u51CF\u8FED\u4EE3\u6B21\u6570\uFF0C\u6B64\u65F6\u5B66\u4E60\u7387\u5C06\u88AB\u8BBE\u7F6E\u4E3A\u6700\u5C0F\u5B66\u4E60\u7387 <code>min_lr</code>\u3002</li></ul></li><li><p><strong>Cosine \u8870\u51CF</strong>:</p><ul><li>\u5982\u679C <code>now_iter</code> \u5728 <code>warmup_iters</code> \u548C <code>lr_decay_iters</code> \u4E4B\u95F4\uFF0C\u5C06\u4F7F\u7528\u4F59\u5F26\u9000\u706B\u7B56\u7565\uFF08cosine annealing\uFF09\u8C03\u6574\u5B66\u4E60\u7387\u3002\u8BA1\u7B97\u516C\u5F0F\u4E3A\uFF1A [ \\text{min_lr} + \\frac{1}{2} \\times (1 + \\cos(\\pi \\times \\text{rate})) \\times (\\text{learning_rate} - \\text{min_lr}) ] \u5176\u4E2D\uFF0C<code>rate</code> \u662F\u4E00\u4E2A\u4ECE 0 \u5230 1 \u7684\u6BD4\u4F8B\u7CFB\u6570\uFF0C\u8868\u793A\u5F53\u524D\u8FED\u4EE3\u5728\u9884\u70ED\u9636\u6BB5\u548C\u8870\u51CF\u9636\u6BB5\u4E4B\u95F4\u7684\u4F4D\u7F6E\u3002</li></ul></li><li><p><strong>\u4F59\u5F26\u9000\u706B</strong>:</p><ul><li>\u4F59\u5F26\u9000\u706B\u662F\u4E00\u79CD\u6A21\u4EFF\u4F59\u5F26\u51FD\u6570\u5468\u671F\u6027\u53D8\u5316\u7684\u65B9\u6CD5\uFF0C\u7528\u4E8E\u5E73\u6ED1\u5730\u51CF\u5C11\u5B66\u4E60\u7387\u3002\u8FD9\u79CD\u65B9\u6CD5\u53EF\u4EE5\u4F7F\u5B66\u4E60\u7387\u5728\u9884\u70ED\u9636\u6BB5\u4E4B\u540E\u9010\u6E10\u964D\u4F4E\uFF0C\u800C\u4E0D\u662F\u7A81\u7136\u51CF\u5C11\uFF0C\u6709\u52A9\u4E8E\u6A21\u578B\u5728\u8BAD\u7EC3\u540E\u671F\u66F4\u7EC6\u81F4\u5730\u63A2\u7D22\u6700\u4F18\u89E3\u7A7A\u95F4\u3002</li></ul></li></ol><p>\u8FD9\u4E2A\u5B66\u4E60\u7387\u8C03\u5EA6\u7B56\u7565\u7ED3\u5408\u4E86\u9884\u70ED\u3001\u7EBF\u6027\u8870\u51CF\u548C\u4F59\u5F26\u9000\u706B\u4E09\u79CD\u65B9\u6CD5\uFF0C\u65E8\u5728\u5E73\u8861\u8BAD\u7EC3\u901F\u5EA6\u548C\u6A21\u578B\u6027\u80FD\u3002\u9884\u70ED\u9636\u6BB5\u5E2E\u52A9\u6A21\u578B\u5FEB\u901F\u8FDB\u5165\u7A33\u5B9A\u72B6\u6001\uFF0C\u4F59\u5F26\u9000\u706B\u5219\u6709\u52A9\u4E8E\u5728\u8BAD\u7EC3\u540E\u671F\u907F\u514D\u8FC7\u65E9\u6536\u655B\u5230\u6B21\u4F18\u89E3\u3002\u901A\u8FC7\u9002\u5F53\u8C03\u6574 <code>warmup_iters</code>\u3001<code>lr_decay_iters</code>\u3001<code>learning_rate</code> \u548C <code>min_lr</code> \u7B49\u53C2\u6570\uFF0C\u53EF\u4EE5\u8FDB\u4E00\u6B65\u4F18\u5316\u5B66\u4E60\u7387\u8C03\u5EA6\u4EE5\u9002\u5E94\u4E0D\u540C\u7684\u8BAD\u7EC3\u4EFB\u52A1\u548C\u6A21\u578B\u3002</p><p>User: import os import tiktoken import torch from model import GPT,Model_args</p><p>checkpoint_save_dir = &#39;./checkpoints&#39; device = &#39;cuda&#39; device_type = &#39;cuda&#39; dtype = &#39;bfloat16&#39; ptdtype = {&#39;float32&#39;: torch.float32, &#39;bfloat16&#39;: torch.bfloat16, &#39;float16&#39;: torch.float16}[dtype]</p><h1 id="generate-\u53C2\u6570" tabindex="-1">generate \u53C2\u6570 <a class="header-anchor" href="#generate-\u53C2\u6570" aria-hidden="true">#</a></h1><p>top_k = 200 tempreture = 0.5 # \u4E00\u822C\u90FD\u5148\u8BBE\u7F6E 1\uFF0C\u60F3\u8981\u66F4 random \u4E00\u70B9\u5C31\u5F80\u4E0A\u8C03 start = &quot;Sherlock Homes&quot; # \u8FD9\u662F\u6700\u5F00\u59CB\u7684\u8F93\u5165 num_samples = 1 # sample \u51E0\u6B21 max_new_tokens = 128</p><h1 id="\u8BFB-checkpoint" tabindex="-1">\u8BFB checkpoint <a class="header-anchor" href="#\u8BFB-checkpoint" aria-hidden="true">#</a></h1><p>print(f&quot;load checkpoint from {checkpoint_save_dir}&quot;) ckpt_path = os.path.join(checkpoint_save_dir,&#39;<a href="http://checkpoint.pt" target="_blank" rel="noreferrer">checkpoint.pt</a>&#39;) # \u8BFB\u53D6 checkpoint \u8DEF\u5F84 checkpoint = torch.load(ckpt_path, map_location=device) args = checkpoint[&#39;model_args&#39;] model = GPT(Model_args(**args))</p><h1 id="\u8BFB\u53D6\u6743\u91CD" tabindex="-1">\u8BFB\u53D6\u6743\u91CD <a class="header-anchor" href="#\u8BFB\u53D6\u6743\u91CD" aria-hidden="true">#</a></h1><h1 id="for-k-v-in-checkpoint-items" tabindex="-1">for k,v in checkpoint.items(): <a class="header-anchor" href="#for-k-v-in-checkpoint-items" aria-hidden="true">#</a></h1><h1 id="print-k" tabindex="-1">print(k) <a class="header-anchor" href="#print-k" aria-hidden="true">#</a></h1><p>state_dict = checkpoint[&#39;model&#39;]</p><h1 id="\u8FD9\u91CC-nanogpt-\u7684\u4F5C\u8005\u8BF4-resume-\u7684\u65F6\u5019\u6709-bug\uFF0C\u4E00\u4E9B\u53C2\u6570\u4F1A\u52A0\u4E0A\u524D\u7F00-orig-mod" tabindex="-1">\u8FD9\u91CC nanogpt \u7684\u4F5C\u8005\u8BF4 resume \u7684\u65F6\u5019\u6709 bug\uFF0C\u4E00\u4E9B\u53C2\u6570\u4F1A\u52A0\u4E0A\u524D\u7F00&#39;_orig_mod&#39; <a class="header-anchor" href="#\u8FD9\u91CC-nanogpt-\u7684\u4F5C\u8005\u8BF4-resume-\u7684\u65F6\u5019\u6709-bug\uFF0C\u4E00\u4E9B\u53C2\u6570\u4F1A\u52A0\u4E0A\u524D\u7F00-orig-mod" aria-hidden="true">#</a></h1><p>unwanted_prefix = &#39;_orig_mod&#39; for k,v in list(state_dict.items()): # \u904D\u5386 dict \u53BB\u9664 key \u4E2D\u4E0D\u8981\u7684\u524D\u7F00 if k.startswith(unwanted_prefix): state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k) # \u622A\u53D6 key \u540E\u534A\u6BB5 model.load_state_dict(state_dict)</p><p>model.eval() <a href="http://model.to" target="_blank" rel="noreferrer">model.to</a>(device)</p><p>enc = tiktoken.get_encoding(&quot;gpt2&quot;)# gpt2 tokenizer decode = lambda x:enc.decode(x) encode = lambda x:enc.encode(x,allowed_special={&quot;&lt;|endoftext|&gt;&quot;}) &#39;&#39;&#39; \u8868\u793A\u6587\u672C\u7ED3\u675F\u7684\u7279\u6B8A token\uFF0C\u5728 tokenization \u540E\u7531\u5F00\u53D1\u8005\u624B\u52A8\u52A0\u5165 \u5728\u5343\u95EE\u7684\u6587\u6863\u91CC\u6709\u4E2A\u89E3\u91CA<a href="https://github.com/QwenLM/Qwen/blob/main/tokenization_note_zh.md" target="_blank" rel="noreferrer">https://github.com/QwenLM/Qwen/blob/main/tokenization_note_zh.md</a><br> \u5982\u679C\u4E0D\u52A0\u8FD9\u6BB5\uFF0C&lt;|endoftext|&gt;\u4F1A\u88AB tokenize \u6210 ids:[1350, 9639, 91, 8691, 723, 427, 91, 82598] tokens: [b&#39;print&#39;, b&#39;(&quot;&lt;&#39;, b&#39;|&#39;, b&#39;endo&#39;, b&#39;ft&#39;, b&#39;ext&#39;, b&#39;|&#39;, b&#39;&gt;&quot;)&#39;] \u6211\u4EEC\u5E0C\u671B\u7684\u60C5\u51B5\u662F ids: [1350, 445, 151643, 899] tokens: [b&#39;print&#39;, b&#39;(&quot;&#39;, &#39;&lt;|endoftext|&gt;&#39;, b&#39;&quot;)&#39;] \u6211\u81EA\u5DF1\u5728 data/test_tiktoken.py \u4E2D\u8BD5\u9A8C\u4E86\u4E00\u4E0B\uFF0C \u5982\u679C\u4E0D\u589E\u52A0\u8FD9\u4E00\u53C2\u6570\uFF0C\u76F4\u63A5\u8FDB\u884C encode \u7684\u8BDD\u4F1A\u76F4\u63A5\u62A5\u9519 &#39;&#39;&#39;</p><p>start_ids = encode(start)</p><h1 id="x-torch-tensor-start-ids-dtype-torch-long-device-device-none" tabindex="-1">x = torch.tensor(start_ids,dtype=torch.long,device=device)[None,...] <a class="header-anchor" href="#x-torch-tensor-start-ids-dtype-torch-long-device-device-none" aria-hidden="true">#</a></h1><h1 id="none-\u589E\u52A0\u4E00\u4E2A\u7EF4\u5EA6\uFF0C\u540E\u9762-\u4FDD\u6301\u4E0D\u53D8-\u5C06\u4E00\u7EF4\u5F20\u91CF\u53D8\u6210\u4E8C\u7EF4\u5F20\u91CF" tabindex="-1">[None,...]\u589E\u52A0\u4E00\u4E2A\u7EF4\u5EA6\uFF0C\u540E\u9762...\u4FDD\u6301\u4E0D\u53D8,\u5C06\u4E00\u7EF4\u5F20\u91CF\u53D8\u6210\u4E8C\u7EF4\u5F20\u91CF <a class="header-anchor" href="#none-\u589E\u52A0\u4E00\u4E2A\u7EF4\u5EA6\uFF0C\u540E\u9762-\u4FDD\u6301\u4E0D\u53D8-\u5C06\u4E00\u7EF4\u5F20\u91CF\u53D8\u6210\u4E8C\u7EF4\u5F20\u91CF" aria-hidden="true">#</a></h1><h1 id="\u6216\u8005\u4F7F\u7528-unsqueeze-\u5E94\u8BE5\u4E5F\u80FD\u5B9E\u73B0" tabindex="-1">\u6216\u8005\u4F7F\u7528 unsqueeze \u5E94\u8BE5\u4E5F\u80FD\u5B9E\u73B0 <a class="header-anchor" href="#\u6216\u8005\u4F7F\u7528-unsqueeze-\u5E94\u8BE5\u4E5F\u80FD\u5B9E\u73B0" aria-hidden="true">#</a></h1><p>x = torch.tensor(start_ids,dtype=torch.long,device=device).unsqueeze(0)</p><p>ctx = torch.amp.autocast(device_type=device_type, dtype=ptdtype)</p><h1 id="\u8FD9\u91CC\u663E\u7136\u4E0D\u7528\u518D-scaler-\u4E86\uFF0C\u56E0\u4E3A\u4E0D\u8BA1\u7B97\u68AF\u5EA6" tabindex="-1">\u8FD9\u91CC\u663E\u7136\u4E0D\u7528\u518D scaler \u4E86\uFF0C\u56E0\u4E3A\u4E0D\u8BA1\u7B97\u68AF\u5EA6 <a class="header-anchor" href="#\u8FD9\u91CC\u663E\u7136\u4E0D\u7528\u518D-scaler-\u4E86\uFF0C\u56E0\u4E3A\u4E0D\u8BA1\u7B97\u68AF\u5EA6" aria-hidden="true">#</a></h1><h1 id="\u5F00\u59CB-generate" tabindex="-1">\u5F00\u59CB generate <a class="header-anchor" href="#\u5F00\u59CB-generate" aria-hidden="true">#</a></h1><p>with torch.no_grad(): with ctx: for k in range(num_samples): y = model.generate(x,max_new_tokens,top_k=top_k,tempreture=tempreture) print(decode(y[0].tolist())) print(&quot;----------&quot;)</p><p>Kimi: \u8FD9\u6BB5\u4EE3\u7801\u662F\u4E00\u4E2A\u7528\u4E8E\u751F\u6210\u6587\u672C\u7684\u811A\u672C\uFF0C\u5B83\u4F7F\u7528\u4E86\u4ECE\u68C0\u67E5\u70B9\u6062\u590D\u7684 GPT \u6A21\u578B\u3002\u4EE5\u4E0B\u662F\u8BE6\u7EC6\u6B65\u9AA4\u548C\u5173\u952E\u70B9\uFF1A</p><ol><li><p><strong>\u5BFC\u5165\u5FC5\u8981\u7684\u5E93</strong>:</p><ul><li>\u5BFC\u5165\u4E86 <code>os</code>, <code>tiktoken</code>, <code>torch</code> \u4EE5\u53CA\u81EA\u5B9A\u4E49\u7684 <code>model</code> \u6A21\u5757\u4E2D\u7684 <code>GPT</code> \u548C <code>Model_args</code> \u7C7B\u3002</li></ul></li><li><p><strong>\u8BBE\u7F6E\u57FA\u672C\u53C2\u6570</strong>:</p><ul><li>\u5B9A\u4E49\u4E86\u68C0\u67E5\u70B9\u4FDD\u5B58\u8DEF\u5F84 <code>checkpoint_save_dir</code>\uFF0C\u8BBE\u5907\u7C7B\u578B <code>device</code> \u548C\u6570\u636E\u7C7B\u578B <code>dtype</code>\u3002</li></ul></li><li><p><strong>\u8BFB\u53D6\u68C0\u67E5\u70B9</strong>:</p><ul><li>\u4ECE\u6307\u5B9A\u7684\u8DEF\u5F84\u52A0\u8F7D\u68C0\u67E5\u70B9\u6587\u4EF6 <code>checkpoint.pt</code>\uFF0C\u8BE5\u6587\u4EF6\u5305\u542B\u6A21\u578B\u53C2\u6570\u3001\u6743\u91CD\u548C\u5176\u4ED6\u8BAD\u7EC3\u4E2D\u7684\u72B6\u6001\u3002</li></ul></li><li><p><strong>\u521B\u5EFA\u6A21\u578B\u5B9E\u4F8B</strong>:</p><ul><li>\u4F7F\u7528\u68C0\u67E5\u70B9\u4E2D\u7684\u53C2\u6570 <code>args</code> \u521B\u5EFA <code>GPT</code> \u6A21\u578B\u7684\u5B9E\u4F8B\u3002</li></ul></li><li><p><strong>\u52A0\u8F7D\u6A21\u578B\u6743\u91CD</strong>:</p><ul><li>\u4ECE\u68C0\u67E5\u70B9\u4E2D\u79FB\u9664\u53EF\u80FD\u5B58\u5728\u7684\u524D\u7F00 <code>_orig_mod</code>\uFF0C\u7136\u540E\u52A0\u8F7D\u6A21\u578B\u6743\u91CD\u5230\u5F53\u524D\u6A21\u578B\u5B9E\u4F8B\u4E2D\u3002</li></ul></li><li><p><strong>\u8BBE\u7F6E\u6A21\u578B\u4E3A\u8BC4\u4F30\u6A21\u5F0F</strong>:</p><ul><li>\u4F7F\u7528 <code>model.eval()</code> \u5C06\u6A21\u578B\u8BBE\u7F6E\u4E3A\u8BC4\u4F30\u6A21\u5F0F\uFF0C\u5173\u95ED\u5728\u6A21\u578B\u4E2D\u4E0D\u9700\u8981\u8BA1\u7B97\u68AF\u5EA6\u7684\u90E8\u5206\uFF08\u5982 Dropout\uFF09\u3002</li></ul></li><li><p><strong>\u5C06\u6A21\u578B\u79FB\u52A8\u5230\u8BBE\u5907</strong>:</p><ul><li>\u4F7F\u7528 <code>model.to(device)</code> \u5C06\u6A21\u578B\u79FB\u52A8\u5230 GPU \u6216\u5176\u4ED6\u6307\u5B9A\u8BBE\u5907\u4E0A\u3002</li></ul></li><li><p><strong>\u521D\u59CB\u5316\u7F16\u7801\u5668</strong>:</p><ul><li>\u4F7F\u7528 <code>tiktoken</code> \u52A0\u8F7D GPT-2 \u7684 tokenizer\u3002</li></ul></li><li><p><strong>\u5B9A\u4E49\u7F16\u7801\u548C\u89E3\u7801\u51FD\u6570</strong>:</p><ul><li><code>decode</code> \u51FD\u6570\u5C06 token ID \u8F6C\u6362\u56DE\u6587\u672C\u3002</li><li><code>encode</code> \u51FD\u6570\u5C06\u6587\u672C\u8F6C\u6362\u4E3A token ID\uFF0C\u540C\u65F6\u5904\u7406\u7279\u6B8A\u7684\u6587\u672C\u7ED3\u675F\u6807\u8BB0 <code>&lt;|endoftext|&gt;</code>\u3002</li></ul></li><li><p><strong>\u6587\u672C\u751F\u6210\u53C2\u6570</strong>:</p><ul><li>\u8BBE\u7F6E <code>top_k</code> \u4E3A 200\uFF0C<code>tempreture</code> \u4E3A 0.5\uFF0C\u8FD9\u4E9B\u53C2\u6570\u63A7\u5236\u751F\u6210\u8FC7\u7A0B\u4E2D\u7684\u968F\u673A\u6027\u548C token \u9009\u62E9\u3002</li></ul></li><li><p><strong>\u51C6\u5907\u8F93\u5165</strong>:</p><ul><li>\u5C06\u5F00\u59CB\u6587\u672C <code>start</code> \u7F16\u7801\u4E3A token ID\uFF0C\u5E76\u5C06\u5176\u8F6C\u6362\u4E3A\u9002\u5408\u6A21\u578B\u7684\u5F20\u91CF <code>x</code>\u3002</li></ul></li><li><p><strong>\u751F\u6210\u6587\u672C</strong>:</p><ul><li>\u4F7F\u7528 <code>torch.no_grad()</code> \u7981\u7528\u68AF\u5EA6\u8BA1\u7B97\uFF0C\u4EE5\u8282\u7701\u5185\u5B58\u5E76\u52A0\u5FEB\u751F\u6210\u901F\u5EA6\u3002</li><li>\u4F7F\u7528 <code>torch.amp.autocast</code> \u8BBE\u7F6E\u6DF7\u5408\u7CBE\u5EA6\u4E0A\u4E0B\u6587\uFF0C\u5C3D\u7BA1\u5728\u751F\u6210\u9636\u6BB5\u53EF\u80FD\u4E0D\u9700\u8981\u3002</li><li>\u8C03\u7528\u6A21\u578B\u7684 <code>generate</code> \u65B9\u6CD5\u751F\u6210\u6587\u672C\uFF0C\u5E76\u4F7F\u7528 <code>decode</code> \u51FD\u6570\u5C06\u751F\u6210\u7684 token ID \u8F6C\u6362\u56DE\u6587\u672C\u3002</li></ul></li><li><p><strong>\u6253\u5370\u751F\u6210\u7684\u6587\u672C</strong>:</p><ul><li>\u6253\u5370\u6BCF\u6B21\u751F\u6210\u7684\u6587\u672C\u548C\u5206\u9694\u7B26\u3002</li></ul></li></ol><p>\u8FD9\u6BB5\u4EE3\u7801\u6F14\u793A\u4E86\u5982\u4F55\u4F7F\u7528\u9884\u8BAD\u7EC3\u7684 GPT \u6A21\u578B\u8FDB\u884C\u6587\u672C\u751F\u6210\uFF0C\u5305\u62EC\u4ECE\u68C0\u67E5\u70B9\u6062\u590D\u6A21\u578B\u3001\u51C6\u5907\u8F93\u5165\u3001\u751F\u6210\u6587\u672C\u4EE5\u53CA\u5C06\u751F\u6210\u7684 token ID \u8F6C\u6362\u56DE\u53EF\u8BFB\u7684\u6587\u672C\u3002\u901A\u8FC7\u8C03\u6574 <code>top_k</code> \u548C <code>tempreture</code> \u53C2\u6570\uFF0C\u53EF\u4EE5\u63A7\u5236\u751F\u6210\u6587\u672C\u7684\u968F\u673A\u6027\u548C\u591A\u6837\u6027\u3002</p>`,118),c=[t,p,r];function i(d,u,_,m,B,g){return n(),o("div",null,c)}const b=s(l,[["render",i]]);export{y as __pageData,b as default};
